{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"../\")\n",
    "from src import prepro, metrics, run, setup\n",
    "import src.models.factory as model_factory\n",
    "import config\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from src.utils import models\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from src.utils.data_processing import *\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#args = setup.create_setup()\n",
    "#args.mode = 'displacement'\n",
    "#args.full_encoder = True\n",
    "#args.encoder_config = 'full_encoder_config'\n",
    "#args.decoder_config = 'lstm_config'\n",
    "window_size = 8\n",
    "predict_at = 16\n",
    "#args.target_intensity_cat = False\n",
    "#args.sub_window_size = 8\n",
    "#args.sub_area = 1\n",
    "#args.output_dir = '../results/results8_16_20_44_28' #''../results/results8_16_18_57_7' best so far\n",
    "#try: ../results/results8_16_20_44_28, 0.086 from training\n",
    "#Reached 70.4 and the best results with combination. 7.47 GRU outputs 64. All rest normal.\n",
    "#args.output_dir = './results/results7_20_17_12_19' #Be careful to change 2304 for intermediary layer\n",
    "#args.output_dir = './results/results7_20_15_4_36' : best for acc 70.5 and nearly best for intensiy 7.50\n",
    "#args. = ./results/results8_12_19_5_42 for best perf t+48h\n",
    "\n",
    "#if args.sub_area > 0:\n",
    "    #x_viz_train = x_viz_train[:, :, :, args.sub_area:-args.sub_area, args.sub_area:-args.sub_area]\n",
    "    #x_viz_test = x_viz_test[:, :, :, args.sub_area:-args.sub_area, args.sub_area:-args.sub_area]\n",
    "\n",
    "tgt_intensity_cat_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                      allow_pickle=True))\n",
    "tgt_intensity_cat_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "\n",
    "tgt_intensity_train = torch.Tensor(np.load('../data/y_train_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                  allow_pickle=True))\n",
    "tgt_intensity_test = torch.Tensor(np.load('../data/y_test_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                 allow_pickle=True))\n",
    "\n",
    "tgt_intensity_cat_baseline_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',  allow_pickle = True))\n",
    "tgt_intensity_cat_baseline_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train_unst = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test_unst = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "\n",
    "mean_intensity = tgt_intensity_train.mean()\n",
    "std_intensity = tgt_intensity_train.std()\n",
    "tgt_intensity_train = (tgt_intensity_train - mean_intensity)/std_intensity\n",
    "tgt_intensity_test = (tgt_intensity_test - mean_intensity)/std_intensity\n",
    "\n",
    "\n",
    "###INTENSITY\n",
    "mean_dx = tgt_displacement_train[:,0].mean()\n",
    "std_dx = tgt_displacement_train[:,0].std()\n",
    "tgt_displacement_train[:,0] = (tgt_displacement_train[:,0] - mean_dx)/std_dx\n",
    "tgt_displacement_test[:,0] = (tgt_displacement_test[:,0] - mean_dx)/std_dx\n",
    "std_dx = float(std_dx)\n",
    "mean_dx = float(mean_dx)\n",
    "\n",
    "mean_dy = tgt_displacement_train[:,1].mean()\n",
    "std_dy = tgt_displacement_train[:,1].std()\n",
    "tgt_displacement_train[:,1] = (tgt_displacement_train[:,1] - mean_dy)/std_dy\n",
    "tgt_displacement_test[:,1] = (tgt_displacement_test[:,1] - mean_dy)/std_dy\n",
    "std_dy = float(std_dy)\n",
    "mean_dy = float(mean_dy)\n",
    "\n",
    "def standardize(tgt_displacement_train, tgt_displacement_test):\n",
    "    mean_dx = tgt_displacement_train[:, 0].mean()\n",
    "    std_dx = tgt_displacement_train[:, 0].std()\n",
    "    tgt_displacement_train[:, 0] = (tgt_displacement_train[:, 0] - mean_dx) / std_dx\n",
    "    tgt_displacement_test[:, 0] = (tgt_displacement_test[:, 0] - mean_dx) / std_dx\n",
    "    std_dx = float(std_dx)\n",
    "    mean_dx = float(mean_dx)\n",
    "    mean_dy = tgt_displacement_train[:, 1].mean()\n",
    "    std_dy = tgt_displacement_train[:, 1].std()\n",
    "    tgt_displacement_train[:, 1] = (tgt_displacement_train[:, 1] - mean_dy) / std_dy\n",
    "    tgt_displacement_test[:, 1] = (tgt_displacement_test[:, 1] - mean_dy) / std_dy\n",
    "    std_dy = float(std_dy)\n",
    "    mean_dy = float(mean_dy)\n",
    "    return tgt_displacement_train, tgt_displacement_test, std_dx, mean_dx, std_dy, mean_dy\n",
    "\n",
    "def unstandardize(tgt_displacement_train, tgt_displacement_test, std_dx, mean_dx, std_dy, mean_dy):\n",
    "    tgt_displacement_train[:, 0] = tgt_displacement_train[:, 0] *  std_dx + mean_dx\n",
    "    tgt_displacement_test[:, 0] = tgt_displacement_test[:, 0] *  std_dx + mean_dx\n",
    "    tgt_displacement_train[:, 1] = tgt_displacement_train[:, 1] * std_dy + mean_dy\n",
    "    tgt_displacement_test[:, 1] = tgt_displacement_test[:, 1] * std_dy + mean_dy\n",
    "    return tgt_displacement_train, tgt_displacement_test\n",
    "\n",
    "\n",
    "##########\n",
    "##########\n",
    "########## PREPARING DATA FOR XGB\n",
    "\n",
    "X_train = np.load('../data/X_train_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "X_test = np.load('../data/X_test_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'cat_cos_day', 'cat_sign_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
    "         'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'cat_storm_category', 'cat_basin_AN',\n",
    "         'cat_basin_EP', 'cat_basin_NI', 'cat_basin_SA',\n",
    "         'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "         'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "         'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i // 30)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-2:] == '_0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_embed = np.load('../data/embeddings/X_train_embeds_1980_34_20_120_results8_16_20_44_28.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embeds_1980_34_20_120_results8_16_20_44_28.npy', allow_pickle = True)\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity.npy', allow_pickle = True)\n",
    "\n",
    "#48\n",
    "X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "\n",
    "X_train_total = np.concatenate((X_train, X_train_embed), axis = 1)\n",
    "X_test_total = np.concatenate((X_test, X_test_embed), axis = 1)\n",
    "\n",
    "std_ = float(std_intensity)\n",
    "mean_ = float(mean_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32623637, 0.2453524 , 0.30252   , 0.2068524 , 0.569222  ,\n",
       "       0.3129427 , 0.25083327, 0.5475748 , 0.45903492, 0.29479325,\n",
       "       0.39042005, 0.46348616, 0.39096308, 0.33948642, 0.24545877,\n",
       "       0.28124598, 0.28033993, 0.42566696, 0.51634353, 0.5100166 ,\n",
       "       0.30813473, 0.476275  , 0.3991406 , 0.3804275 , 0.4139351 ,\n",
       "       0.29657942, 0.5055465 , 0.3844849 , 0.15621336, 0.44216263,\n",
       "       0.19743301, 0.45874766, 0.5273378 , 0.32123196, 0.38916793,\n",
       "       0.5022551 , 0.2860133 , 0.27160797, 0.28035945, 0.5265858 ,\n",
       "       0.4426414 , 0.3194403 , 0.49691105, 0.29644164, 0.5246908 ,\n",
       "       0.42100573, 0.42218858, 0.44222334, 0.37747246, 0.55683464,\n",
       "       0.4348592 , 0.5397909 , 0.26551577, 0.25035217, 0.25046262,\n",
       "       0.44206345, 0.3987248 , 0.44384882, 0.4536024 , 0.36178795,\n",
       "       0.34023088, 0.5061376 , 0.3568393 , 0.37379837, 0.47772896,\n",
       "       0.31256968, 0.3720116 , 0.26771006, 0.55373466, 0.35055223,\n",
       "       0.3148587 , 0.53132206, 0.5260325 , 0.3746377 , 0.52086645,\n",
       "       0.5121704 , 0.54049605, 0.5390898 , 0.31467497, 0.28347987,\n",
       "       0.36942   , 0.4609382 , 0.467228  , 0.37233213, 0.3577239 ,\n",
       "       0.5445715 , 0.4770471 , 0.3745039 , 0.40336004, 0.35426185,\n",
       "       0.46040392, 0.50151086, 0.22374433, 0.3060887 , 0.27847117,\n",
       "       0.32169902, 0.4725596 , 0.17069644, 0.450594  , 0.45766014,\n",
       "       0.3293865 , 0.22917628, 0.3640513 , 0.3843086 , 0.44542947,\n",
       "       0.43859264, 0.47468027, 0.3033968 , 0.5997776 , 0.5110383 ,\n",
       "       0.54268515, 0.5087991 , 0.4208691 , 0.5851813 , 0.3900144 ,\n",
       "       0.62761587, 0.23671357, 0.3614385 , 0.3338742 , 0.4989046 ,\n",
       "       0.5657068 , 0.49180514, 0.45035204, 0.3835785 , 0.42036885,\n",
       "       0.39433023, 0.33779177, 0.4028771 , 0.5392608 , 0.35182974,\n",
       "       0.44165125, 0.29532254, 0.48255593, 0.35587546, 0.35727155,\n",
       "       0.5132281 , 0.5419763 , 0.37571284, 0.53432125, 0.4855775 ,\n",
       "       0.58861333, 0.60812473, 0.33541846, 0.27945414, 0.42556366,\n",
       "       0.47586873, 0.48170805, 0.31579086, 0.37299258, 0.576204  ,\n",
       "       0.47814867, 0.3954492 , 0.37132332, 0.4082822 , 0.42378452,\n",
       "       0.54358625, 0.26281413, 0.29862678, 0.3048093 , 0.28581676,\n",
       "       0.4765962 , 0.14033379, 0.505194  , 0.49023783, 0.34209287,\n",
       "       0.21793814, 0.40849683, 0.3158929 , 0.4033025 , 0.3569461 ,\n",
       "       0.40106145, 0.25359562, 0.6047464 , 0.54381055, 0.56590974,\n",
       "       0.4858134 , 0.44225168, 0.5732466 , 0.3606604 , 0.6456514 ,\n",
       "       0.22012852, 0.40491384, 0.35480317, 0.47740582, 0.57424927,\n",
       "       0.5071636 , 0.44146773, 0.4179456 , 0.43506554, 0.35875317,\n",
       "       0.35737398, 0.41084975, 0.5601241 , 0.3788927 , 0.4837668 ,\n",
       "       0.31845272, 0.5141609 , 0.38012388, 0.3891519 , 0.5260566 ,\n",
       "       0.5542082 , 0.3820099 , 0.5332071 , 0.4784726 , 0.61038375,\n",
       "       0.6249919 , 0.3573188 , 0.29345074, 0.45603904, 0.5032049 ,\n",
       "       0.49388808, 0.3080863 , 0.3836148 , 0.58716375, 0.4873531 ,\n",
       "       0.40695265, 0.37337494, 0.43927494, 0.44913092, 0.57424605,\n",
       "       0.29164436, 0.30882505, 0.3245    , 0.28165624, 0.49171606,\n",
       "       0.14131485, 0.5344678 , 0.51226133, 0.36189902, 0.22145939,\n",
       "       0.4348317 , 0.31908935, 0.41521165, 0.33055922, 0.3880521 ,\n",
       "       0.23661591, 0.6214975 , 0.56108326, 0.57767665, 0.48257506,\n",
       "       0.49310055, 0.5800798 , 0.36198488, 0.6537529 , 0.22078434,\n",
       "       0.43009102, 0.37417006, 0.48973393, 0.5881437 , 0.51374966,\n",
       "       0.4571781 , 0.43668213, 0.45877507, 0.37924597, 0.3777159 ,\n",
       "       0.43310696, 0.56609136, 0.3960279 , 0.505114  , 0.33608735,\n",
       "       0.5278607 , 0.39721632, 0.40749177, 0.52240366, 0.5516116 ,\n",
       "       0.39239374, 0.5395992 , 0.48308936, 0.6151073 , 0.63073385,\n",
       "       0.37423706, 0.302134  , 0.47389317, 0.5161768 , 0.50102675,\n",
       "       0.29940802, 0.3872367 , 0.5896922 , 0.49734616, 0.4152353 ,\n",
       "       0.3715936 , 0.46378598, 0.438153  , 0.5861474 , 0.31485817,\n",
       "       0.30056348, 0.34109926, 0.25633177, 0.49056906, 0.13554269,\n",
       "       0.54389   , 0.50235283, 0.3789    , 0.22432546, 0.4505674 ,\n",
       "       0.30375782, 0.40579033, 0.34590328, 0.39170542, 0.23482834,\n",
       "       0.6201406 , 0.5681161 , 0.5842688 , 0.47746083, 0.50975335,\n",
       "       0.5712219 , 0.35923046, 0.6598028 , 0.2254231 , 0.4464943 ,\n",
       "       0.3933967 , 0.49448892, 0.5944917 , 0.5118088 , 0.4631518 ,\n",
       "       0.44232577, 0.47694162, 0.38648108, 0.37996128, 0.42783904,\n",
       "       0.5677888 , 0.40933508, 0.52464014, 0.35175863, 0.53789675,\n",
       "       0.40793517, 0.4236095 , 0.52171147, 0.5499655 , 0.40089735,\n",
       "       0.5415835 , 0.47867605, 0.6185996 , 0.63461167, 0.38678345,\n",
       "       0.30951056, 0.48855576, 0.5280736 , 0.506091  , 0.29781955,\n",
       "       0.39074513, 0.5905282 , 0.5062226 , 0.42300028, 0.3708935 ,\n",
       "       0.4857458 , 0.44822317, 0.5926362 , 0.33260348, 0.31170094,\n",
       "       0.3540561 , 0.2550905 , 0.4908885 , 0.13602693, 0.5493088 ,\n",
       "       0.50392807, 0.39244702, 0.22750504, 0.46196336, 0.30466735,\n",
       "       0.40549493, 0.34815943, 0.38965806, 0.23527284, 0.6186712 ,\n",
       "       0.57347035, 0.58922666, 0.47426566, 0.5197278 , 0.5650226 ,\n",
       "       0.3609645 , 0.6654874 , 0.23026623, 0.4596969 , 0.4067298 ,\n",
       "       0.49522245, 0.59864753, 0.5127497 , 0.46947134, 0.447365  ,\n",
       "       0.49019116, 0.3886479 , 0.3858679 , 0.4303602 , 0.5710205 ,\n",
       "       0.4207136 , 0.54041076, 0.36578962, 0.54829013, 0.41997588,\n",
       "       0.43759322, 0.52307594, 0.5488048 , 0.4088507 , 0.54297996,\n",
       "       0.47958568, 0.6212043 , 0.6378104 , 0.39828292, 0.3165961 ,\n",
       "       0.5014346 , 0.5397176 , 0.51026535, 0.29682642, 0.39443722,\n",
       "       0.59239805, 0.5146874 , 0.4299739 , 0.37247452, 0.501986  ,\n",
       "       0.45768583, 0.5986841 , 0.34680632, 0.31509203, 0.36578795,\n",
       "       0.25293103, 0.49290037, 0.13582747, 0.5544436 , 0.50451905,\n",
       "       0.40502942, 0.23054703, 0.47314388, 0.303049  , 0.40811476,\n",
       "       0.3506053 , 0.39244342, 0.23662129, 0.61877656, 0.57849944,\n",
       "       0.59477085, 0.4740384 , 0.53158313, 0.56098   , 0.3654416 ,\n",
       "       0.66992587, 0.23499136, 0.47157845, 0.41971272, 0.49879536,\n",
       "       0.6033316 , 0.51312906, 0.47598174, 0.45282182, 0.50226474,\n",
       "       0.3943974 , 0.39226747, 0.431134  , 0.5741446 , 0.43142122,\n",
       "       0.5541834 , 0.37887627, 0.5575256 , 0.4321555 , 0.45053884,\n",
       "       0.52496046, 0.54721117, 0.41692585, 0.5452414 , 0.4808867 ,\n",
       "       0.6230441 , 0.64073527, 0.40924105, 0.32324633, 0.5134183 ,\n",
       "       0.551011  , 0.51375717, 0.29521665, 0.39808938, 0.59354305,\n",
       "       0.52333516, 0.4365585 , 0.37431127, 0.51641595, 0.464145  ,\n",
       "       0.60346425, 0.3586714 , 0.31893563, 0.37689334, 0.25115192,\n",
       "       0.49419433, 0.13552888, 0.5592379 , 0.5049655 , 0.417309  ,\n",
       "       0.23370586, 0.4844303 , 0.30100748, 0.40838665, 0.35515797,\n",
       "       0.39632842, 0.23902294, 0.61829144, 0.5826638 , 0.6003691 ,\n",
       "       0.47409663, 0.54136574, 0.5566166 , 0.369547  , 0.67380273,\n",
       "       0.24001902, 0.48299688, 0.4331734 , 0.50202185, 0.6079752 ,\n",
       "       0.5135353 , 0.48197958, 0.45776963, 0.51324075, 0.39964983,\n",
       "       0.39823088, 0.4309476 ], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.std(axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBRegressor(max_depth=6, n_estimators=140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "xgb2.fit(X_train, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb2.predict(X_test))*std_+mean_))\n",
    "\n",
    "xgb = XGBRegressor(max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.9)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  22.123682\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7)\n",
    "xgb.fit(X_train_embed, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_embed))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  20.64371\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 120, learning_rate = 0.07, subsample = 0.7)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639']\ntraining data did not have the following fields: f549, f620, f591, f552, f519, f585, f551, f627, f601, f636, f520, f581, f565, f525, f584, f586, f540, f569, f573, f522, f571, f558, f590, f576, f605, f561, f583, f533, f625, f616, f589, f611, f548, f516, f612, f574, f617, f614, f572, f538, f602, f524, f638, f544, f621, f523, f541, f513, f635, f588, f618, f530, f608, f554, f514, f596, f599, f521, f566, f542, f634, f624, f593, f606, f597, f531, f563, f619, f598, f528, f556, f637, f532, f629, f518, f564, f632, f550, f547, f535, f560, f630, f546, f578, f529, f577, f557, f570, f631, f543, f553, f527, f628, f613, f609, f545, f623, f537, f536, f515, f517, f575, f579, f534, f526, f562, f603, f594, f567, f592, f582, f607, f559, f580, f539, f633, f512, f555, f604, f626, f600, f587, f610, f568, f595, f615, f622, f639",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-42771f508d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                           validate_features=validate_features)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 2131\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m     def get_split_value_histogram(self, feature, fmap='', bins=None,\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639']\ntraining data did not have the following fields: f549, f620, f591, f552, f519, f585, f551, f627, f601, f636, f520, f581, f565, f525, f584, f586, f540, f569, f573, f522, f571, f558, f590, f576, f605, f561, f583, f533, f625, f616, f589, f611, f548, f516, f612, f574, f617, f614, f572, f538, f602, f524, f638, f544, f621, f523, f541, f513, f635, f588, f618, f530, f608, f554, f514, f596, f599, f521, f566, f542, f634, f624, f593, f606, f597, f531, f563, f619, f598, f528, f556, f637, f532, f629, f518, f564, f632, f550, f547, f535, f560, f630, f546, f578, f529, f577, f557, f570, f631, f543, f553, f527, f628, f613, f609, f545, f623, f537, f536, f515, f517, f575, f579, f534, f526, f562, f603, f594, f567, f592, f582, f607, f559, f580, f539, f633, f512, f555, f604, f626, f600, f587, f610, f568, f595, f615, f622, f639"
     ]
    }
   ],
   "source": [
    "xgb.predict(X_train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  6.808701\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_train)*std_+mean_, np.array(xgb.predict(X_train_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32623637, 0.2453524 , 0.30252   , 0.2068524 , 0.569222  ,\n",
       "       0.3129427 , 0.25083327, 0.5475748 , 0.45903492, 0.29479325,\n",
       "       0.39042005, 0.46348616, 0.39096308, 0.33948642, 0.24545877,\n",
       "       0.28124598, 0.28033993, 0.42566696, 0.51634353, 0.5100166 ,\n",
       "       0.30813473, 0.476275  , 0.3991406 , 0.3804275 , 0.4139351 ,\n",
       "       0.29657942, 0.5055465 , 0.3844849 , 0.15621336, 0.44216263,\n",
       "       0.19743301, 0.45874766, 0.5273378 , 0.32123196, 0.38916793,\n",
       "       0.5022551 , 0.2860133 , 0.27160797, 0.28035945, 0.5265858 ,\n",
       "       0.4426414 , 0.3194403 , 0.49691105, 0.29644164, 0.5246908 ,\n",
       "       0.42100573, 0.42218858, 0.44222334, 0.37747246, 0.55683464,\n",
       "       0.4348592 , 0.5397909 , 0.26551577, 0.25035217, 0.25046262,\n",
       "       0.44206345, 0.3987248 , 0.44384882, 0.4536024 , 0.36178795,\n",
       "       0.34023088, 0.5061376 , 0.3568393 , 0.37379837, 0.47772896,\n",
       "       0.31256968, 0.3720116 , 0.26771006, 0.55373466, 0.35055223,\n",
       "       0.3148587 , 0.53132206, 0.5260325 , 0.3746377 , 0.52086645,\n",
       "       0.5121704 , 0.54049605, 0.5390898 , 0.31467497, 0.28347987,\n",
       "       0.36942   , 0.4609382 , 0.467228  , 0.37233213, 0.3577239 ,\n",
       "       0.5445715 , 0.4770471 , 0.3745039 , 0.40336004, 0.35426185,\n",
       "       0.46040392, 0.50151086, 0.22374433, 0.3060887 , 0.27847117,\n",
       "       0.32169902, 0.4725596 , 0.17069644, 0.450594  , 0.45766014,\n",
       "       0.3293865 , 0.22917628, 0.3640513 , 0.3843086 , 0.44542947,\n",
       "       0.43859264, 0.47468027, 0.3033968 , 0.5997776 , 0.5110383 ,\n",
       "       0.54268515, 0.5087991 , 0.4208691 , 0.5851813 , 0.3900144 ,\n",
       "       0.62761587, 0.23671357, 0.3614385 , 0.3338742 , 0.4989046 ,\n",
       "       0.5657068 , 0.49180514, 0.45035204, 0.3835785 , 0.42036885,\n",
       "       0.39433023, 0.33779177, 0.4028771 , 0.5392608 , 0.35182974,\n",
       "       0.44165125, 0.29532254, 0.48255593, 0.35587546, 0.35727155,\n",
       "       0.5132281 , 0.5419763 , 0.37571284, 0.53432125, 0.4855775 ,\n",
       "       0.58861333, 0.60812473, 0.33541846, 0.27945414, 0.42556366,\n",
       "       0.47586873, 0.48170805, 0.31579086, 0.37299258, 0.576204  ,\n",
       "       0.47814867, 0.3954492 , 0.37132332, 0.4082822 , 0.42378452,\n",
       "       0.54358625, 0.26281413, 0.29862678, 0.3048093 , 0.28581676,\n",
       "       0.4765962 , 0.14033379, 0.505194  , 0.49023783, 0.34209287,\n",
       "       0.21793814, 0.40849683, 0.3158929 , 0.4033025 , 0.3569461 ,\n",
       "       0.40106145, 0.25359562, 0.6047464 , 0.54381055, 0.56590974,\n",
       "       0.4858134 , 0.44225168, 0.5732466 , 0.3606604 , 0.6456514 ,\n",
       "       0.22012852, 0.40491384, 0.35480317, 0.47740582, 0.57424927,\n",
       "       0.5071636 , 0.44146773, 0.4179456 , 0.43506554, 0.35875317,\n",
       "       0.35737398, 0.41084975, 0.5601241 , 0.3788927 , 0.4837668 ,\n",
       "       0.31845272, 0.5141609 , 0.38012388, 0.3891519 , 0.5260566 ,\n",
       "       0.5542082 , 0.3820099 , 0.5332071 , 0.4784726 , 0.61038375,\n",
       "       0.6249919 , 0.3573188 , 0.29345074, 0.45603904, 0.5032049 ,\n",
       "       0.49388808, 0.3080863 , 0.3836148 , 0.58716375, 0.4873531 ,\n",
       "       0.40695265, 0.37337494, 0.43927494, 0.44913092, 0.57424605,\n",
       "       0.29164436, 0.30882505, 0.3245    , 0.28165624, 0.49171606,\n",
       "       0.14131485, 0.5344678 , 0.51226133, 0.36189902, 0.22145939,\n",
       "       0.4348317 , 0.31908935, 0.41521165, 0.33055922, 0.3880521 ,\n",
       "       0.23661591, 0.6214975 , 0.56108326, 0.57767665, 0.48257506,\n",
       "       0.49310055, 0.5800798 , 0.36198488, 0.6537529 , 0.22078434,\n",
       "       0.43009102, 0.37417006, 0.48973393, 0.5881437 , 0.51374966,\n",
       "       0.4571781 , 0.43668213, 0.45877507, 0.37924597, 0.3777159 ,\n",
       "       0.43310696, 0.56609136, 0.3960279 , 0.505114  , 0.33608735,\n",
       "       0.5278607 , 0.39721632, 0.40749177, 0.52240366, 0.5516116 ,\n",
       "       0.39239374, 0.5395992 , 0.48308936, 0.6151073 , 0.63073385,\n",
       "       0.37423706, 0.302134  , 0.47389317, 0.5161768 , 0.50102675,\n",
       "       0.29940802, 0.3872367 , 0.5896922 , 0.49734616, 0.4152353 ,\n",
       "       0.3715936 , 0.46378598, 0.438153  , 0.5861474 , 0.31485817,\n",
       "       0.30056348, 0.34109926, 0.25633177, 0.49056906, 0.13554269,\n",
       "       0.54389   , 0.50235283, 0.3789    , 0.22432546, 0.4505674 ,\n",
       "       0.30375782, 0.40579033, 0.34590328, 0.39170542, 0.23482834,\n",
       "       0.6201406 , 0.5681161 , 0.5842688 , 0.47746083, 0.50975335,\n",
       "       0.5712219 , 0.35923046, 0.6598028 , 0.2254231 , 0.4464943 ,\n",
       "       0.3933967 , 0.49448892, 0.5944917 , 0.5118088 , 0.4631518 ,\n",
       "       0.44232577, 0.47694162, 0.38648108, 0.37996128, 0.42783904,\n",
       "       0.5677888 , 0.40933508, 0.52464014, 0.35175863, 0.53789675,\n",
       "       0.40793517, 0.4236095 , 0.52171147, 0.5499655 , 0.40089735,\n",
       "       0.5415835 , 0.47867605, 0.6185996 , 0.63461167, 0.38678345,\n",
       "       0.30951056, 0.48855576, 0.5280736 , 0.506091  , 0.29781955,\n",
       "       0.39074513, 0.5905282 , 0.5062226 , 0.42300028, 0.3708935 ,\n",
       "       0.4857458 , 0.44822317, 0.5926362 , 0.33260348, 0.31170094,\n",
       "       0.3540561 , 0.2550905 , 0.4908885 , 0.13602693, 0.5493088 ,\n",
       "       0.50392807, 0.39244702, 0.22750504, 0.46196336, 0.30466735,\n",
       "       0.40549493, 0.34815943, 0.38965806, 0.23527284, 0.6186712 ,\n",
       "       0.57347035, 0.58922666, 0.47426566, 0.5197278 , 0.5650226 ,\n",
       "       0.3609645 , 0.6654874 , 0.23026623, 0.4596969 , 0.4067298 ,\n",
       "       0.49522245, 0.59864753, 0.5127497 , 0.46947134, 0.447365  ,\n",
       "       0.49019116, 0.3886479 , 0.3858679 , 0.4303602 , 0.5710205 ,\n",
       "       0.4207136 , 0.54041076, 0.36578962, 0.54829013, 0.41997588,\n",
       "       0.43759322, 0.52307594, 0.5488048 , 0.4088507 , 0.54297996,\n",
       "       0.47958568, 0.6212043 , 0.6378104 , 0.39828292, 0.3165961 ,\n",
       "       0.5014346 , 0.5397176 , 0.51026535, 0.29682642, 0.39443722,\n",
       "       0.59239805, 0.5146874 , 0.4299739 , 0.37247452, 0.501986  ,\n",
       "       0.45768583, 0.5986841 , 0.34680632, 0.31509203, 0.36578795,\n",
       "       0.25293103, 0.49290037, 0.13582747, 0.5544436 , 0.50451905,\n",
       "       0.40502942, 0.23054703, 0.47314388, 0.303049  , 0.40811476,\n",
       "       0.3506053 , 0.39244342, 0.23662129, 0.61877656, 0.57849944,\n",
       "       0.59477085, 0.4740384 , 0.53158313, 0.56098   , 0.3654416 ,\n",
       "       0.66992587, 0.23499136, 0.47157845, 0.41971272, 0.49879536,\n",
       "       0.6033316 , 0.51312906, 0.47598174, 0.45282182, 0.50226474,\n",
       "       0.3943974 , 0.39226747, 0.431134  , 0.5741446 , 0.43142122,\n",
       "       0.5541834 , 0.37887627, 0.5575256 , 0.4321555 , 0.45053884,\n",
       "       0.52496046, 0.54721117, 0.41692585, 0.5452414 , 0.4808867 ,\n",
       "       0.6230441 , 0.64073527, 0.40924105, 0.32324633, 0.5134183 ,\n",
       "       0.551011  , 0.51375717, 0.29521665, 0.39808938, 0.59354305,\n",
       "       0.52333516, 0.4365585 , 0.37431127, 0.51641595, 0.464145  ,\n",
       "       0.60346425, 0.3586714 , 0.31893563, 0.37689334, 0.25115192,\n",
       "       0.49419433, 0.13552888, 0.5592379 , 0.5049655 , 0.417309  ,\n",
       "       0.23370586, 0.4844303 , 0.30100748, 0.40838665, 0.35515797,\n",
       "       0.39632842, 0.23902294, 0.61829144, 0.5826638 , 0.6003691 ,\n",
       "       0.47409663, 0.54136574, 0.5566166 , 0.369547  , 0.67380273,\n",
       "       0.24001902, 0.48299688, 0.4331734 , 0.50202185, 0.6079752 ,\n",
       "       0.5135353 , 0.48197958, 0.45776963, 0.51324075, 0.39964983,\n",
       "       0.39823088, 0.4309476 ], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.std(axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  11.97465\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 140, learning_rate = 0.07, subsample = 0.8)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings\r\n",
      "last3years.csv\r\n",
      "tensor_completion\r\n",
      "vision_data_1980_34_20_120_forecast_all_48_clean.npy\r\n",
      "vision_data_1980_34_20_120.npy\r\n",
      "X_test_stat_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "X_test_stat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "X_test_stat_1980_34_20_120_w16_at_8.npy\r\n",
      "X_test_stat_1980_34_20_120_w4_at_16.npy\r\n",
      "X_test_stat_1980_34_20_120_w4_at_8.npy\r\n",
      "X_test_stat_1980_34_20_120_w8_at_16.npy\r\n",
      "X_test_stat_1980_34_20_120_w8_at_8.npy\r\n",
      "X_test_stat_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "X_test_stat_with_dates_columns_1980_w8_at_8.npy\r\n",
      "X_test_vision_1980_34_20_120_w12_at_8.npy\r\n",
      "X_test_vision_1980_34_20_120_w16at_16.npy\r\n",
      "X_test_vision_1980_34_20_120_w16_at_24.npy\r\n",
      "X_test_vision_1980_34_20_120_w16_at_8.npy\r\n",
      "X_test_vision_1980_34_20_120_w2_at_8.npy\r\n",
      "X_test_vision_1980_34_20_120_w4_at_16.npy\r\n",
      "X_test_vision_1980_34_20_120_w4_at_8.npy\r\n",
      "X_test_vision_1980_34_20_120_w8_at_16.npy\r\n",
      "X_test_vision_1980_34_20_120_w8_at_8.npy\r\n",
      "X_test_vision_1980_50_20_90_w12.npy\r\n",
      "X_test_vision_1980_50_20_90_w16.npy\r\n",
      "X_test_vision_1980_50_20_90_w8.npy\r\n",
      "X_test_vision_comp_1980_34_20_120.npy\r\n",
      "X_train_stat_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "X_train_stat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "X_train_stat_1980_34_20_120_w16_at_8.npy\r\n",
      "X_train_stat_1980_34_20_120_w4_at_16.npy\r\n",
      "X_train_stat_1980_34_20_120_w4_at_8.npy\r\n",
      "X_train_stat_1980_34_20_120_w8_at_16.npy\r\n",
      "X_train_stat_1980_34_20_120_w8_at_8.npy\r\n",
      "X_train_stat_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "X_train_stat_with_dates_columns_1980_w8_at_8.npy\r\n",
      "X_train_vision_1980_34_20_120_w12_at_8.npy\r\n",
      "X_train_vision_1980_34_20_120_w16at_16.npy\r\n",
      "X_train_vision_1980_34_20_120_w16_at_24.npy\r\n",
      "X_train_vision_1980_34_20_120_w16_at_8.npy\r\n",
      "X_train_vision_1980_34_20_120_w2_at_8.npy\r\n",
      "X_train_vision_1980_34_20_120_w4_at_16.npy\r\n",
      "X_train_vision_1980_34_20_120_w4_at_8.npy\r\n",
      "X_train_vision_1980_34_20_120_w8_at_16.npy\r\n",
      "X_train_vision_1980_34_20_120_w8_at_8.npy\r\n",
      "X_train_vision_1980_50_20_90_w12.npy\r\n",
      "X_train_vision_1980_50_20_90_w16.npy\r\n",
      "X_train_vision_1980_50_20_90_w8.npy\r\n",
      "X_train_vision_comp_1980_34_20_120.npy\r\n",
      "y_1980_34_20_120_forecast_24.npy\r\n",
      "y_1980_34_20_120_forecast_all_24.npy\r\n",
      "y_1980_34_20_120_forecast_all_48_clean.npy\r\n",
      "y_1980_34_20_120.npy\r\n",
      "y_1980_34_20_120_withforecast_2661.npy\r\n",
      "y_1980_34_20_120_withforecast.npy\r\n",
      "y_test_displacement_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_test_displacement_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_test_displacement_1980_34_20_120_w8_at_16.npy\r\n",
      "y_test_displacement_1980_34_20_120_w8_at_8.npy\r\n",
      "y_test_displacement_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_test_displacement_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_test_intensity_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_test_intensity_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_test_intensity_1980_34_20_120_w8_at_16.npy\r\n",
      "y_test_intensity_1980_34_20_120_w8_at_8.npy\r\n",
      "y_test_intensity_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_test_intensity_cat_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_test_intensity_cat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_test_intensity_cat_1980_34_20_120_w8_at_16.npy\r\n",
      "y_test_intensity_cat_1980_34_20_120_w8_at_8.npy\r\n",
      "y_test_intensity_cat_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_test_intensity_cat_baseline_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_test_intensity_cat_baseline_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_test_intensity_cat_baseline_1980_34_20_120_w8_at_16.npy\r\n",
      "y_test_intensity_cat_baseline_1980_34_20_120_w8_at_8.npy\r\n",
      "y_test_intensity_cat_baseline_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_test_intensity_cat_baseline_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_test_intensity_cat_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_test_intensity_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_train_displacement_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_train_displacement_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_train_displacement_1980_34_20_120_w8_at_16.npy\r\n",
      "y_train_displacement_1980_34_20_120_w8_at_8.npy\r\n",
      "y_train_displacement_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_train_displacement_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_train_intensity_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_train_intensity_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_train_intensity_1980_34_20_120_w8_at_16.npy\r\n",
      "y_train_intensity_1980_34_20_120_w8_at_8.npy\r\n",
      "y_train_intensity_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_train_intensity_cat_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_train_intensity_cat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_train_intensity_cat_1980_34_20_120_w8_at_16.npy\r\n",
      "y_train_intensity_cat_1980_34_20_120_w8_at_8.npy\r\n",
      "y_train_intensity_cat_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_train_intensity_cat_baseline_1980_34_20_120_forecast_24_w8_at_8.npy\r\n",
      "y_train_intensity_cat_baseline_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy\r\n",
      "y_train_intensity_cat_baseline_1980_34_20_120_w8_at_16.npy\r\n",
      "y_train_intensity_cat_baseline_1980_34_20_120_w8_at_8.npy\r\n",
      "y_train_intensity_cat_baseline_1980_34_20_120_withforecast_2661_w8_at_8.npy\r\n",
      "y_train_intensity_cat_baseline_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_train_intensity_cat_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_train_intensity_with_dates_columns_1980_w8_at_8.npy\r\n",
      "y_with_dates_1980.npy\r\n",
      "y_with_dates_columns_1980.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_24_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy', allow_pickle=True))\n",
    "\n",
    "#X_test_dates = pd.DataFrame(np.load('../data/X_test_stat_with_dates_columns_1980_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True)[:,:4])\n",
    "\n",
    "#X_test_dates.columns = ['YEAR', 'MONTH', 'DAY', 'HOUR']\n",
    "\n",
    "names_baselines = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'OFCL_24_lat', 'OFCL_24_lon', 'OFCL_24_vmax', 'OFCL_24_mslp', 'P91E_24_lat', 'P91E_24_lon', 'P91E_24_vmax', 'P91E_24_mslp', 'GFDL_24_lat', 'GFDL_24_lon', 'GFDL_24_vmax', 'GFDL_24_mslp', 'NGPS_24_lat', 'NGPS_24_lon', 'NGPS_24_vmax', 'NGPS_24_mslp', 'LBAR_24_lat', 'LBAR_24_lon', 'LBAR_24_vmax', 'LBAR_24_mslp', 'GUNS_24_lat', 'GUNS_24_lon', 'GUNS_24_vmax', 'GUNS_24_mslp', 'UKXI_24_lat', 'UKXI_24_lon', 'UKXI_24_vmax', 'UKXI_24_mslp', 'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp', 'A98E_24_lat', 'A98E_24_lon', 'A98E_24_vmax', 'A98E_24_mslp', 'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'DSHP_24_lat', 'DSHP_24_lon', 'DSHP_24_vmax', 'DSHP_24_mslp', 'FSSE_24_lat', 'FSSE_24_lon', 'FSSE_24_vmax', 'FSSE_24_mslp', 'CLP5_24_lat', 'CLP5_24_lon', 'CLP5_24_vmax', 'CLP5_24_mslp', 'AEMN_24_lat', 'AEMN_24_lon', 'AEMN_24_vmax', 'AEMN_24_mslp', 'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'GFSO_24_lat', 'GFSO_24_lon', 'GFSO_24_vmax', 'GFSO_24_mslp', 'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SA', 'basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "\n",
    "names_all_baselines = names_baselines * 8#args.window_size\n",
    "\n",
    "for i in range(len(names_all_baselines)):\n",
    "    names_all_baselines[i] += '_' + str(i // 92)\n",
    "\n",
    "X_test_baseline.columns = names_all_baselines\n",
    "\n",
    "#X_test_baseline = pd.concat([X_test_baseline, X_test_dates], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26800, 740)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EP:\n",
    "We beat: SHIP, HWRF, GFSO, AEMN, DSHP, (GFDL, UKXI, CMC)\n",
    "We lose: OFCL, FSSE\n",
    "\n",
    "AN:\n",
    "We beat: SHIP, HWRF, GFSO, AEMN, GFDL, DSHP, (UKXI, CMC) \n",
    "We lose: HWRF, OFCL, FSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.07, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "       n_estimators=150, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "       tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = X_train_total\n",
    "    #test = X_test_total\n",
    "tgt_train = tgt_intensity_train\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=1)\n",
    "xgb_total.fit(train, tgt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps 1368\n",
      "MAE intensity basin EP Hurricast :  15.04 with std  19.6\n",
      "MAE intensity basin EP Official Forecast FSSE :  15.78 with std  18.86\n",
      "MAE intensity basin EP Official Forecast OFCL :  17.37 with std  20.59\n",
      "Percentage of missed intensification > 20kn Hurricast:  28.44\n",
      "Percentage of missed intensification > 20kn Official ForecastFSSE :  29.31\n",
      "Percentage of missed intensification > 20kn Official Forecast 2OFCL :  30.41\n",
      "\n",
      "MAE intensity basin EP Hurricast last 1000 :  15.54\n",
      "MAE intensity basin EP Official Forecast FSSE :  15.6\n"
     ]
    }
   ],
   "source": [
    "compare_perf_intensity(xgb_total = xgb_total, basin='EP', forecast='FSSE', mode='vmax', forecast2 = 'OFCL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-eefc5c1222b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_xgb_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EMXI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OFCL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-cab3eb48c918>\u001b[0m in \u001b[0;36mtrain_xgb_intensity\u001b[0;34m(forecast, basin_only, sparse, max_depth, n_estimators, learning_rate, subsample, min_child_weight, basin, forecast2)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mxgb_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mcompare_perf_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.12, subsample = 0.7, min_child_weight = 5, basin = 'AN', forecast = 'HWRF') 82.14 and 117.26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-cab3eb48c918>\u001b[0m in \u001b[0;36mcompare_perf_intensity\u001b[0;34m(xgb_total, basin, forecast, last_storms, mode, forecast2)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                      \u001b[0;31m#xgb.predict(X_test_withBASELINE) * std_ + mean_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Timesteps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAE intensity basin \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Hurricast : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with std \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         print(\"MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n\u001b[1;32m    182\u001b[0m               np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 170\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 582\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "train_xgb_intensity(forecast = 'EMXI', basin_only = False, sparse = False, max_depth = 8, n_estimators = 150, learning_rate = 0.07, subsample = 0.8, min_child_weight=1, basin = 'EP', forecast2 = 'OFCL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X_train_total\n",
    "train_y = X_train_total\n",
    "test_x = X_test_total\n",
    "test_y = X_test_total\n",
    "tgt_train = tgt_displacement_train\n",
    "\n",
    "xgb_x = XGBRegressor(max_depth=7, n_estimators=90, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=7, n_estimators=90, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP: Intensity\n",
    "We beat: HWRF, SHIP, GFSO, AEMN, DSHP, (GFDL, UKXI, CMC)\n",
    "We lose: OFCL, FSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP: Track\n",
    "We beat: GFDL, CMC, CLP5\n",
    "We lose: FSSE, OFCL, SHIP, HWRF, GFSO, AEMN, DSHP (UKXI)\n",
    "    \n",
    "AN: Track\n",
    "We beat: GFDL, CMC, CLP5\n",
    "We lose: FSSE, OFCL, SHIP, HWRF, GFSO, AEMN, DSHP (UKXI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_perf_track(basin='EP', forecast='SHIP', forecast2 = 'HWRF', LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_track(basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    train_x = X_train_total\n",
    "    train_y = X_train_total\n",
    "    test_x = X_test_total\n",
    "    test_y = X_test_total\n",
    "    tgt_train = tgt_displacement_train\n",
    "    if sparse:\n",
    "        train_x, train_y = X_train_total_sparse_x, X_train_total_sparse_y\n",
    "        test_x, test_y = X_test_total_sparse_x, X_test_total_sparse_y\n",
    "    if basin_only:\n",
    "        train_x = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        train_y = train_x\n",
    "        tgt_train = tgt_displacement_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "    xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "    DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "    DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "    LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "    LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "    compare_perf_track(basin=basin, forecast=forecast, forecast2 = forecast2, LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "\n",
    "def train_xgb_track_all_years(use_forecast = False, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    train_x = X_train_total\n",
    "    train_y = X_train_total\n",
    "    test_x = X_test_total\n",
    "    test_y = X_test_total\n",
    "    tgt_train = tgt_displacement_train\n",
    "    if sparse:\n",
    "        train_x, train_y = X_train_total_sparse_x, X_train_total_sparse_y\n",
    "        test_x, test_y = X_test_total_sparse_x, X_test_total_sparse_y\n",
    "    if basin_only:\n",
    "        train_x = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        train_y = train_x\n",
    "        tgt_train = tgt_displacement_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    if use_forecast:\n",
    "        train_for = X_train_forecasts\n",
    "        tgt_train_for = tgt_train_dis_forecasts\n",
    "        test_for = X_test_forecasts\n",
    "        xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_x.fit(train_for, tgt_train_for[:, 0])\n",
    "        xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_y.fit(train_for, tgt_train_for[:, 1])\n",
    "        DLATS_PRED = np.array(xgb_x.predict(X_new)) * std_dx + mean_dx\n",
    "        DLONS_PRED = np.array(xgb_y.predict(X_new)) * std_dy + mean_dy\n",
    "    else:\n",
    "        xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "        xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "        DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "        DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "    LATS_PRED_2012 = X_test['LAT_7'] + DLATS_PRED\n",
    "    LONS_PRED_2012 = X_test['LON_7'] + DLONS_PRED\n",
    "    compare_perf_track(basin=basin, forecast=forecast, forecast2 = forecast2, LATS_PRED_=LATS_PRED_2012, LONS_PRED_=LONS_PRED_2012)\n",
    "    dict = {'year': [], 'num_samples': [], 'MAEs_full': [], 'std_full': [], 'MAES_2012': [], 'std_2012': [],\n",
    "            'MAES_SHIP': [], 'std_SHIP': [], 'MAES_HWRF': [], 'std_HWRF': []}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[\n",
    "                X_test_baseline['YEAR'] < year].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis=0)\n",
    "            tgt_train = np.concatenate((tgt_displacement_train, tgt_displacement_test[index]), axis=0)\n",
    "            xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_x.fit(train, tgt_train[:, 0])\n",
    "            xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_y.fit(train, tgt_train[:, 1])\n",
    "            DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "            DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "            LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "            LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "            compare_perf_track_per_year(dict, LATS_PRED_, LONS_PRED_, LATS_PRED_2012, LONS_PRED_2012, forecast=forecast,\n",
    "                                            forecast2=forecast2, basin=basin,  year=year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_xgb_intensity(forecast = 'SHIP', basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = None):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total.fit(train, tgt_train)\n",
    "    compare_perf_intensity(xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', forecast2 = forecast2)\n",
    "\n",
    "#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.12, subsample = 0.7, min_child_weight = 5, basin = 'AN', forecast = 'HWRF') 82.14 and 117.26\n",
    "#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.1, subsample = 0.7, min_child_weight = 5, basin = 'EP', forecast = 'HWRF')\n",
    "\n",
    "LATS_TEST = X_test['LAT_7'] + np.array(tgt_displacement_test[:,0])*std_dx+mean_dx\n",
    "LONS_TEST = X_test['LON_7'] + np.array(tgt_displacement_test[:,1])*std_dy+mean_dy\n",
    "\n",
    "def compare_perf_track(LATS_PRED_, LONS_PRED_, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    LATS_TEST_ = X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx\n",
    "    LONS_TEST_ = X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy\n",
    "    baseline_1_x = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_1_y = baseline_[forecast + '_24_lon_7']\n",
    "    LATS_BASE = np.array(baseline_1_x)\n",
    "    LONS_BASE = np.array(baseline_1_y)\n",
    "    LATS_TEST_ = np.array(LATS_TEST_[index])\n",
    "    LONS_TEST_ = np.array(LONS_TEST_[index])\n",
    "    LATS_PRED_ = np.array(LATS_PRED_[index])\n",
    "    LONS_PRED_ = np.array(LONS_PRED_[index])\n",
    "    d_km_baseline = np.zeros(len(LATS_BASE))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_BASE))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    for i in range(len(LATS_BASE)):\n",
    "        d_km_baseline[i] = get_distance_km(LONS_BASE[i], LATS_BASE[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        if forecast2 != None:\n",
    "            d_km_baseline2[i] = get_distance_km(LONS_BASE_2[i], LATS_BASE_2[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Number of timesteps:\", len(LATS_BASE))\n",
    "    print(basin, 'Model | MAE | std')\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2))\n",
    "    print(str(forecast2), np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2))\n",
    "    print(\"Hurricast\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2))\n",
    "    print(\"\\nModel | Number of Busts > 200km | Percentage Bust\")\n",
    "    print(forecast, sum(d_km_baseline > 200), np.around(sum(d_km_baseline > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    print(str(forecast2), sum(d_km_baseline2 > 200), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_BASE), decimals =2))\n",
    "    print(\"Hurricast\", sum(d_km_pred > 200), np.around(sum(d_km_pred > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "\n",
    "\n",
    "\n",
    "def compare_perf_intensity(xgb_total, basin = 'AN', forecast = 'SHIP', last_storms = 1000, mode = 'vmax', forecast2 = 'HWRF'):\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    else:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    X_test_withBASELINE_total = X_test_total[index]\n",
    "    baseline_1 = baseline_[forecast + '_24_' + mode + '_7']\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Timesteps\", len(tgt_))\n",
    "        print(\"MAE intensity basin \" + basin + \" Hurricast : \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds), decimals=2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \" + str(forecast2) + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_2), decimals=2), \"with std \",\n",
    "              np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "        print(\"Percentage of missed intensification > 20kn Hurricast: \", np.around(sum(abs(tgt_ - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(\"Percentage of missed intensification > 20kn Official Forecast\"+ forecast + \" : \", np.around(sum(abs(tgt_ - baseline_1) > 20) / len(baseline_1) * 100, decimals =2))\n",
    "        print(\"Percentage of missed intensification > 20kn Official Forecast 2\"+ str(forecast2) + \" : \", np.around(sum(abs(tgt_ - baseline_2) > 20) / len(baseline_2) * 100, decimals =2))\n",
    "        print(\"\\nMAE intensity basin \" + basin + \" Hurricast last\", last_storms, \": \", np.around(mean_absolute_error(tgt_[-last_storms:], preds[-last_storms:]), decimals=2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \" + forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_[-last_storms:], baseline_1[-last_storms:]), decimals=2))\n",
    "\n",
    "\n",
    "#train_xgb_intensity(forecast = 'SHIP', basin = 'EP', max_depth=8, n_estimators = 120, learning_rate = 0.07, subsample = 0.8, min_child_weight = 1)\n",
    "#train_xgb_intensity(forecast = 'SHIP', basin = 'AN', max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.8, min_child_weight = 1, forecast2 = 'HWRF')\n",
    "\n",
    "\n",
    "def compare_perf_intensity_per_year(dict, xgb_tot, xgb_total, year, forecast2, basin = 'AN', forecast = 'HWRF', mode = 'vmax'):\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        #X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    X_test_withBASELINE_total = X_test_total[index]\n",
    "    baseline_1 = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        print(\"Total number of steps for comparison: \", len(tgt_))\n",
    "        preds_1 = xgb_tot.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Hurricast trained full: \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds), decimals=2))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Hurricast trained until 2012: \", np.around(mean_absolute_error(tgt_, preds_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "        if forecast2 != None:\n",
    "            print(\"Year \", year, \" MAE intensity basin \" + basin + \" Official Forecast \" + forecast2 + \" : \",\n",
    "                np.around(mean_absolute_error(tgt_, baseline_2), decimals=2), \"with std \",\n",
    "                np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "        append_dict_intensity(dict, tgt_, preds, preds_1, baseline_1, baseline_2, year)\n",
    "        #print(\"Year \", year, \" Percentage of missed intensification > 20kn Hurricast: \", np.around(sum(tgt_ - preds > 20)/len(preds) * 100, decimals = 2))\n",
    "        #print(\"Year \", year, \" Percentage of missed intensification > 20kn Official Forecast: \", np.around(sum(tgt_ - baseline_1 > 20) / len(baseline_1) * 100, decimals =2))\n",
    "\n",
    "\n",
    "def compare_perf_track_per_year(dict, LATS_PRED_, LONS_PRED_, LATS_PRED_2012, LONS_PRED_2012, year, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    LATS_TEST_ = X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx\n",
    "    LONS_TEST_ = X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy\n",
    "    baseline_1_x = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_1_y = baseline_[forecast + '_24_lon_7']\n",
    "    LATS_BASE = np.array(baseline_1_x)\n",
    "    LONS_BASE = np.array(baseline_1_y)\n",
    "    LATS_TEST_ = np.array(LATS_TEST_[index])\n",
    "    LONS_TEST_ = np.array(LONS_TEST_[index])\n",
    "    LATS_PRED_ = np.array(LATS_PRED_[index])\n",
    "    LONS_PRED_ = np.array(LONS_PRED_[index])\n",
    "    LATS_PRED_2012 = np.array(LATS_PRED_2012[index])\n",
    "    LONS_PRED_2012 = np.array(LONS_PRED_2012[index])\n",
    "    d_km_baseline = np.zeros(len(LATS_BASE))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_BASE))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    d_km_pred_2012 = np.zeros(len(LONS_PRED_))\n",
    "    for i in range(len(LATS_BASE)):\n",
    "        d_km_baseline[i] = get_distance_km(LONS_BASE[i], LATS_BASE[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred_2012[i] = get_distance_km(LONS_PRED_2012[i], LATS_PRED_2012[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        if forecast2 != None:\n",
    "            d_km_baseline2[i] = get_distance_km(LONS_BASE_2[i], LATS_BASE_2[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Year\", year, \"Number of timesteps:\", len(LATS_BASE))\n",
    "    print(basin, 'Model | MAE | std')\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2))\n",
    "    print(str(forecast2), np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2))\n",
    "    print(\"Hurricast Max Data\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2))\n",
    "    print(\"Hurricast Until 2012\", np.around(d_km_pred_2012.mean(), decimals=2), np.around(d_km_pred_2012.std(), decimals=2))\n",
    "    print(\"\\nModel | Number of Busts > 200km | Percentage Bust\")\n",
    "    print(forecast, sum(d_km_baseline > 200), np.around(sum(d_km_baseline > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    print(str(forecast2), sum(d_km_baseline2 > 200), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_BASE), decimals =2))\n",
    "    print(\"Hurricast\", sum(d_km_pred > 200), np.around(sum(d_km_pred > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    append_dict_track(dict, d_km_baseline, d_km_baseline2, d_km_pred, d_km_pred_2012, year)\n",
    "\n",
    "def append_dict_track(dict, d_km_baseline, d_km_baseline2, d_km_pred, d_km_pred_2012, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(d_km_baseline))\n",
    "    dict['MAEs_full'].append(np.around(d_km_pred.mean(), decimals = 2))\n",
    "    dict['std_full'].append(np.around(d_km_pred.std(), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(d_km_pred_2012.mean(), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(d_km_pred_2012.std(), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(d_km_baseline.mean(), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(d_km_baseline.std(), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(d_km_baseline2.mean(), decimals =2))\n",
    "    dict['std_HWRF'].append(np.around(d_km_baseline2.std(), decimals=2))\n",
    "\n",
    "def append_dict_intensity(dict, tgt_, preds, preds_1, baseline_1, baseline_2, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(tgt_))\n",
    "    dict['MAEs_full'].append(np.around(mean_absolute_error(tgt_, preds), decimals = 2))\n",
    "    dict['std_full'].append(np.around(np.std(tgt_ - preds), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(mean_absolute_error(tgt_, preds_1), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(mean_absolute_error(tgt_, baseline_2), decimals=2))\n",
    "    dict['std_HWRF'].append(np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "\n",
    "\n",
    "def train_xgb_intensity_all_years(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total.fit(train, tgt_train)\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            compare_perf_intensity_per_year(forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "\n",
    "def train_xgb_intensity_all_years_full_train(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total_1 = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total_1.fit(train, tgt_train)\n",
    "    dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[]}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[X_test_baseline['YEAR'] < year].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis = 0)\n",
    "            tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[index]), axis = 0)\n",
    "            xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                     subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_total.fit(train, tgt_train)\n",
    "            compare_perf_intensity_per_year(dict = dict, xgb_tot = xgb_total_1, forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
