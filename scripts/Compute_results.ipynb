{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"../\")\n",
    "from src import prepro, metrics, run, setup\n",
    "import src.models.factory as model_factory\n",
    "import config\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from src.utils import models\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from src.utils.data_processing import *\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#args = setup.create_setup()\n",
    "#args.mode = 'displacement'\n",
    "#args.full_encoder = True\n",
    "#args.encoder_config = 'full_encoder_config'\n",
    "#args.decoder_config = 'lstm_config'\n",
    "window_size = 8\n",
    "predict_at = 8\n",
    "#args.target_intensity_cat = False\n",
    "#args.sub_window_size = 8\n",
    "#args.sub_area = 1\n",
    "#args.output_dir = '../results/results8_16_20_44_28' #''../results/results8_16_18_57_7' best so far\n",
    "#try: ../results/results8_16_20_44_28, 0.086 from training\n",
    "#Reached 70.4 and the best results with combination. 7.47 GRU outputs 64. All rest normal.\n",
    "#args.output_dir = './results/results7_20_17_12_19' #Be careful to change 2304 for intermediary layer\n",
    "#args.output_dir = './results/results7_20_15_4_36' : best for acc 70.5 and nearly best for intensiy 7.50\n",
    "#args. = ./results/results8_12_19_5_42 for best perf t+48h\n",
    "\n",
    "#if args.sub_area > 0:\n",
    "    #x_viz_train = x_viz_train[:, :, :, args.sub_area:-args.sub_area, args.sub_area:-args.sub_area]\n",
    "    #x_viz_test = x_viz_test[:, :, :, args.sub_area:-args.sub_area, args.sub_area:-args.sub_area]\n",
    "\n",
    "tgt_intensity_cat_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                      allow_pickle=True))\n",
    "tgt_intensity_cat_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "\n",
    "tgt_intensity_train = torch.Tensor(np.load('../data/y_train_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                  allow_pickle=True))\n",
    "tgt_intensity_test = torch.Tensor(np.load('../data/y_test_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                 allow_pickle=True))\n",
    "\n",
    "tgt_intensity_cat_baseline_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',  allow_pickle = True))\n",
    "tgt_intensity_cat_baseline_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train_unst = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test_unst = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "\n",
    "mean_intensity = tgt_intensity_train.mean()\n",
    "std_intensity = tgt_intensity_train.std()\n",
    "tgt_intensity_train = (tgt_intensity_train - mean_intensity)/std_intensity\n",
    "tgt_intensity_test = (tgt_intensity_test - mean_intensity)/std_intensity\n",
    "\n",
    "\n",
    "###INTENSITY\n",
    "mean_dx = tgt_displacement_train[:,0].mean()\n",
    "std_dx = tgt_displacement_train[:,0].std()\n",
    "tgt_displacement_train[:,0] = (tgt_displacement_train[:,0] - mean_dx)/std_dx\n",
    "tgt_displacement_test[:,0] = (tgt_displacement_test[:,0] - mean_dx)/std_dx\n",
    "std_dx = float(std_dx)\n",
    "mean_dx = float(mean_dx)\n",
    "\n",
    "mean_dy = tgt_displacement_train[:,1].mean()\n",
    "std_dy = tgt_displacement_train[:,1].std()\n",
    "tgt_displacement_train[:,1] = (tgt_displacement_train[:,1] - mean_dy)/std_dy\n",
    "tgt_displacement_test[:,1] = (tgt_displacement_test[:,1] - mean_dy)/std_dy\n",
    "std_dy = float(std_dy)\n",
    "mean_dy = float(mean_dy)\n",
    "\n",
    "def standardize(tgt_displacement_train, tgt_displacement_test):\n",
    "    mean_dx = tgt_displacement_train[:, 0].mean()\n",
    "    std_dx = tgt_displacement_train[:, 0].std()\n",
    "    tgt_displacement_train[:, 0] = (tgt_displacement_train[:, 0] - mean_dx) / std_dx\n",
    "    tgt_displacement_test[:, 0] = (tgt_displacement_test[:, 0] - mean_dx) / std_dx\n",
    "    std_dx = float(std_dx)\n",
    "    mean_dx = float(mean_dx)\n",
    "    mean_dy = tgt_displacement_train[:, 1].mean()\n",
    "    std_dy = tgt_displacement_train[:, 1].std()\n",
    "    tgt_displacement_train[:, 1] = (tgt_displacement_train[:, 1] - mean_dy) / std_dy\n",
    "    tgt_displacement_test[:, 1] = (tgt_displacement_test[:, 1] - mean_dy) / std_dy\n",
    "    std_dy = float(std_dy)\n",
    "    mean_dy = float(mean_dy)\n",
    "    return tgt_displacement_train, tgt_displacement_test, std_dx, mean_dx, std_dy, mean_dy\n",
    "\n",
    "def unstandardize(tgt_displacement_train, tgt_displacement_test, std_dx, mean_dx, std_dy, mean_dy):\n",
    "    tgt_displacement_train[:, 0] = tgt_displacement_train[:, 0] *  std_dx + mean_dx\n",
    "    tgt_displacement_test[:, 0] = tgt_displacement_test[:, 0] *  std_dx + mean_dx\n",
    "    tgt_displacement_train[:, 1] = tgt_displacement_train[:, 1] * std_dy + mean_dy\n",
    "    tgt_displacement_test[:, 1] = tgt_displacement_test[:, 1] * std_dy + mean_dy\n",
    "    return tgt_displacement_train, tgt_displacement_test\n",
    "\n",
    "\n",
    "##########\n",
    "##########\n",
    "########## PREPARING DATA FOR XGB\n",
    "\n",
    "X_train = np.load('../data/X_train_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "X_test = np.load('../data/X_test_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'cat_cos_day', 'cat_sign_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
    "         'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'cat_storm_category', 'cat_basin_AN',\n",
    "         'cat_basin_EP', 'cat_basin_NI', 'cat_basin_SA',\n",
    "         'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "         'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "         'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i // 30)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-2:] == '_0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]\n",
    "\n",
    "\n",
    "std_ = float(std_intensity)\n",
    "mean_ = float(mean_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_embed = np.load('../data/embeddings/X_train_embeds_1980_34_20_120_results8_16_20_44_28.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embeds_1980_34_20_120_results8_16_20_44_28.npy', allow_pickle = True)\n",
    "X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity.npy', allow_pickle = True)\n",
    "X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity.npy', allow_pickle = True)\n",
    "\n",
    "#48\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "\n",
    "X_train_total = np.concatenate((X_train, X_train_embed), axis = 1)\n",
    "X_test_total = np.concatenate((X_test, X_test_embed), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107199, 512)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  7.8533998\n",
      "MAE intensity:  7.4758453\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBRegressor(max_depth=6, n_estimators=140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "xgb2.fit(X_train, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb2.predict(X_test))*std_+mean_))\n",
    "\n",
    "xgb = XGBRegressor(max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight = 1)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  7.6953325\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 100, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "xgb.fit(X_train_embed, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_embed))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  7.4689264\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 100, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  11.97465\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 140, learning_rate = 0.07, subsample = 0.8)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_24_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "#X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy', allow_pickle=True))\n",
    "\n",
    "X_test_dates = pd.DataFrame(np.load('../data/X_test_stat_with_dates_columns_1980_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True)[:,:4])\n",
    "\n",
    "X_test_dates.columns = ['YEAR', 'MONTH', 'DAY', 'HOUR']\n",
    "\n",
    "names_baselines = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'OFCL_24_lat', 'OFCL_24_lon', 'OFCL_24_vmax', 'OFCL_24_mslp', 'P91E_24_lat', 'P91E_24_lon', 'P91E_24_vmax', 'P91E_24_mslp', 'GFDL_24_lat', 'GFDL_24_lon', 'GFDL_24_vmax', 'GFDL_24_mslp', 'NGPS_24_lat', 'NGPS_24_lon', 'NGPS_24_vmax', 'NGPS_24_mslp', 'LBAR_24_lat', 'LBAR_24_lon', 'LBAR_24_vmax', 'LBAR_24_mslp', 'GUNS_24_lat', 'GUNS_24_lon', 'GUNS_24_vmax', 'GUNS_24_mslp', 'UKXI_24_lat', 'UKXI_24_lon', 'UKXI_24_vmax', 'UKXI_24_mslp', 'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp', 'A98E_24_lat', 'A98E_24_lon', 'A98E_24_vmax', 'A98E_24_mslp', 'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'DSHP_24_lat', 'DSHP_24_lon', 'DSHP_24_vmax', 'DSHP_24_mslp', 'FSSE_24_lat', 'FSSE_24_lon', 'FSSE_24_vmax', 'FSSE_24_mslp', 'CLP5_24_lat', 'CLP5_24_lon', 'CLP5_24_vmax', 'CLP5_24_mslp', 'AEMN_24_lat', 'AEMN_24_lon', 'AEMN_24_vmax', 'AEMN_24_mslp', 'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'GFSO_24_lat', 'GFSO_24_lon', 'GFSO_24_vmax', 'GFSO_24_mslp', 'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SA', 'basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "\n",
    "names_all_baselines = names_baselines * 8#args.window_size\n",
    "\n",
    "for i in range(len(names_all_baselines)):\n",
    "    names_all_baselines[i] += '_' + str(i // 92)\n",
    "\n",
    "X_test_baseline.columns = names_all_baselines\n",
    "\n",
    "#X_test_baseline = pd.concat([X_test_baseline, X_test_dates], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_24_2012_v2_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "#X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_48_2012_v2_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "\n",
    "names_baselines = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'GFDL_24_lat', 'GFDL_24_lon', 'GFDL_24_vmax', 'GFDL_24_mslp', 'GFDL_24_COS_LAT', 'GFDL_24_SIN_LAT', 'GFDL_24_COS_LON', 'GFDL_24_SIN_LON', 'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'CMC_24_COS_LAT', 'CMC_24_SIN_LAT', 'CMC_24_COS_LON', 'CMC_24_SIN_LON', 'FSSE_24_lat', 'FSSE_24_lon', 'FSSE_24_vmax', 'FSSE_24_mslp', 'FSSE_24_COS_LAT', 'FSSE_24_SIN_LAT', 'FSSE_24_COS_LON', 'FSSE_24_SIN_LON', 'OFCL_24_lat', 'OFCL_24_lon', 'OFCL_24_vmax', 'OFCL_24_mslp', 'OFCL_24_COS_LAT', 'OFCL_24_SIN_LAT', 'OFCL_24_COS_LON', 'OFCL_24_SIN_LON', 'NGPS_24_lat', 'NGPS_24_lon', 'NGPS_24_vmax', 'NGPS_24_mslp', 'NGPS_24_COS_LAT', 'NGPS_24_SIN_LAT', 'NGPS_24_COS_LON', 'NGPS_24_SIN_LON', 'DSHP_24_lat', 'DSHP_24_lon', 'DSHP_24_vmax', 'DSHP_24_mslp', 'DSHP_24_COS_LAT', 'DSHP_24_SIN_LAT', 'DSHP_24_COS_LON', 'DSHP_24_SIN_LON', 'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'SHIP_24_COS_LAT', 'SHIP_24_SIN_LAT', 'SHIP_24_COS_LON', 'SHIP_24_SIN_LON', 'CLP5_24_lat', 'CLP5_24_lon', 'CLP5_24_vmax', 'CLP5_24_mslp', 'CLP5_24_COS_LAT', 'CLP5_24_SIN_LAT', 'CLP5_24_COS_LON', 'CLP5_24_SIN_LON', 'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'HWRF_24_COS_LAT', 'HWRF_24_SIN_LAT', 'HWRF_24_COS_LON', 'HWRF_24_SIN_LON', 'UKXI_24_lat', 'UKXI_24_lon', 'UKXI_24_vmax', 'UKXI_24_mslp', 'UKXI_24_COS_LAT', 'UKXI_24_SIN_LAT', 'UKXI_24_COS_LON', 'UKXI_24_SIN_LON', 'LBAR_24_lat', 'LBAR_24_lon', 'LBAR_24_vmax', 'LBAR_24_mslp', 'LBAR_24_COS_LAT', 'LBAR_24_SIN_LAT', 'LBAR_24_COS_LON', 'LBAR_24_SIN_LON', 'AEMN_24_lat', 'AEMN_24_lon', 'AEMN_24_vmax', 'AEMN_24_mslp', 'AEMN_24_COS_LAT', 'AEMN_24_SIN_LAT', 'AEMN_24_COS_LON', 'AEMN_24_SIN_LON', 'DISPLACEMENT_LAT_CLP5_24', 'DISPLACEMENT_LON_CLP5_24', 'DISPLACEMENT_LAT_SHIP_24', 'DISPLACEMENT_LON_SHIP_24', 'DISPLACEMENT_LAT_DSHP_24', 'DISPLACEMENT_LON_DSHP_24', 'DISPLACEMENT_LAT_LBAR_24', 'DISPLACEMENT_LON_LBAR_24', 'DISPLACEMENT_LAT_CMC_24', 'DISPLACEMENT_LON_CMC_24', 'DISPLACEMENT_LAT_NGPS_24', 'DISPLACEMENT_LON_NGPS_24', 'DISPLACEMENT_LAT_GFDL_24', 'DISPLACEMENT_LON_GFDL_24', 'DISPLACEMENT_LAT_HWRF_24', 'DISPLACEMENT_LON_HWRF_24', 'DISPLACEMENT_LAT_UKXI_24', 'DISPLACEMENT_LON_UKXI_24', 'DISPLACEMENT_LAT_FSSE_24', 'DISPLACEMENT_LON_FSSE_24', 'DISPLACEMENT_LAT_AEMN_24', 'DISPLACEMENT_LON_AEMN_24', 'DISPLACEMENT_LAT_OFCL_24', 'DISPLACEMENT_LON_OFCL_24', 'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp', 'EMXI_24_COS_LAT', 'EMXI_24_SIN_LAT', 'EMXI_24_COS_LON', 'EMXI_24_SIN_LON', 'DISPLACEMENT_LAT_EMXI_24', 'DISPLACEMENT_LON_EMXI_24', 'GFSO_24_lat', 'GFSO_24_lon', 'GFSO_24_vmax', 'GFSO_24_mslp', 'GFSO_24_COS_LAT', 'GFSO_24_SIN_LAT', 'GFSO_24_COS_LON', 'GFSO_24_SIN_LON', 'DISPLACEMENT_LAT_GFSO_24', 'DISPLACEMENT_LON_GFSO_24', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SI', 'basin_SP', 'basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "#names_baselines = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'DSHP_24_lat', 'DSHP_24_lon', 'DSHP_24_vmax', 'DSHP_24_mslp', 'DSHP_24_COS_LAT', 'DSHP_24_SIN_LAT', 'DSHP_24_COS_LON', 'DSHP_24_SIN_LON', 'OFCL_24_lat', 'OFCL_24_lon', 'OFCL_24_vmax', 'OFCL_24_mslp', 'OFCL_24_COS_LAT', 'OFCL_24_SIN_LAT', 'OFCL_24_COS_LON', 'OFCL_24_SIN_LON', 'UKXI_24_lat', 'UKXI_24_lon', 'UKXI_24_vmax', 'UKXI_24_mslp', 'UKXI_24_COS_LAT', 'UKXI_24_SIN_LAT', 'UKXI_24_COS_LON', 'UKXI_24_SIN_LON', 'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'CMC_24_COS_LAT', 'CMC_24_SIN_LAT', 'CMC_24_COS_LON', 'CMC_24_SIN_LON', 'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'SHIP_24_COS_LAT', 'SHIP_24_SIN_LAT', 'SHIP_24_COS_LON', 'SHIP_24_SIN_LON', 'FSSE_24_lat', 'FSSE_24_lon', 'FSSE_24_vmax', 'FSSE_24_mslp', 'FSSE_24_COS_LAT', 'FSSE_24_SIN_LAT', 'FSSE_24_COS_LON', 'FSSE_24_SIN_LON', 'CLP5_24_lat', 'CLP5_24_lon', 'CLP5_24_vmax', 'CLP5_24_mslp', 'CLP5_24_COS_LAT', 'CLP5_24_SIN_LAT', 'CLP5_24_COS_LON', 'CLP5_24_SIN_LON', 'AEMN_24_lat', 'AEMN_24_lon', 'AEMN_24_vmax', 'AEMN_24_mslp', 'AEMN_24_COS_LAT', 'AEMN_24_SIN_LAT', 'AEMN_24_COS_LON', 'AEMN_24_SIN_LON', 'LBAR_24_lat', 'LBAR_24_lon', 'LBAR_24_vmax', 'LBAR_24_mslp', 'LBAR_24_COS_LAT', 'LBAR_24_SIN_LAT', 'LBAR_24_COS_LON', 'LBAR_24_SIN_LON', 'GFDL_24_lat', 'GFDL_24_lon', 'GFDL_24_vmax', 'GFDL_24_mslp', 'GFDL_24_COS_LAT', 'GFDL_24_SIN_LAT', 'GFDL_24_COS_LON', 'GFDL_24_SIN_LON', 'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'HWRF_24_COS_LAT', 'HWRF_24_SIN_LAT', 'HWRF_24_COS_LON', 'HWRF_24_SIN_LON', 'NGPS_24_lat', 'NGPS_24_lon', 'NGPS_24_vmax', 'NGPS_24_mslp', 'NGPS_24_COS_LAT', 'NGPS_24_SIN_LAT', 'NGPS_24_COS_LON', 'NGPS_24_SIN_LON', 'DISPLACEMENT_LAT_CLP5_24', 'DISPLACEMENT_LON_CLP5_24', 'DISPLACEMENT_LAT_SHIP_24', 'DISPLACEMENT_LON_SHIP_24', 'DISPLACEMENT_LAT_DSHP_24', 'DISPLACEMENT_LON_DSHP_24', 'DISPLACEMENT_LAT_LBAR_24', 'DISPLACEMENT_LON_LBAR_24', 'DISPLACEMENT_LAT_CMC_24', 'DISPLACEMENT_LON_CMC_24', 'DISPLACEMENT_LAT_NGPS_24', 'DISPLACEMENT_LON_NGPS_24', 'DISPLACEMENT_LAT_GFDL_24', 'DISPLACEMENT_LON_GFDL_24', 'DISPLACEMENT_LAT_HWRF_24', 'DISPLACEMENT_LON_HWRF_24', 'DISPLACEMENT_LAT_UKXI_24', 'DISPLACEMENT_LON_UKXI_24', 'DISPLACEMENT_LAT_FSSE_24', 'DISPLACEMENT_LON_FSSE_24', 'DISPLACEMENT_LAT_AEMN_24', 'DISPLACEMENT_LON_AEMN_24', 'DISPLACEMENT_LAT_OFCL_24', 'DISPLACEMENT_LON_OFCL_24', 'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp', 'EMXI_24_COS_LAT', 'EMXI_24_SIN_LAT', 'EMXI_24_COS_LON', 'EMXI_24_SIN_LON', 'DISPLACEMENT_LAT_EMXI_24', 'DISPLACEMENT_LON_EMXI_24', 'GFSO_24_lat', 'GFSO_24_lon', 'GFSO_24_vmax', 'GFSO_24_mslp', 'GFSO_24_COS_LAT', 'GFSO_24_SIN_LAT', 'GFSO_24_COS_LON', 'GFSO_24_SIN_LON', 'DISPLACEMENT_LAT_GFSO_24', 'DISPLACEMENT_LON_GFSO_24', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SI', 'basin_SP', 'basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "names_all_baselines = names_baselines * 8#args.window_size\n",
    "\n",
    "for i in range(len(names_all_baselines)):\n",
    "    names_all_baselines[i] += '_' + str(i // 167)\n",
    "\n",
    "X_test_baseline.columns = names_all_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = X_test_baseline.shape[0]\n",
    "X_test_total = X_test_total[-n:]\n",
    "tgt_intensity_test = tgt_intensity_test[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26800, 740)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EP:\n",
    "We beat: SHIP, HWRF, GFSO, AEMN, DSHP, (GFDL, UKXI, CMC)\n",
    "We lose: OFCL, FSSE\n",
    "\n",
    "AN:\n",
    "We beat: SHIP, HWRF, GFSO, AEMN, GFDL, DSHP, (UKXI, CMC) \n",
    "We lose: HWRF, OFCL, FSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints='',\n",
       "       learning_rate=0.07, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "       n_estimators=150, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "       tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = X_train_total\n",
    "    #test = X_test_total\n",
    "tgt_train = tgt_intensity_train\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=1)\n",
    "xgb_total.fit(train, tgt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total2 = X_test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21770, 1336)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total = X_test_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17416, 1336)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AN: 11.81 | 11.94 XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=7)\n",
    "EP: 12.39 XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN: 11.86, XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=7)\n",
    "EP: 11.97, XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=7)\n",
    "    \n",
    "    (XGBRegressor(max_depth=9, n_estimators=120, learning_rate=0.05, subsample=0.8, min_child_weight=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  10.510416\n",
      "Int64Index([18036, 18038, 18040, 18042, 18044, 18046, 18048, 18050, 18106,\n",
      "            18108,\n",
      "            ...\n",
      "            21227, 21229, 21231, 21233, 21235, 21237, 21239, 21241, 21243,\n",
      "            21245],\n",
      "           dtype='int64', length=379)\n",
      "Total number of steps for comparison:  379\n",
      "Year  2018  MAE intensity basin AN Hurricast trained full:  12.14 with std  16.58\n",
      "Year  2018  MAE intensity basin AN Hurricast trained until 2012:  12.02 with std  16.58\n",
      "Year  2018  MAE intensity basin AN Official Forecast SHIP :  15.88 with std  19.79\n",
      "Year  2018  MAE intensity basin AN Official Forecast HWRF :  12.04 with std  16.87\n",
      "Year  2018  MAE intensity basin AN Official Forecast OFCL :  11.02 with std  15.46\n",
      "Year  2018  MAE intensity basin AN Official Forecast FSSE :  11.42 with std  15.22\n",
      "Int64Index([20395, 20397, 20399, 20401, 20403, 20405, 20407, 20409, 20411,\n",
      "            20413,\n",
      "            ...\n",
      "            21227, 21229, 21231, 21233, 21235, 21237, 21239, 21241, 21243,\n",
      "            21245],\n",
      "           dtype='int64', length=179)\n",
      "Total number of steps for comparison:  179\n",
      "Year  2019  MAE intensity basin AN Hurricast trained full:  12.44 with std  16.25\n",
      "Year  2019  MAE intensity basin AN Hurricast trained until 2012:  12.33 with std  16.21\n",
      "Year  2019  MAE intensity basin AN Official Forecast SHIP :  15.48 with std  18.51\n",
      "Year  2019  MAE intensity basin AN Official Forecast HWRF :  12.3 with std  16.36\n",
      "Year  2019  MAE intensity basin AN Official Forecast OFCL :  10.31 with std  13.26\n",
      "Year  2019  MAE intensity basin AN Official Forecast FSSE :  10.07 with std  12.78\n",
      "Int64Index([17805, 17807, 17809, 17811, 17813, 17815, 17817, 17819, 17821,\n",
      "            17823,\n",
      "            ...\n",
      "            20646, 20648, 20650, 20652, 20654, 20656, 20658, 20660, 20662,\n",
      "            20664],\n",
      "           dtype='int64', length=352)\n",
      "Total number of steps for comparison:  352\n",
      "Year  2018  MAE intensity basin EP Hurricast trained full:  11.97 with std  15.79\n",
      "Year  2018  MAE intensity basin EP Hurricast trained until 2012:  12.29 with std  16.01\n",
      "Year  2018  MAE intensity basin EP Official Forecast SHIP :  18.16 with std  22.0\n",
      "Year  2018  MAE intensity basin EP Official Forecast HWRF :  12.95 with std  17.4\n",
      "Year  2018  MAE intensity basin EP Official Forecast OFCL :  13.47 with std  17.63\n",
      "Year  2018  MAE intensity basin EP Official Forecast FSSE :  13.66 with std  17.52\n",
      "Int64Index([20518, 20520, 20522, 20524, 20526, 20528, 20530, 20532, 20536,\n",
      "            20538, 20540, 20542, 20544, 20546, 20548, 20550, 20552, 20554,\n",
      "            20556, 20558, 20560, 20562, 20636, 20638, 20640, 20642, 20644,\n",
      "            20646, 20648, 20650, 20652, 20654, 20656, 20658, 20660, 20662,\n",
      "            20664],\n",
      "           dtype='int64')\n",
      "Total number of steps for comparison:  37\n",
      "Year  2019  MAE intensity basin EP Hurricast trained full:  8.48 with std  7.34\n",
      "Year  2019  MAE intensity basin EP Hurricast trained until 2012:  10.46 with std  8.71\n",
      "Year  2019  MAE intensity basin EP Official Forecast SHIP :  23.69 with std  19.81\n",
      "Year  2019  MAE intensity basin EP Official Forecast HWRF :  16.01 with std  17.82\n",
      "Year  2019  MAE intensity basin EP Official Forecast OFCL :  21.23 with std  19.8\n",
      "Year  2019  MAE intensity basin EP Official Forecast FSSE :  20.76 with std  19.16\n"
     ]
    }
   ],
   "source": [
    "m = int(0.777*n)\n",
    "train2 = X_test_baseline[:m]\n",
    "    #test = X_test_total\n",
    "tgt_train2 = tgt_intensity_test[:m]\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=10, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=7)\n",
    "xgb_total.fit(np.array(train3), tgt_train2)\n",
    "xgb_tot = XGBRegressor(max_depth=10, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=5)\n",
    "xgb_tot.fit(np.array(train3), tgt_train2)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test[m:])*std_+mean_, np.array(xgb_total.predict(X_test_total[m:]))*std_+mean_))\n",
    "\n",
    "compare_perf_intensity_per_year_4cast(dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_tot, basin='AN', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2018)\n",
    "compare_perf_intensity_per_year_4cast(dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_tot, basin='AN', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2019)\n",
    "compare_perf_intensity_per_year_4cast(dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_tot, basin='EP', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2018)\n",
    "compare_perf_intensity_per_year_4cast(dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_tot, basin='EP', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = X_test_embed[-n:]\n",
    "train3 = np.concatenate((train2, t[:m]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total = np.concatenate((X_test_total, t), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.913044, 34.826088, 34.739132, 34.652172, 34.565216, 34.47826 ,\n",
       "       34.391304, 34.304348, 34.130436, 34.04348 , 33.95652 , 33.869564,\n",
       "       33.782608, 33.695652, 33.608696, 33.52174 , 33.434784, 33.347828,\n",
       "       33.260868, 33.173912, 33.086956, 33.      , 45.833332, 45.43651 ,\n",
       "       45.039684, 44.642857, 44.246033, 43.849205, 43.45238 , 43.055557,\n",
       "       42.65873 , 42.261906, 41.865078, 41.468254, 41.07143 , 40.674603,\n",
       "       40.27778 ], dtype=float32)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = 'vmax'\n",
    "forecast = 'SHIP'\n",
    "forecast2 = 'HWRF'\n",
    "forecast3 = 'OFCL'\n",
    "forecast4 = 'FSSE'\n",
    "year = 2019\n",
    "basin = 'EP'\n",
    "baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "index = baseline_.index\n",
    "baseline_1 = baseline_[forecast + '_24_'+mode+'_7']\n",
    "baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "baseline_3 = baseline_[forecast3 + '_24_' + mode + '_7']\n",
    "baseline_4 = baseline_[forecast4 + '_24_' + mode + '_7']\n",
    "X_test_withBASELINE_total = X_test_total[index]\n",
    "X_test_withBASELINE_total[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35. ,  35. ,  35. ,  37.5,  42.5,  45. ,  47.5,  52.5,  57.5,\n",
       "        62.5,  67.5,  72.5,  77.5,  80. ,  80. ,  77.5,  37.5,  40. ,\n",
       "        40. ,  42.5,  50. ,  60. ,  70. ,  75. ,  85. , 100. ,  95. ,\n",
       "        92.5,  82.5,  72.5,  67.5,  65. ,  62.5,  60. ,  65. ,  70. ,\n",
       "        67.5], dtype=float32)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40. ,  32.5,  30. ,  30. ,  30. ,  30. ,  30. ,  27.5,  25. ,\n",
       "       110. , 105. ,  95. ,  85. ,  75. ,  65. ,  55. ,  50. ,  45. ,\n",
       "        40. ,  40. ,  35. ,  30. ,  45. ,  45. ,  45. ,  45. ,  40. ,\n",
       "        40. ,  35. ,  35. ,  40. ,  40. ,  35. ,  35. ,  35. ,  30. ,\n",
       "        30. ,  35. ,  35. ,  30. ,  30. ,  30. ,  30. ,  25. ,  30. ,\n",
       "        25. ,  25. ,  40. ,  40. ,  40. ,  40. ,  35. ,  35. ,  35. ,\n",
       "        35. ,  35. ,  30. ,  30. ,  30. ,  30. ,  30. ,  30. ,  30. ,\n",
       "        30. ,  30. ,  30. , 120. , 120. , 115. , 110. , 110. , 117.5,\n",
       "       127.5, 132.5, 122.5, 110. , 100. ,  85. ,  75. ,  75. ,  75. ,\n",
       "        75. ,  75. ,  75. ,  70. ,  70. ,  70. ,  65. ,  60. ,  60. ,\n",
       "        55. ,  50. ,  45. ,  45. ,  45. ,  65. ,  55. ,  55. ,  50. ,\n",
       "        45. ,  45. ], dtype=float32)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN: 11.64: XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=7)\n",
    "    EP: 12.63\n",
    "        XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([20518, 20520, 20522, 20524, 20526, 20528, 20530, 20532, 20536,\n",
      "            20538, 20540, 20542, 20544, 20546, 20548, 20550, 20552, 20554,\n",
      "            20556, 20558, 20560, 20562, 20636, 20638, 20640, 20642, 20644,\n",
      "            20646, 20648, 20650, 20652, 20654, 20656, 20658, 20660, 20662,\n",
      "            20664],\n",
      "           dtype='int64')\n",
      "Total number of steps for comparison:  37\n",
      "Year  2019  MAE intensity basin EP Hurricast trained full:  10.5 with std  7.98\n",
      "Year  2019  MAE intensity basin EP Hurricast trained until 2012:  10.5 with std  7.98\n",
      "Year  2019  MAE intensity basin EP Official Forecast SHIP :  23.69 with std  19.81\n",
      "Year  2019  MAE intensity basin EP Official Forecast HWRF :  16.01 with std  17.82\n",
      "Year  2019  MAE intensity basin EP Official Forecast OFCL :  21.23 with std  19.8\n",
      "Year  2019  MAE intensity basin EP Official Forecast FSSE :  20.76 with std  19.16\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'MAES_OFCL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-0264c1d05507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_perf_intensity_per_year_4cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_samples'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAEs_full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAES_2012'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_2012'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAES_SHIP'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_SHIP'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAES_HWRF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_HWRF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SHIP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HWRF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OFCL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FSSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-64de63c7b7d0>\u001b[0m in \u001b[0;36mcompare_perf_intensity_per_year_4cast\u001b[0;34m(dict, xgb_tot, xgb_total, year, forecast2, forecast3, forecast4, basin, forecast, mode)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with std \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 np.around(np.std(tgt_ - baseline_4), decimals=2))\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mappend_dict_intensity_4cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-64de63c7b7d0>\u001b[0m in \u001b[0;36mappend_dict_intensity_4cast\u001b[0;34m(dict, tgt_, preds, preds_1, baseline_1, baseline_2, baseline_3, baseline_4, year)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAES_HWRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_HWRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbaseline_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAES_OFCL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_OFCL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbaseline_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAES_FSSE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MAES_OFCL'"
     ]
    }
   ],
   "source": [
    "compare_perf_intensity_per_year_4cast(dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[]}, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([  489,   491,   493,   495,   497,   499,   501,   503,   505,\\n             3037,\\n            ...\\n            21231, 21233, 21235, 21237, 21239, 21241, 21243, 21245, 21251,\\n            21253],\\n           dtype='int64', length=1037)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-50fe1ca366aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_perf_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'FSSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-5b3d525d30f6>\u001b[0m in \u001b[0;36mcompare_perf_intensity\u001b[0;34m(xgb_total, basin, forecast, last_storms, mode, forecast2)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mX_test_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mforecast\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_24_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_7'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mX_test_withBASELINE_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_total\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0mbaseline_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mforecast\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_24_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_7'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vmax'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([  489,   491,   493,   495,   497,   499,   501,   503,   505,\\n             3037,\\n            ...\\n            21231, 21233, 21235, 21237, 21239, 21241, 21243, 21245, 21251,\\n            21253],\\n           dtype='int64', length=1037)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "compare_perf_intensity(xgb_total = xgb_total, basin='AN', forecast='FSSE', mode='vmax', forecast2 = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  315\n",
      "Year  2018  MAE intensity basin EP Hurricast trained full:  19.78 with std  23.87\n",
      "Year  2018  MAE intensity basin EP Hurricast trained until 2012:  19.78 with std  23.87\n",
      "Year  2018  MAE intensity basin EP Official Forecast SHIP :  17.52 with std  20.54\n",
      "Year  2018  MAE intensity basin EP Official Forecast HWRF :  12.59 with std  16.6\n",
      "Year  2018  MAE intensity basin EP Official Forecast OFCL :  12.56 with std  16.02\n",
      "Year  2018  MAE intensity basin EP Official Forecast FSSE :  12.83 with std  15.3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'MAES_OFCL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-791807013b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_perf_intensity_per_year_4cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_samples'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAEs_full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAES_2012'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_2012'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAES_SHIP'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_SHIP'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MAES_HWRF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_HWRF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SHIP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HWRF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OFCL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FSSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-fe341c1fec46>\u001b[0m in \u001b[0;36mcompare_perf_intensity_per_year_4cast\u001b[0;34m(dict, xgb_tot, xgb_total, year, forecast2, forecast3, forecast4, basin, forecast, mode)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with std \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 np.around(np.std(tgt_ - baseline_4), decimals=2))\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mappend_dict_intensity_4cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-fe341c1fec46>\u001b[0m in \u001b[0;36mappend_dict_intensity_4cast\u001b[0;34m(dict, tgt_, preds, preds_1, baseline_1, baseline_2, baseline_3, baseline_4, year)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAES_HWRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_HWRF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbaseline_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAES_OFCL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_OFCL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbaseline_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAES_FSSE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MAES_OFCL'"
     ]
    }
   ],
   "source": [
    "compare_perf_intensity_per_year_4cast(dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[]}, xgb_total = xgb, xgb_tot = xgb, basin='EP', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  0\n",
      "\n",
      " No forecasts for year  2012\n",
      "Total number of steps for comparison:  0\n",
      "\n",
      " No forecasts for year  2013\n",
      "Total number of steps for comparison:  205\n",
      "Year  2014  MAE intensity basin EP Hurricast trained full:  17.15 with std  20.19\n",
      "Year  2014  MAE intensity basin EP Hurricast trained until 2012:  16.14 with std  20.26\n",
      "Year  2014  MAE intensity basin EP Official Forecast HWRF :  13.46 with std  16.03\n",
      "Year  2014  MAE intensity basin EP Official Forecast SHIP :  15.53 with std  19.13\n",
      "Year  2014  MAE intensity basin EP Official Forecast OFCL :  13.61 with std  16.65\n",
      "Year  2014  MAE intensity basin EP Official Forecast FSSE :  13.57 with std  15.51\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  221\n",
      "Year  2015  MAE intensity basin EP Hurricast trained full:  17.8 with std  19.73\n",
      "Year  2015  MAE intensity basin EP Hurricast trained until 2012:  19.24 with std  21.17\n",
      "Year  2015  MAE intensity basin EP Official Forecast HWRF :  12.75 with std  15.94\n",
      "Year  2015  MAE intensity basin EP Official Forecast SHIP :  14.44 with std  18.8\n",
      "Year  2015  MAE intensity basin EP Official Forecast OFCL :  11.26 with std  16.08\n",
      "Year  2015  MAE intensity basin EP Official Forecast FSSE :  11.64 with std  15.72\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  259\n",
      "Year  2016  MAE intensity basin EP Hurricast trained full:  15.15 with std  19.63\n",
      "Year  2016  MAE intensity basin EP Hurricast trained until 2012:  16.04 with std  20.2\n",
      "Year  2016  MAE intensity basin EP Official Forecast HWRF :  11.17 with std  15.2\n",
      "Year  2016  MAE intensity basin EP Official Forecast SHIP :  12.54 with std  15.9\n",
      "Year  2016  MAE intensity basin EP Official Forecast OFCL :  11.24 with std  14.69\n",
      "Year  2016  MAE intensity basin EP Official Forecast FSSE :  11.12 with std  14.16\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  140\n",
      "Year  2017  MAE intensity basin EP Hurricast trained full:  10.62 with std  13.62\n",
      "Year  2017  MAE intensity basin EP Hurricast trained until 2012:  11.42 with std  14.91\n",
      "Year  2017  MAE intensity basin EP Official Forecast HWRF :  8.35 with std  10.66\n",
      "Year  2017  MAE intensity basin EP Official Forecast SHIP :  11.16 with std  13.02\n",
      "Year  2017  MAE intensity basin EP Official Forecast OFCL :  9.75 with std  11.23\n",
      "Year  2017  MAE intensity basin EP Official Forecast FSSE :  10.34 with std  12.57\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  315\n",
      "Year  2018  MAE intensity basin EP Hurricast trained full:  17.84 with std  21.61\n",
      "Year  2018  MAE intensity basin EP Hurricast trained until 2012:  19.5 with std  22.62\n",
      "Year  2018  MAE intensity basin EP Official Forecast HWRF :  12.59 with std  16.6\n",
      "Year  2018  MAE intensity basin EP Official Forecast SHIP :  17.52 with std  20.54\n",
      "Year  2018  MAE intensity basin EP Official Forecast OFCL :  12.56 with std  16.02\n",
      "Year  2018  MAE intensity basin EP Official Forecast FSSE :  12.83 with std  15.3\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  37\n",
      "Year  2019  MAE intensity basin EP Hurricast trained full:  8.99 with std  9.32\n",
      "Year  2019  MAE intensity basin EP Hurricast trained until 2012:  5.93 with std  5.59\n",
      "Year  2019  MAE intensity basin EP Official Forecast HWRF :  16.01 with std  17.82\n",
      "Year  2019  MAE intensity basin EP Official Forecast SHIP :  23.69 with std  19.81\n",
      "Year  2019  MAE intensity basin EP Official Forecast OFCL :  21.23 with std  19.8\n",
      "Year  2019  MAE intensity basin EP Official Forecast FSSE :  20.76 with std  19.16\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [16.14, 19.24, 16.04, 11.42, 19.5, 5.93],\n",
       " 'MAES_FSSE': [13.57, 11.64, 11.12, 10.34, 12.83, 20.76],\n",
       " 'MAES_HWRF': [15.53, 14.44, 12.54, 11.16, 17.52, 23.69],\n",
       " 'MAES_OFCL': [13.61, 11.26, 11.24, 9.75, 12.56, 21.23],\n",
       " 'MAES_SHIP': [13.46, 12.75, 11.17, 8.35, 12.59, 16.01],\n",
       " 'MAEs_full': [17.15, 17.8, 15.15, 10.62, 17.84, 8.99],\n",
       " 'num_samples': [205, 221, 259, 140, 315, 37],\n",
       " 'std_2012': [20.26, 21.17, 20.2, 14.91, 22.62, 5.59],\n",
       " 'std_FSSE': [15.51, 15.72, 14.16, 12.57, 15.3, 19.16],\n",
       " 'std_HWRF': [19.13, 18.8, 15.9, 13.02, 20.54, 19.81],\n",
       " 'std_OFCL': [16.65, 16.08, 14.69, 11.23, 16.02, 19.8],\n",
       " 'std_SHIP': [16.03, 15.94, 15.2, 10.66, 16.6, 17.82],\n",
       " 'std_full': [20.19, 19.73, 19.63, 13.62, 21.61, 9.32],\n",
       " 'year': [2014, 2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_4cast(forecast = 'HWRF', basin_only = False, sparse = False, max_depth = 8, n_estimators = 100, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'EP', forecast2 = 'SHIP', forecast3 = 'OFCL', forecast4 = 'FSSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  37\n",
      "Year  2012  MAE intensity basin AN Hurricast trained full:  11.05 with std  12.09\n",
      "Year  2012  MAE intensity basin AN Hurricast trained until 2012:  11.17 with std  13.25\n",
      "Year  2012  MAE intensity basin AN Official Forecast HWRF :  8.2 with std  9.99\n",
      "Year  2012  MAE intensity basin AN Official Forecast SHIP :  10.39 with std  12.46\n",
      "Year  2012  MAE intensity basin AN Official Forecast OFCL :  7.23 with std  9.64\n",
      "Year  2012  MAE intensity basin AN Official Forecast FSSE :  10.53 with std  9.93\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  4\n",
      "Year  2013  MAE intensity basin AN Hurricast trained full:  19.54 with std  9.04\n",
      "Year  2013  MAE intensity basin AN Hurricast trained until 2012:  23.33 with std  8.36\n",
      "Year  2013  MAE intensity basin AN Official Forecast HWRF :  14.62 with std  11.62\n",
      "Year  2013  MAE intensity basin AN Official Forecast SHIP :  37.12 with std  11.24\n",
      "Year  2013  MAE intensity basin AN Official Forecast OFCL :  15.62 with std  2.07\n",
      "Year  2013  MAE intensity basin AN Official Forecast FSSE :  16.12 with std  9.36\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  61\n",
      "Year  2014  MAE intensity basin AN Hurricast trained full:  12.24 with std  14.51\n",
      "Year  2014  MAE intensity basin AN Hurricast trained until 2012:  12.2 with std  14.72\n",
      "Year  2014  MAE intensity basin AN Official Forecast HWRF :  12.7 with std  14.58\n",
      "Year  2014  MAE intensity basin AN Official Forecast SHIP :  10.97 with std  12.74\n",
      "Year  2014  MAE intensity basin AN Official Forecast OFCL :  7.62 with std  9.51\n",
      "Year  2014  MAE intensity basin AN Official Forecast FSSE :  10.41 with std  10.75\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  101\n",
      "Year  2015  MAE intensity basin AN Hurricast trained full:  15.34 with std  20.63\n",
      "Year  2015  MAE intensity basin AN Hurricast trained until 2012:  16.07 with std  21.36\n",
      "Year  2015  MAE intensity basin AN Official Forecast HWRF :  10.04 with std  14.63\n",
      "Year  2015  MAE intensity basin AN Official Forecast SHIP :  11.8 with std  15.01\n",
      "Year  2015  MAE intensity basin AN Official Forecast OFCL :  9.06 with std  12.34\n",
      "Year  2015  MAE intensity basin AN Official Forecast FSSE :  9.23 with std  12.95\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  200\n",
      "Year  2016  MAE intensity basin AN Hurricast trained full:  17.2 with std  20.63\n",
      "Year  2016  MAE intensity basin AN Hurricast trained until 2012:  16.78 with std  20.42\n",
      "Year  2016  MAE intensity basin AN Official Forecast HWRF :  11.38 with std  16.17\n",
      "Year  2016  MAE intensity basin AN Official Forecast SHIP :  12.48 with std  17.19\n",
      "Year  2016  MAE intensity basin AN Official Forecast OFCL :  9.77 with std  13.33\n",
      "Year  2016  MAE intensity basin AN Official Forecast FSSE :  10.76 with std  14.56\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  200\n",
      "Year  2017  MAE intensity basin AN Hurricast trained full:  18.07 with std  21.95\n",
      "Year  2017  MAE intensity basin AN Hurricast trained until 2012:  17.89 with std  21.7\n",
      "Year  2017  MAE intensity basin AN Official Forecast HWRF :  11.85 with std  14.8\n",
      "Year  2017  MAE intensity basin AN Official Forecast SHIP :  16.58 with std  22.44\n",
      "Year  2017  MAE intensity basin AN Official Forecast OFCL :  11.26 with std  14.9\n",
      "Year  2017  MAE intensity basin AN Official Forecast FSSE :  9.37 with std  12.63\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  200\n",
      "Year  2018  MAE intensity basin AN Hurricast trained full:  17.68 with std  23.03\n",
      "Year  2018  MAE intensity basin AN Hurricast trained until 2012:  17.38 with std  22.88\n",
      "Year  2018  MAE intensity basin AN Official Forecast HWRF :  11.81 with std  17.3\n",
      "Year  2018  MAE intensity basin AN Official Forecast SHIP :  16.25 with std  20.24\n",
      "Year  2018  MAE intensity basin AN Official Forecast OFCL :  11.65 with std  17.13\n",
      "Year  2018  MAE intensity basin AN Official Forecast FSSE :  12.62 with std  17.08\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  179\n",
      "Year  2019  MAE intensity basin AN Hurricast trained full:  16.88 with std  20.49\n",
      "Year  2019  MAE intensity basin AN Hurricast trained until 2012:  16.59 with std  20.23\n",
      "Year  2019  MAE intensity basin AN Official Forecast HWRF :  12.3 with std  16.36\n",
      "Year  2019  MAE intensity basin AN Official Forecast SHIP :  15.48 with std  18.51\n",
      "Year  2019  MAE intensity basin AN Official Forecast OFCL :  10.31 with std  13.26\n",
      "Year  2019  MAE intensity basin AN Official Forecast FSSE :  10.07 with std  12.78\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [11.17, 23.33, 12.2, 16.07, 16.78, 17.89, 17.38, 16.59],\n",
       " 'MAES_FSSE': [10.53, 16.12, 10.41, 9.23, 10.76, 9.37, 12.62, 10.07],\n",
       " 'MAES_HWRF': [10.39, 37.12, 10.97, 11.8, 12.48, 16.58, 16.25, 15.48],\n",
       " 'MAES_OFCL': [7.23, 15.62, 7.62, 9.06, 9.77, 11.26, 11.65, 10.31],\n",
       " 'MAES_SHIP': [8.2, 14.62, 12.7, 10.04, 11.38, 11.85, 11.81, 12.3],\n",
       " 'MAEs_full': [11.05, 19.54, 12.24, 15.34, 17.2, 18.07, 17.68, 16.88],\n",
       " 'num_samples': [37, 4, 61, 101, 200, 200, 200, 179],\n",
       " 'std_2012': [13.25, 8.36, 14.72, 21.36, 20.42, 21.7, 22.88, 20.23],\n",
       " 'std_FSSE': [9.93, 9.36, 10.75, 12.95, 14.56, 12.63, 17.08, 12.78],\n",
       " 'std_HWRF': [12.46, 11.24, 12.74, 15.01, 17.19, 22.44, 20.24, 18.51],\n",
       " 'std_OFCL': [9.64, 2.07, 9.51, 12.34, 13.33, 14.9, 17.13, 13.26],\n",
       " 'std_SHIP': [9.99, 11.62, 14.58, 14.63, 16.17, 14.8, 17.3, 16.36],\n",
       " 'std_full': [12.09, 9.04, 14.51, 20.63, 20.63, 21.95, 23.03, 20.49],\n",
       " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_4cast(forecast = 'HWRF', basin_only = False, sparse = False, max_depth = 8, n_estimators = 100, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = 'SHIP', forecast3 = 'OFCL', forecast4 = 'FSSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  0\n",
      "\n",
      " No forecasts for year  2012\n",
      "Total number of steps for comparison:  6\n",
      "Year  2013  MAE intensity basin EP Hurricast trained full:  22.26 with std  8.79\n",
      "Year  2013  MAE intensity basin EP Hurricast trained until 2012:  21.47 with std  6.96\n",
      "Year  2013  MAE intensity basin EP Official Forecast HWRF :  11.33 with std  9.29\n",
      "Year  2013  MAE intensity basin EP Official Forecast SHIP :  27.0 with std  13.22\n",
      "Year  2013  MAE intensity basin EP Official Forecast OFCL :  10.0 with std  13.74\n",
      "Year  2013  MAE intensity basin EP Official Forecast FSSE :  10.67 with std  12.78\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  273\n",
      "Year  2014  MAE intensity basin EP Hurricast trained full:  10.14 with std  13.69\n",
      "Year  2014  MAE intensity basin EP Hurricast trained until 2012:  10.14 with std  13.79\n",
      "Year  2014  MAE intensity basin EP Official Forecast HWRF :  11.41 with std  14.57\n",
      "Year  2014  MAE intensity basin EP Official Forecast SHIP :  12.02 with std  15.44\n",
      "Year  2014  MAE intensity basin EP Official Forecast OFCL :  9.73 with std  13.45\n",
      "Year  2014  MAE intensity basin EP Official Forecast FSSE :  10.01 with std  13.07\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  274\n",
      "Year  2015  MAE intensity basin EP Hurricast trained full:  11.68 with std  15.87\n",
      "Year  2015  MAE intensity basin EP Hurricast trained until 2012:  11.69 with std  15.82\n",
      "Year  2015  MAE intensity basin EP Official Forecast HWRF :  12.28 with std  17.5\n",
      "Year  2015  MAE intensity basin EP Official Forecast SHIP :  13.06 with std  17.95\n",
      "Year  2015  MAE intensity basin EP Official Forecast OFCL :  10.89 with std  15.91\n",
      "Year  2015  MAE intensity basin EP Official Forecast FSSE :  10.66 with std  14.73\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  315\n",
      "Year  2016  MAE intensity basin EP Hurricast trained full:  9.58 with std  13.32\n",
      "Year  2016  MAE intensity basin EP Hurricast trained until 2012:  9.94 with std  13.39\n",
      "Year  2016  MAE intensity basin EP Official Forecast HWRF :  10.38 with std  13.74\n",
      "Year  2016  MAE intensity basin EP Official Forecast SHIP :  9.87 with std  12.84\n",
      "Year  2016  MAE intensity basin EP Official Forecast OFCL :  8.72 with std  11.89\n",
      "Year  2016  MAE intensity basin EP Official Forecast FSSE :  8.51 with std  11.53\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  167\n",
      "Year  2017  MAE intensity basin EP Hurricast trained full:  9.12 with std  12.79\n",
      "Year  2017  MAE intensity basin EP Hurricast trained until 2012:  9.04 with std  13.09\n",
      "Year  2017  MAE intensity basin EP Official Forecast HWRF :  7.87 with std  11.61\n",
      "Year  2017  MAE intensity basin EP Official Forecast SHIP :  9.97 with std  13.0\n",
      "Year  2017  MAE intensity basin EP Official Forecast OFCL :  8.14 with std  11.67\n",
      "Year  2017  MAE intensity basin EP Official Forecast FSSE :  7.92 with std  10.67\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  357\n",
      "Year  2018  MAE intensity basin EP Hurricast trained full:  12.21 with std  15.82\n",
      "Year  2018  MAE intensity basin EP Hurricast trained until 2012:  12.37 with std  16.1\n",
      "Year  2018  MAE intensity basin EP Official Forecast HWRF :  10.92 with std  14.83\n",
      "Year  2018  MAE intensity basin EP Official Forecast SHIP :  12.92 with std  15.86\n",
      "Year  2018  MAE intensity basin EP Official Forecast OFCL :  10.18 with std  13.44\n",
      "Year  2018  MAE intensity basin EP Official Forecast FSSE :  9.82 with std  12.65\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  40\n",
      "Year  2019  MAE intensity basin EP Hurricast trained full:  4.02 with std  4.2\n",
      "Year  2019  MAE intensity basin EP Hurricast trained until 2012:  3.89 with std  4.25\n",
      "Year  2019  MAE intensity basin EP Official Forecast HWRF :  21.71 with std  21.95\n",
      "Year  2019  MAE intensity basin EP Official Forecast SHIP :  25.58 with std  21.77\n",
      "Year  2019  MAE intensity basin EP Official Forecast OFCL :  26.6 with std  23.02\n",
      "Year  2019  MAE intensity basin EP Official Forecast FSSE :  24.89 with std  20.87\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [21.47, 10.14, 11.69, 9.94, 9.04, 12.37, 3.89],\n",
       " 'MAES_FSSE': [10.67, 10.01, 10.66, 8.51, 7.92, 9.82, 24.89],\n",
       " 'MAES_HWRF': [27.0, 12.02, 13.06, 9.87, 9.97, 12.92, 25.58],\n",
       " 'MAES_OFCL': [10.0, 9.73, 10.89, 8.72, 8.14, 10.18, 26.6],\n",
       " 'MAES_SHIP': [11.33, 11.41, 12.28, 10.38, 7.87, 10.92, 21.71],\n",
       " 'MAEs_full': [22.26, 10.14, 11.68, 9.58, 9.12, 12.21, 4.02],\n",
       " 'num_samples': [6, 273, 274, 315, 167, 357, 40],\n",
       " 'std_2012': [6.96, 13.79, 15.82, 13.39, 13.09, 16.1, 4.25],\n",
       " 'std_FSSE': [12.78, 13.07, 14.73, 11.53, 10.67, 12.65, 20.87],\n",
       " 'std_HWRF': [13.22, 15.44, 17.95, 12.84, 13.0, 15.86, 21.77],\n",
       " 'std_OFCL': [13.74, 13.45, 15.91, 11.89, 11.67, 13.44, 23.02],\n",
       " 'std_SHIP': [9.29, 14.57, 17.5, 13.74, 11.61, 14.83, 21.95],\n",
       " 'std_full': [8.79, 13.69, 15.87, 13.32, 12.79, 15.82, 4.2],\n",
       " 'year': [2013, 2014, 2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_4cast(forecast = 'HWRF', basin_only = False, sparse = False, max_depth = 8, n_estimators = 120, learning_rate = 0.07, subsample = 0.8, min_child_weight=1, basin = 'EP', forecast2 = 'SHIP', forecast3 = 'OFCL', forecast4 = 'FSSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_intensity_all_years_full_train(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total_1 = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total_1.fit(train, tgt_train)\n",
    "    dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[]}\n",
    "    for year in range(2012, 2020):\n",
    "            index = X_test_baseline.loc[X_test_baseline['YEAR'] < year].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis = 0)\n",
    "            tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[index]), axis = 0)\n",
    "            xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                     subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_total.fit(train, tgt_train)\n",
    "            compare_perf_intensity_per_year(dict = dict, xgb_tot = xgb_total_1, forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-eefc5c1222b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_xgb_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EMXI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OFCL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-cab3eb48c918>\u001b[0m in \u001b[0;36mtrain_xgb_intensity\u001b[0;34m(forecast, basin_only, sparse, max_depth, n_estimators, learning_rate, subsample, min_child_weight, basin, forecast2)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mxgb_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mcompare_perf_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.12, subsample = 0.7, min_child_weight = 5, basin = 'AN', forecast = 'HWRF') 82.14 and 117.26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-cab3eb48c918>\u001b[0m in \u001b[0;36mcompare_perf_intensity\u001b[0;34m(xgb_total, basin, forecast, last_storms, mode, forecast2)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                                      \u001b[0;31m#xgb.predict(X_test_withBASELINE) * std_ + mean_))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Timesteps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAE intensity basin \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Hurricast : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with std \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         print(\"MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n\u001b[1;32m    182\u001b[0m               np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m    169\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 170\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     output_errors = np.average(np.abs(y_pred - y_true),\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 582\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "train_xgb_intensity(forecast = 'EMXI', basin_only = False, sparse = False, max_depth = 8, n_estimators = 150, learning_rate = 0.07, subsample = 0.8, min_child_weight=1, basin = 'EP', forecast2 = 'OFCL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X_train_total\n",
    "train_y = X_train_total\n",
    "test_x = X_test_total\n",
    "test_y = X_test_total\n",
    "tgt_train = tgt_displacement_train\n",
    "\n",
    "xgb_x = XGBRegressor(max_depth=7, n_estimators=90, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=7, n_estimators=90, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        42.100052\n",
       "1        42.950531\n",
       "2        43.727261\n",
       "3        44.291496\n",
       "4        11.833095\n",
       "           ...    \n",
       "26795    41.138153\n",
       "26796    41.615891\n",
       "26797    41.676640\n",
       "26798    41.337860\n",
       "26799    41.493984\n",
       "Name: LAT_7, Length: 26800, dtype: float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LATS_PRED_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        42.151398\n",
       "1        42.899998\n",
       "2        43.847599\n",
       "3        44.899998\n",
       "4        12.634900\n",
       "           ...    \n",
       "26795    40.200001\n",
       "26796    40.669701\n",
       "26797    41.200001\n",
       "26798    41.635597\n",
       "26799    42.000000\n",
       "Name: LAT_7, Length: 26800, dtype: float32"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LATS_TEST_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP: Intensity\n",
    "We beat: HWRF, SHIP, GFSO, AEMN, DSHP, (GFDL, UKXI, CMC)\n",
    "We lose: OFCL, FSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP: Track\n",
    "We beat: GFDL, CMC, CLP5\n",
    "We lose: FSSE, OFCL, SHIP, HWRF, GFSO, AEMN, DSHP (UKXI)\n",
    "    \n",
    "AN: Track\n",
    "We beat: GFDL, CMC, CLP5\n",
    "We lose: FSSE, OFCL, SHIP, HWRF, GFSO, AEMN, DSHP (UKXI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_perf_track(basin='EP', forecast='SHIP', forecast2 = 'HWRF', LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_track(basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    train_x = X_train_total\n",
    "    train_y = X_train_total\n",
    "    test_x = X_test_total\n",
    "    test_y = X_test_total\n",
    "    tgt_train = tgt_displacement_train\n",
    "    if sparse:\n",
    "        train_x, train_y = X_train_total_sparse_x, X_train_total_sparse_y\n",
    "        test_x, test_y = X_test_total_sparse_x, X_test_total_sparse_y\n",
    "    if basin_only:\n",
    "        train_x = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        train_y = train_x\n",
    "        tgt_train = tgt_displacement_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "    xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "    DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "    DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "    LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "    LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "    compare_perf_track(basin=basin, forecast=forecast, forecast2 = forecast2, LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "\n",
    "def train_xgb_track_all_years(use_forecast = False, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    train_x = X_train_total\n",
    "    train_y = X_train_total\n",
    "    test_x = X_test_total\n",
    "    test_y = X_test_total\n",
    "    tgt_train = tgt_displacement_train\n",
    "    if sparse:\n",
    "        train_x, train_y = X_train_total_sparse_x, X_train_total_sparse_y\n",
    "        test_x, test_y = X_test_total_sparse_x, X_test_total_sparse_y\n",
    "    if basin_only:\n",
    "        train_x = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        train_y = train_x\n",
    "        tgt_train = tgt_displacement_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    if use_forecast:\n",
    "        train_for = X_train_forecasts\n",
    "        tgt_train_for = tgt_train_dis_forecasts\n",
    "        test_for = X_test_forecasts\n",
    "        xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_x.fit(train_for, tgt_train_for[:, 0])\n",
    "        xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_y.fit(train_for, tgt_train_for[:, 1])\n",
    "        DLATS_PRED = np.array(xgb_x.predict(X_new)) * std_dx + mean_dx\n",
    "        DLONS_PRED = np.array(xgb_y.predict(X_new)) * std_dy + mean_dy\n",
    "    else:\n",
    "        xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "        xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "        DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "        DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "    LATS_PRED_2012 = X_test['LAT_7'] + DLATS_PRED\n",
    "    LONS_PRED_2012 = X_test['LON_7'] + DLONS_PRED\n",
    "    compare_perf_track(basin=basin, forecast=forecast, forecast2 = forecast2, LATS_PRED_=LATS_PRED_2012, LONS_PRED_=LONS_PRED_2012)\n",
    "    dict = {'year': [], 'num_samples': [], 'MAEs_full': [], 'std_full': [], 'MAES_2012': [], 'std_2012': [],\n",
    "            'MAES_SHIP': [], 'std_SHIP': [], 'MAES_HWRF': [], 'std_HWRF': []}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[\n",
    "                X_test_baseline['YEAR'] < year].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis=0)\n",
    "            tgt_train = np.concatenate((tgt_displacement_train, tgt_displacement_test[index]), axis=0)\n",
    "            xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_x.fit(train, tgt_train[:, 0])\n",
    "            xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_y.fit(train, tgt_train[:, 1])\n",
    "            DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "            DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "            LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "            LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "            compare_perf_track_per_year(dict, LATS_PRED_, LONS_PRED_, LATS_PRED_2012, LONS_PRED_2012, forecast=forecast,\n",
    "                                            forecast2=forecast2, basin=basin,  year=year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_xgb_intensity(forecast = 'SHIP', basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = None):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total.fit(train, tgt_train)\n",
    "    compare_perf_intensity(xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', forecast2 = forecast2)\n",
    "\n",
    "#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.12, subsample = 0.7, min_child_weight = 5, basin = 'AN', forecast = 'HWRF') 82.14 and 117.26\n",
    "#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.1, subsample = 0.7, min_child_weight = 5, basin = 'EP', forecast = 'HWRF')\n",
    "\n",
    "LATS_TEST = X_test['LAT_7'] + np.array(tgt_displacement_test[:,0])*std_dx+mean_dx\n",
    "LONS_TEST = X_test['LON_7'] + np.array(tgt_displacement_test[:,1])*std_dy+mean_dy\n",
    "\n",
    "def compare_perf_track(LATS_PRED_, LONS_PRED_, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    LATS_TEST_ = X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx\n",
    "    LONS_TEST_ = X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy\n",
    "    baseline_1_x = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_1_y = baseline_[forecast + '_24_lon_7']\n",
    "    LATS_BASE = np.array(baseline_1_x)\n",
    "    LONS_BASE = np.array(baseline_1_y)\n",
    "    LATS_TEST_ = np.array(LATS_TEST_[index])\n",
    "    LONS_TEST_ = np.array(LONS_TEST_[index])\n",
    "    LATS_PRED_ = np.array(LATS_PRED_[index])\n",
    "    LONS_PRED_ = np.array(LONS_PRED_[index])\n",
    "    d_km_baseline = np.zeros(len(LATS_BASE))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_BASE))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    for i in range(len(LATS_BASE)):\n",
    "        d_km_baseline[i] = get_distance_km(LONS_BASE[i], LATS_BASE[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        if forecast2 != None:\n",
    "            d_km_baseline2[i] = get_distance_km(LONS_BASE_2[i], LATS_BASE_2[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Number of timesteps:\", len(LATS_BASE))\n",
    "    print(basin, 'Model | MAE | std')\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2))\n",
    "    print(str(forecast2), np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2))\n",
    "    print(\"Hurricast\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2))\n",
    "    print(\"\\nModel | Number of Busts > 200km | Percentage Bust\")\n",
    "    print(forecast, sum(d_km_baseline > 200), np.around(sum(d_km_baseline > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    print(str(forecast2), sum(d_km_baseline2 > 200), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_BASE), decimals =2))\n",
    "    print(\"Hurricast\", sum(d_km_pred > 200), np.around(sum(d_km_pred > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "\n",
    "\n",
    "\n",
    "def compare_perf_intensity(xgb_total, basin = 'AN', forecast = 'SHIP', last_storms = 1000, mode = 'vmax', forecast2 = 'HWRF'):\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    else:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    X_test_withBASELINE_total = X_test_total[index]\n",
    "    baseline_1 = baseline_[forecast + '_24_' + mode + '_7']\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Timesteps\", len(tgt_))\n",
    "        print(\"MAE intensity basin \" + basin + \" Hurricast : \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds), decimals=2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \" + str(forecast2) + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_2), decimals=2), \"with std \",\n",
    "              np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "        print(\"Percentage of missed intensification > 20kn Hurricast: \", np.around(sum(abs(tgt_ - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(\"Percentage of missed intensification > 20kn Official Forecast\"+ forecast + \" : \", np.around(sum(abs(tgt_ - baseline_1) > 20) / len(baseline_1) * 100, decimals =2))\n",
    "        print(\"Percentage of missed intensification > 20kn Official Forecast 2\"+ str(forecast2) + \" : \", np.around(sum(abs(tgt_ - baseline_2) > 20) / len(baseline_2) * 100, decimals =2))\n",
    "        print(\"\\nMAE intensity basin \" + basin + \" Hurricast last\", last_storms, \": \", np.around(mean_absolute_error(tgt_[-last_storms:], preds[-last_storms:]), decimals=2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \" + forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_[-last_storms:], baseline_1[-last_storms:]), decimals=2))\n",
    "\n",
    "\n",
    "#train_xgb_intensity(forecast = 'SHIP', basin = 'EP', max_depth=8, n_estimators = 120, learning_rate = 0.07, subsample = 0.8, min_child_weight = 1)\n",
    "#train_xgb_intensity(forecast = 'SHIP', basin = 'AN', max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.8, min_child_weight = 1, forecast2 = 'HWRF')\n",
    "\n",
    "\n",
    "def compare_perf_intensity_per_year(dict, xgb_tot, xgb_total, year, forecast2, basin = 'AN', forecast = 'HWRF', mode = 'vmax'):\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        #X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    X_test_withBASELINE_total = X_test_total[index]\n",
    "    baseline_1 = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        print(\"Total number of steps for comparison: \", len(tgt_))\n",
    "        preds_1 = xgb_tot.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Hurricast trained full: \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds), decimals=2))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Hurricast trained until 2012: \", np.around(mean_absolute_error(tgt_, preds_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "        if forecast2 != None:\n",
    "            print(\"Year \", year, \" MAE intensity basin \" + basin + \" Official Forecast \" + forecast2 + \" : \",\n",
    "                np.around(mean_absolute_error(tgt_, baseline_2), decimals=2), \"with std \",\n",
    "                np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "        append_dict_intensity(dict, tgt_, preds, preds_1, baseline_1, baseline_2, year)\n",
    "        #print(\"Year \", year, \" Percentage of missed intensification > 20kn Hurricast: \", np.around(sum(tgt_ - preds > 20)/len(preds) * 100, decimals = 2))\n",
    "        #print(\"Year \", year, \" Percentage of missed intensification > 20kn Official Forecast: \", np.around(sum(tgt_ - baseline_1 > 20) / len(baseline_1) * 100, decimals =2))\n",
    "\n",
    "\n",
    "def compare_perf_track_per_year(dict, LATS_PRED_, LONS_PRED_, LATS_PRED_2012, LONS_PRED_2012, year, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] >= year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    LATS_TEST_ = X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx\n",
    "    LONS_TEST_ = X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy\n",
    "    baseline_1_x = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_1_y = baseline_[forecast + '_24_lon_7']\n",
    "    LATS_BASE = np.array(baseline_1_x)\n",
    "    LONS_BASE = np.array(baseline_1_y)\n",
    "    LATS_TEST_ = np.array(LATS_TEST_[index])\n",
    "    LONS_TEST_ = np.array(LONS_TEST_[index])\n",
    "    LATS_PRED_ = np.array(LATS_PRED_[index])\n",
    "    LONS_PRED_ = np.array(LONS_PRED_[index])\n",
    "    LATS_PRED_2012 = np.array(LATS_PRED_2012[index])\n",
    "    LONS_PRED_2012 = np.array(LONS_PRED_2012[index])\n",
    "    d_km_baseline = np.zeros(len(LATS_BASE))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_BASE))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    d_km_pred_2012 = np.zeros(len(LONS_PRED_))\n",
    "    for i in range(len(LATS_BASE)):\n",
    "        d_km_baseline[i] = get_distance_km(LONS_BASE[i], LATS_BASE[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred_2012[i] = get_distance_km(LONS_PRED_2012[i], LATS_PRED_2012[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        if forecast2 != None:\n",
    "            d_km_baseline2[i] = get_distance_km(LONS_BASE_2[i], LATS_BASE_2[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Year\", year, \"Number of timesteps:\", len(LATS_BASE))\n",
    "    print(basin, 'Model | MAE | std')\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2))\n",
    "    print(str(forecast2), np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2))\n",
    "    print(\"Hurricast Max Data\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2))\n",
    "    print(\"Hurricast Until 2012\", np.around(d_km_pred_2012.mean(), decimals=2), np.around(d_km_pred_2012.std(), decimals=2))\n",
    "    print(\"\\nModel | Number of Busts > 200km | Percentage Bust\")\n",
    "    print(forecast, sum(d_km_baseline > 200), np.around(sum(d_km_baseline > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    print(str(forecast2), sum(d_km_baseline2 > 200), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_BASE), decimals =2))\n",
    "    print(\"Hurricast\", sum(d_km_pred > 200), np.around(sum(d_km_pred > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    append_dict_track(dict, d_km_baseline, d_km_baseline2, d_km_pred, d_km_pred_2012, year)\n",
    "\n",
    "def append_dict_track(dict, d_km_baseline, d_km_baseline2, d_km_pred, d_km_pred_2012, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(d_km_baseline))\n",
    "    dict['MAEs_full'].append(np.around(d_km_pred.mean(), decimals = 2))\n",
    "    dict['std_full'].append(np.around(d_km_pred.std(), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(d_km_pred_2012.mean(), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(d_km_pred_2012.std(), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(d_km_baseline.mean(), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(d_km_baseline.std(), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(d_km_baseline2.mean(), decimals =2))\n",
    "    dict['std_HWRF'].append(np.around(d_km_baseline2.std(), decimals=2))\n",
    "\n",
    "def append_dict_intensity(dict, tgt_, preds, preds_1, baseline_1, baseline_2, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(tgt_))\n",
    "    dict['MAEs_full'].append(np.around(mean_absolute_error(tgt_, preds), decimals = 2))\n",
    "    dict['std_full'].append(np.around(np.std(tgt_ - preds), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(mean_absolute_error(tgt_, preds_1), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(mean_absolute_error(tgt_, baseline_2), decimals=2))\n",
    "    dict['std_HWRF'].append(np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "\n",
    "\n",
    "def train_xgb_intensity_all_years(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total.fit(train, tgt_train)\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            compare_perf_intensity_per_year(forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "\n",
    "def train_xgb_intensity_all_years_full_train(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total_1 = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total_1.fit(train, tgt_train)\n",
    "    dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[]}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[X_test_baseline['YEAR_0'] < year].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis = 0)\n",
    "            tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[index]), axis = 0)\n",
    "            xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                     subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_total.fit(train, tgt_train)\n",
    "            compare_perf_intensity_per_year(dict = dict, xgb_tot = xgb_total_1, forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATS_TRAIN = np.array(X_train['LAT_7']) + np.array(tgt_displacement_train[:,0])*std_dx+mean_dx\n",
    "LONS_TRAIN = np.array(X_train['LON_7']) + np.array(tgt_displacement_train[:,0])*std_dy+mean_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-34.    , -34.9872, -35.9178, ...,  40.1   ,  40.8061,  41.5   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LATS_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X_train_total\n",
    "train_y = X_train_total\n",
    "test_x = X_test_total\n",
    "test_y = X_test_total\n",
    "tgt_train = tgt_displacement_train\n",
    "\n",
    "xgb_x = XGBRegressor(max_depth=7, n_estimators=90, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_x.fit(train_x, LATS_TRAIN_RAD)\n",
    "xgb_y = XGBRegressor(max_depth=7, n_estimators=90, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_y.fit(train_y, LONS_TRAIN_RAD)\n",
    "LATS_PRED_RAD = xgb_x.predict(test_x)\n",
    "LONS_PRED_RAD = xgb_y.predict(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATS_TEST_ = X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx\n",
    "LONS_TEST_ = X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATS_TRAIN_RAD = np.cos(np.pi / 180 * LATS_TRAIN)\n",
    "LONS_TRAIN_RAD = np.cos(np.pi / 180 * LONS_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATS_PRED_ = 180 * np.arccos(LATS_PRED_RAD) / np.pi\n",
    "LONS_PRED_ = 180 * np.arccos(LONS_PRED_RAD) / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "for i in range(len(LATS_PRED_)):\n",
    "    d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1468.4680797683357"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_km_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(LONS_PRED_RAD)):\n",
    "    if LONS_PRED_RAD[i] > 1:\n",
    "        LONS_PRED_RAD[i] = 0.999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(LONS_PRED_)):\n",
    "    if LONS_TEST_[i] < 0:\n",
    "        LONS_PRED_[i] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.07,\n",
       "  'min_child_weight': 5,\n",
       "  'n_estimators': 100,\n",
       "  'subsample': 0.7},\n",
       " -0.2854653795560201)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    " 'min_child_weight':[1,5],\n",
    " 'n_estimators':[100, 120, 150],\n",
    " 'subsample':[0.6,0.7,0.8,],\n",
    " 'learning_rate':[0.07, 0.1, 0.15],\n",
    "}\n",
    "grid = GridSearchCV(estimator = XGBRegressor(learning_rate = 0.07, n_estimators=140, max_depth=8,\n",
    "min_child_weight=1, subsample=0.8, seed=1),\n",
    "param_grid = params, n_jobs=4, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "grid.fit(X_train_total, np.array(tgt_intensity_train))\n",
    "\n",
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_intensity_all_years_full_train_4cast(forecast2 = None, forecast3 = None, forecast4 = None, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    xgb_total_1 = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total_1.fit(train, tgt_train)\n",
    "    dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_FSSE':[], 'std_FSSE':[], 'MAES_OFCL':[], 'std_OFCL':[]}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[X_test_baseline['YEAR_0'] < year].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis = 0)\n",
    "            tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[index]), axis = 0)\n",
    "            xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                     subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_total.fit(train, tgt_train)\n",
    "            compare_perf_intensity_per_year_4cast(test, dict = dict, xgb_tot = xgb_total_1, forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year, forecast3= forecast3, forecast4 = forecast4)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n",
    "\n",
    "def train_xgb_intensity_all_years_full_train_6cast(forecast2 = None, forecast3 = None, forecast4 = None, forecast5 = None, forecast6 = None, max_depth = 8, n_estimators = 140, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP'):\n",
    "    train = X_train_total\n",
    "    test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    xgb_total_1 = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total_1.fit(train, tgt_train)\n",
    "    dict6 = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_FSSE':[], 'std_FSSE':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_GFSO':[], 'std_GFSO':[], 'MAES_DSHP':[], 'std_DSHP':[]}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[X_test_baseline['YEAR_0'] < year].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis = 0)\n",
    "            tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[index]), axis = 0)\n",
    "            xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                     subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_total.fit(train, tgt_train)\n",
    "            compare_perf_intensity_per_year_6cast(test, dict6, xgb_tot = xgb_total_1, forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, year = year, forecast3= forecast3, forecast4 = forecast4, forecast5 = forecast5, forecast6 = forecast6)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict6\n",
    "\n",
    "def compare_perf_intensity_per_year_4cast(test, dict, xgb_tot, xgb_total, year, forecast2, forecast3, forecast4, basin = 'AN', forecast = 'SHIP', mode = 'vmax'):\n",
    "    baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "    if basin == 'EP':\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] < 2019].loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]\n",
    "    index = baseline_.index\n",
    "    baseline_1 = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    baseline_3 = baseline_[forecast3 + '_24_' + mode + '_7']\n",
    "    baseline_4 = baseline_[forecast4 + '_24_' + mode + '_7']\n",
    "    X_test_withBASELINE_total = np.array(test)[index]\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        print(\"Total number of steps for comparison: \", len(tgt_))\n",
    "        print(\"Year\", year, \"Basin\", basin, \"MAE intensity | std | busts > 20kn %\")\n",
    "        preds_1 = xgb_tot.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Hurr full: \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), np.around(np.std(tgt_ - preds), decimals=2), np.around(sum(abs(tgt_ - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(\"Hurr until 2012: \", np.around(mean_absolute_error(tgt_, preds_1), decimals = 2), np.around(np.std(tgt_ - preds_1), decimals=2), np.around(sum(abs(tgt_ - preds_1) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(forecast,\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), np.around(np.std(tgt_ - baseline_1), decimals = 2), np.around(sum(abs(tgt_ - baseline_1) > 20)/len(preds) * 100, decimals = 2))\n",
    "        if forecast2 != None:\n",
    "            print(forecast2,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_2), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_2), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_2) > 20)/len(preds) * 100, decimals = 2))\n",
    "            print(forecast3,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_3), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_3), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_3) > 20)/len(preds) * 100, decimals = 2))\n",
    "            print(forecast4,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_4), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_4), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_4) > 20)/len(preds) * 100, decimals = 2))\n",
    "\n",
    "        append_dict_intensity_4cast(dict, tgt_, preds, preds_1, baseline_1, baseline_2, baseline_3, baseline_4, year)\n",
    "        \n",
    "        \n",
    "def append_dict_intensity_4cast(dict, tgt_, preds, preds_1, baseline_1, baseline_2, baseline_3, baseline_4, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(tgt_))\n",
    "    dict['MAEs_full'].append(np.around(mean_absolute_error(tgt_, preds), decimals = 2))\n",
    "    dict['std_full'].append(np.around(np.std(tgt_ - preds), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(mean_absolute_error(tgt_, preds_1), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(mean_absolute_error(tgt_, baseline_2), decimals=2))\n",
    "    dict['std_HWRF'].append(np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "    dict['MAES_OFCL'].append(np.around(mean_absolute_error(tgt_, baseline_3), decimals=2))\n",
    "    dict['std_OFCL'].append(np.around(np.std(tgt_ - baseline_3), decimals=2))\n",
    "    dict['MAES_FSSE'].append(np.around(mean_absolute_error(tgt_, baseline_4), decimals=2))\n",
    "    dict['std_FSSE'].append(np.around(np.std(tgt_ - baseline_4), decimals=2))\n",
    "    \n",
    "def append_dict_intensity_6cast(dict, tgt_, preds, preds_1, baseline_1, baseline_2, baseline_3, baseline_4, baseline_5, baseline_6, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(tgt_))\n",
    "    dict['MAEs_full'].append(np.around(mean_absolute_error(tgt_, preds), decimals = 2))\n",
    "    dict['std_full'].append(np.around(np.std(tgt_ - preds), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(mean_absolute_error(tgt_, preds_1), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(mean_absolute_error(tgt_, baseline_2), decimals=2))\n",
    "    dict['std_HWRF'].append(np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "    dict['MAES_OFCL'].append(np.around(mean_absolute_error(tgt_, baseline_3), decimals=2))\n",
    "    dict['std_OFCL'].append(np.around(np.std(tgt_ - baseline_3), decimals=2))\n",
    "    dict['MAES_FSSE'].append(np.around(mean_absolute_error(tgt_, baseline_4), decimals=2))\n",
    "    dict['std_FSSE'].append(np.around(np.std(tgt_ - baseline_4), decimals=2))\n",
    "    dict['MAES_GFSO'].append(np.around(mean_absolute_error(tgt_, baseline_5), decimals=2))\n",
    "    dict['std_GFSO'].append(np.around(np.std(tgt_ - baseline_5), decimals=2))\n",
    "    dict['MAES_DSHP'].append(np.around(mean_absolute_error(tgt_, baseline_6), decimals=2))\n",
    "    dict['std_DSHP'].append(np.around(np.std(tgt_ - baseline_6), decimals=2))\n",
    "    \n",
    "    \n",
    "def compare_perf_intensity_per_year_6cast(test, dict, xgb_tot, xgb_total, year, forecast2, forecast3, forecast4, forecast5, forecast6, basin = 'AN', forecast = 'SHIP'):\n",
    "    mode = 'vmax'\n",
    "    baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "    if basin == 'EP':\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] < 2019].loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]\n",
    "    index = baseline_.index\n",
    "    baseline_1 = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    baseline_3 = baseline_[forecast3 + '_24_' + mode + '_7']\n",
    "    baseline_4 = baseline_[forecast4 + '_24_' + mode + '_7']\n",
    "    baseline_5 = baseline_[forecast5 + '_24_' + mode + '_7']\n",
    "    baseline_6 = baseline_[forecast6 + '_24_' + mode + '_7']\n",
    "    X_test_withBASELINE_total = np.array(test)[index]\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        print(\"Total number of steps for comparison: \", len(tgt_))\n",
    "        print(\"Year\", year, \"Basin\", basin, \"MAE intensity | std | busts > 20kn %\")\n",
    "        preds_1 = xgb_tot.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Hurr full: \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), np.around(np.std(tgt_ - preds), decimals=2), np.around(sum(abs(tgt_ - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(\"Hurr until 2012: \", np.around(mean_absolute_error(tgt_, preds_1), decimals = 2), np.around(np.std(tgt_ - preds_1), decimals=2), np.around(sum(abs(tgt_ - preds_1) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(forecast,\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), np.around(np.std(tgt_ - baseline_1), decimals = 2), np.around(sum(abs(tgt_ - baseline_1) > 20)/len(preds) * 100, decimals = 2))\n",
    "        if forecast2 != None:\n",
    "            print(forecast2,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_2), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_2), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_2) > 20)/len(preds) * 100, decimals = 2))\n",
    "            print(forecast3,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_3), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_3), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_3) > 20)/len(preds) * 100, decimals = 2))\n",
    "            print(forecast4,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_4), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_4), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_4) > 20)/len(preds) * 100, decimals = 2))\n",
    "            print(forecast5,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_5), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_5), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_5) > 20)/len(preds) * 100, decimals = 2))\n",
    "            print(forecast6,\n",
    "                np.around(mean_absolute_error(tgt_, baseline_6), decimals=2),\n",
    "                np.around(np.std(tgt_ - baseline_6), decimals=2),\n",
    "                np.around(sum(abs(tgt_ - baseline_6) > 20)/len(preds) * 100, decimals = 2))\n",
    "\n",
    "        append_dict_intensity_6cast(dict, tgt_, preds, preds_1, baseline_1, baseline_2, baseline_3, baseline_4, baseline_5, baseline_6, year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN\n",
    "{'MAES_2012': [9.11, 11.78, 6.65, 8.61, 10.93, 12.33, 9.77, 10.26],\n",
    " 'MAES_FSSE': [10.37, 8.56, 8.16, 8.0, 8.87, 7.72, 8.82, 8.73],\n",
    " 'MAES_HWRF': [9.56, 19.31, 7.02, 9.52, 10.38, 12.32, 10.79, 10.89],\n",
    " 'MAES_OFCL': [9.02, 14.06, 6.7, 7.93, 8.42, 8.59, 8.53, 8.55],\n",
    " 'MAES_SHIP': [8.1, 9.31, 12.13, 9.44, 10.11, 10.05, 8.8, 9.89],\n",
    " 'MAEs_full': [8.84, 12.67, 6.66, 8.67, 11.06, 12.26, 9.78, 10.37],\n",
    " 'num_samples': [41, 8, 72, 122, 231, 228, 236, 208],\n",
    " 'std_2012': [11.11, 10.61, 8.11, 11.71, 14.56, 15.76, 12.47, 13.18],\n",
    " 'std_FSSE': [11.62, 8.28, 8.09, 11.84, 12.22, 10.07, 12.16, 11.42],\n",
    " 'std_HWRF': [10.79, 12.82, 8.36, 12.95, 14.57, 17.27, 14.97, 14.22],\n",
    " 'std_OFCL': [11.36, 5.44, 8.39, 11.75, 11.4, 11.83, 12.1, 11.53],\n",
    " 'std_SHIP': [11.14, 9.22, 13.58, 13.77, 14.34, 12.65, 12.37, 12.68],\n",
    " 'std_full': [11.07, 11.07, 8.17, 11.44, 14.53, 15.52, 12.79, 13.47],\n",
    " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}\n",
    "\n",
    "{'MAES_2012': [9.55, 13.23, 6.83, 8.68, 11.24, 12.18, 9.73, 10.28],\n",
    " 'MAES_FSSE': [10.37, 8.56, 8.16, 8.0, 8.87, 7.72, 8.82, 8.73],\n",
    " 'MAES_HWRF': [9.56, 19.31, 7.02, 9.52, 10.38, 12.32, 10.79, 10.89],\n",
    " 'MAES_OFCL': [9.02, 14.06, 6.7, 7.93, 8.42, 8.59, 8.53, 8.55],\n",
    " 'MAES_SHIP': [8.1, 9.31, 12.13, 9.44, 10.11, 10.05, 8.8, 9.89],\n",
    " 'MAEs_full': [8.91, 10.02, 6.48, 8.52, 11.21, 12.37, 9.83, 10.32],\n",
    " 'num_samples': [41, 8, 72, 122, 231, 228, 236, 208],\n",
    " 'std_2012': [11.84, 13.37, 8.25, 11.73, 14.86, 15.6, 12.56, 13.21],\n",
    " 'std_FSSE': [11.62, 8.28, 8.09, 11.84, 12.22, 10.07, 12.16, 11.42],\n",
    " 'std_HWRF': [10.79, 12.82, 8.36, 12.95, 14.57, 17.27, 14.97, 14.22],\n",
    " 'std_OFCL': [11.36, 5.44, 8.39, 11.75, 11.4, 11.83, 12.1, 11.53],\n",
    " 'std_SHIP': [11.14, 9.22, 13.58, 13.77, 14.34, 12.65, 12.37, 12.68],\n",
    " 'std_full': [11.27, 9.2, 8.01, 11.47, 14.47, 15.82, 12.74, 13.53],\n",
    " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}\n",
    "\n",
    "{'MAES_2012': [8.56, 11.37, 6.81, 8.61, 11.04, 12.08, 9.75, 10.55],\n",
    " 'MAES_FSSE': [10.37, 8.56, 8.16, 8.0, 8.87, 7.72, 8.82, 8.73],\n",
    " 'MAES_HWRF': [9.56, 19.31, 7.02, 9.52, 10.38, 12.32, 10.79, 10.89],\n",
    " 'MAES_OFCL': [9.02, 14.06, 6.7, 7.93, 8.42, 8.59, 8.53, 8.55],\n",
    " 'MAES_SHIP': [8.1, 9.31, 12.13, 9.44, 10.11, 10.05, 8.8, 9.89],\n",
    " 'MAEs_full': [9.27, 12.28, 6.51, 8.46, 11.25, 12.26, 9.72, 10.41],\n",
    " 'num_samples': [41, 8, 72, 122, 231, 228, 236, 208],\n",
    " 'std_2012': [10.97, 11.19, 8.34, 11.75, 14.43, 15.63, 12.67, 13.55],\n",
    " 'std_FSSE': [11.62, 8.28, 8.09, 11.84, 12.22, 10.07, 12.16, 11.42],\n",
    " 'std_HWRF': [10.79, 12.82, 8.36, 12.95, 14.57, 17.27, 14.97, 14.22],\n",
    " 'std_OFCL': [11.36, 5.44, 8.39, 11.75, 11.4, 11.83, 12.1, 11.53],\n",
    " 'std_SHIP': [11.14, 9.22, 13.58, 13.77, 14.34, 12.65, 12.37, 12.68],\n",
    " 'std_full': [11.91, 9.89, 7.98, 11.16, 14.44, 15.64, 12.85, 13.57],\n",
    " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP\n",
    "{'MAES_2012': [22.5, 10.2, 12.01, 9.93, 8.98, 12.73, 4.08],\n",
    " 'MAES_FSSE': [10.67, 10.01, 10.66, 8.51, 7.92, 9.82, 24.89],\n",
    " 'MAES_HWRF': [27.0, 12.02, 13.06, 9.87, 9.97, 12.92, 25.58],\n",
    " 'MAES_OFCL': [10.0, 9.73, 10.89, 8.72, 8.14, 10.18, 26.6],\n",
    " 'MAES_SHIP': [11.33, 11.41, 12.28, 10.38, 7.87, 10.92, 21.71],\n",
    " 'MAEs_full': [20.61, 10.28, 11.46, 9.78, 9.12, 12.17, 3.87],\n",
    " 'num_samples': [6, 273, 274, 315, 167, 357, 40],\n",
    " 'std_2012': [8.98, 13.79, 16.12, 13.36, 12.98, 16.46, 4.31],\n",
    " 'std_FSSE': [12.78, 13.07, 14.73, 11.53, 10.67, 12.65, 20.87],\n",
    " 'std_HWRF': [13.22, 15.44, 17.95, 12.84, 13.0, 15.86, 21.77],\n",
    " 'std_OFCL': [13.74, 13.45, 15.91, 11.89, 11.67, 13.44, 23.02],\n",
    " 'std_SHIP': [9.29, 14.57, 17.5, 13.74, 11.61, 14.83, 21.95],\n",
    " 'std_full': [7.0, 13.89, 15.63, 13.48, 12.95, 15.74, 3.92],\n",
    " 'year': [2013, 2014, 2015, 2016, 2017, 2018, 2019]}\n",
    "\n",
    "{'MAES_2012': [22.98, 10.18, 11.94, 9.86, 9.07, 12.7, 4.16],\n",
    " 'MAES_FSSE': [10.67, 10.01, 10.66, 8.51, 7.92, 9.82, 24.89],\n",
    " 'MAES_HWRF': [27.0, 12.02, 13.06, 9.87, 9.97, 12.92, 25.58],\n",
    " 'MAES_OFCL': [10.0, 9.73, 10.89, 8.72, 8.14, 10.18, 26.6],\n",
    " 'MAES_SHIP': [11.33, 11.41, 12.28, 10.38, 7.87, 10.92, 21.71],\n",
    " 'MAEs_full': [20.71, 10.24, 11.46, 9.77, 9.11, 12.19, 4.18],\n",
    " 'num_samples': [6, 273, 274, 315, 167, 357, 40],\n",
    " 'std_2012': [9.24, 13.75, 16.04, 13.31, 13.08, 16.45, 4.4],\n",
    " 'std_FSSE': [12.78, 13.07, 14.73, 11.53, 10.67, 12.65, 20.87],\n",
    " 'std_HWRF': [13.22, 15.44, 17.95, 12.84, 13.0, 15.86, 21.77],\n",
    " 'std_OFCL': [13.74, 13.45, 15.91, 11.89, 11.67, 13.44, 23.02],\n",
    " 'std_SHIP': [9.29, 14.57, 17.5, 13.74, 11.61, 14.83, 21.95],\n",
    " 'std_full': [7.0, 13.87, 15.62, 13.45, 12.97, 15.76, 4.04],\n",
    " 'year': [2013, 2014, 2015, 2016, 2017, 2018, 2019]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.61, 10.28, 11.46, 9.78, 9.12, 12.17, 3.87]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(([22.5, 10.2, 12.01, 9.93, 8.98, 12.73, 4.08], [22.98, 10.18, 11.94, 9.86, 9.07, 12.7, 4.16], [20.71, 10.24, 11.46, 9.77, 9.11, 12.19, 4.18], [20.61, 10.28, 11.46, 9.78, 9.12, 12.17, 3.87]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 8\n",
    "predict_at = 16\n",
    "\n",
    "tgt_intensity_cat_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                      allow_pickle=True))\n",
    "tgt_intensity_cat_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "\n",
    "tgt_intensity_train = torch.Tensor(np.load('../data/y_train_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                  allow_pickle=True))\n",
    "tgt_intensity_test = torch.Tensor(np.load('../data/y_test_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                 allow_pickle=True))\n",
    "\n",
    "tgt_intensity_cat_baseline_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',  allow_pickle = True))\n",
    "tgt_intensity_cat_baseline_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train_unst = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test_unst = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "\n",
    "mean_intensity = tgt_intensity_train.mean()\n",
    "std_intensity = tgt_intensity_train.std()\n",
    "tgt_intensity_train = (tgt_intensity_train - mean_intensity)/std_intensity\n",
    "tgt_intensity_test = (tgt_intensity_test - mean_intensity)/std_intensity\n",
    "\n",
    "\n",
    "###INTENSITY\n",
    "mean_dx = tgt_displacement_train[:,0].mean()\n",
    "std_dx = tgt_displacement_train[:,0].std()\n",
    "tgt_displacement_train[:,0] = (tgt_displacement_train[:,0] - mean_dx)/std_dx\n",
    "tgt_displacement_test[:,0] = (tgt_displacement_test[:,0] - mean_dx)/std_dx\n",
    "std_dx = float(std_dx)\n",
    "mean_dx = float(mean_dx)\n",
    "\n",
    "mean_dy = tgt_displacement_train[:,1].mean()\n",
    "std_dy = tgt_displacement_train[:,1].std()\n",
    "tgt_displacement_train[:,1] = (tgt_displacement_train[:,1] - mean_dy)/std_dy\n",
    "tgt_displacement_test[:,1] = (tgt_displacement_test[:,1] - mean_dy)/std_dy\n",
    "std_dy = float(std_dy)\n",
    "mean_dy = float(mean_dy)\n",
    "\n",
    "X_train = np.load('../data/X_train_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "X_test = np.load('../data/X_test_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'cat_cos_day', 'cat_sign_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
    "         'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'cat_storm_category', 'cat_basin_AN',\n",
    "         'cat_basin_EP', 'cat_basin_NI', 'cat_basin_SA',\n",
    "         'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "         'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "         'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i // 30)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-2:] == '_0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]\n",
    "\n",
    "\n",
    "X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_48_2012_v2_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "#X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_all_48_clean_w8_at_16.npy', allow_pickle=True))\n",
    "\n",
    "names_baselines = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'DSHP_48_lat', 'DSHP_48_lon', 'DSHP_48_vmax', 'DSHP_48_mslp', 'DSHP_48_COS_LAT', 'DSHP_48_SIN_LAT', 'DSHP_48_COS_LON', 'DSHP_48_SIN_LON', 'OFCL_48_lat', 'OFCL_48_lon', 'OFCL_48_vmax', 'OFCL_48_mslp', 'OFCL_48_COS_LAT', 'OFCL_48_SIN_LAT', 'OFCL_48_COS_LON', 'OFCL_48_SIN_LON', 'UKXI_48_lat', 'UKXI_48_lon', 'UKXI_48_vmax', 'UKXI_48_mslp', 'UKXI_48_COS_LAT', 'UKXI_48_SIN_LAT', 'UKXI_48_COS_LON', 'UKXI_48_SIN_LON', 'CMC_48_lat', 'CMC_48_lon', 'CMC_48_vmax', 'CMC_48_mslp', 'CMC_48_COS_LAT', 'CMC_48_SIN_LAT', 'CMC_48_COS_LON', 'CMC_48_SIN_LON', 'SHIP_48_lat', 'SHIP_48_lon', 'SHIP_48_vmax', 'SHIP_48_mslp', 'SHIP_48_COS_LAT', 'SHIP_48_SIN_LAT', 'SHIP_48_COS_LON', 'SHIP_48_SIN_LON', 'FSSE_48_lat', 'FSSE_48_lon', 'FSSE_48_vmax', 'FSSE_48_mslp', 'FSSE_48_COS_LAT', 'FSSE_48_SIN_LAT', 'FSSE_48_COS_LON', 'FSSE_48_SIN_LON', 'CLP5_48_lat', 'CLP5_48_lon', 'CLP5_48_vmax', 'CLP5_48_mslp', 'CLP5_48_COS_LAT', 'CLP5_48_SIN_LAT', 'CLP5_48_COS_LON', 'CLP5_48_SIN_LON', 'AEMN_48_lat', 'AEMN_48_lon', 'AEMN_48_vmax', 'AEMN_48_mslp', 'AEMN_48_COS_LAT', 'AEMN_48_SIN_LAT', 'AEMN_48_COS_LON', 'AEMN_48_SIN_LON', 'LBAR_48_lat', 'LBAR_48_lon', 'LBAR_48_vmax', 'LBAR_48_mslp', 'LBAR_48_COS_LAT', 'LBAR_48_SIN_LAT', 'LBAR_48_COS_LON', 'LBAR_48_SIN_LON', 'GFDL_48_lat', 'GFDL_48_lon', 'GFDL_48_vmax', 'GFDL_48_mslp', 'GFDL_48_COS_LAT', 'GFDL_48_SIN_LAT', 'GFDL_48_COS_LON', 'GFDL_48_SIN_LON', 'HWRF_48_lat', 'HWRF_48_lon', 'HWRF_48_vmax', 'HWRF_48_mslp', 'HWRF_48_COS_LAT', 'HWRF_48_SIN_LAT', 'HWRF_48_COS_LON', 'HWRF_48_SIN_LON', 'NGPS_48_lat', 'NGPS_48_lon', 'NGPS_48_vmax', 'NGPS_48_mslp', 'NGPS_48_COS_LAT', 'NGPS_48_SIN_LAT', 'NGPS_48_COS_LON', 'NGPS_48_SIN_LON', 'DISPLACEMENT_LAT_CLP5_48', 'DISPLACEMENT_LON_CLP5_48', 'DISPLACEMENT_LAT_SHIP_48', 'DISPLACEMENT_LON_SHIP_48', 'DISPLACEMENT_LAT_DSHP_48', 'DISPLACEMENT_LON_DSHP_48', 'DISPLACEMENT_LAT_LBAR_48', 'DISPLACEMENT_LON_LBAR_48', 'DISPLACEMENT_LAT_CMC_48', 'DISPLACEMENT_LON_CMC_48', 'DISPLACEMENT_LAT_NGPS_48', 'DISPLACEMENT_LON_NGPS_48', 'DISPLACEMENT_LAT_GFDL_48', 'DISPLACEMENT_LON_GFDL_48', 'DISPLACEMENT_LAT_HWRF_48', 'DISPLACEMENT_LON_HWRF_48', 'DISPLACEMENT_LAT_UKXI_48', 'DISPLACEMENT_LON_UKXI_48', 'DISPLACEMENT_LAT_FSSE_48', 'DISPLACEMENT_LON_FSSE_48', 'DISPLACEMENT_LAT_AEMN_48', 'DISPLACEMENT_LON_AEMN_48', 'DISPLACEMENT_LAT_OFCL_48', 'DISPLACEMENT_LON_OFCL_48', 'EMXI_48_lat', 'EMXI_48_lon', 'EMXI_48_vmax', 'EMXI_48_mslp', 'EMXI_48_COS_LAT', 'EMXI_48_SIN_LAT', 'EMXI_48_COS_LON', 'EMXI_48_SIN_LON', 'DISPLACEMENT_LAT_EMXI_48', 'DISPLACEMENT_LON_EMXI_48', 'GFSO_48_lat', 'GFSO_48_lon', 'GFSO_48_vmax', 'GFSO_48_mslp', 'GFSO_48_COS_LAT', 'GFSO_48_SIN_LAT', 'GFSO_48_COS_LON', 'GFSO_48_SIN_LON', 'DISPLACEMENT_LAT_GFSO_48', 'DISPLACEMENT_LON_GFSO_48', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SI', 'basin_SP', 'basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "\n",
    "names_all_baselines = names_baselines * 8#args.window_size\n",
    "\n",
    "for i in range(len(names_all_baselines)):\n",
    "    names_all_baselines[i] += '_' + str(i // 167)\n",
    "\n",
    "X_test_baseline.columns = names_all_baselines\n",
    "\n",
    "\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "\n",
    "X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "\n",
    "X_train_total = np.concatenate((X_train, X_train_embed), axis = 1)\n",
    "X_test_total = np.concatenate((X_test, X_test_embed), axis = 1)\n",
    "\n",
    "std_ = float(std_intensity)\n",
    "mean_ = float(mean_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_48_2012_v2_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#48 EP\n",
    "{'MAES_2012': [16.65, 17.68, 16.56, 11.43, 19.61, 4.58],\n",
    " 'MAES_FSSE': [13.57, 11.64, 11.12, 10.34, 12.83, 20.76],\n",
    " 'MAES_HWRF': [15.53, 14.44, 12.54, 11.16, 17.52, 23.69],\n",
    " 'MAES_OFCL': [13.61, 11.26, 11.24, 9.75, 12.56, 21.23],\n",
    " 'MAES_SHIP': [13.46, 12.75, 11.17, 8.35, 12.59, 16.01],\n",
    " 'MAEs_full': [16.16, 15.76, 16.23, 10.34, 19.29, 5.3],\n",
    " 'num_samples': [205, 221, 259, 140, 315, 37],\n",
    " 'std_2012': [20.16, 19.65, 21.14, 13.71, 23.47, 5.77],\n",
    " 'std_FSSE': [15.51, 15.72, 14.16, 12.57, 15.3, 19.16],\n",
    " 'std_HWRF': [19.13, 18.8, 15.9, 13.02, 20.54, 19.81],\n",
    " 'std_OFCL': [16.65, 16.08, 14.69, 11.23, 16.02, 19.8],\n",
    " 'std_SHIP': [16.03, 15.94, 15.2, 10.66, 16.6, 17.82],\n",
    " 'std_full': [19.51, 17.97, 20.97, 12.3, 23.67, 6.5],\n",
    " 'year': [2014, 2015, 2016, 2017, 2018, 2019]}\n",
    "\n",
    "#48 AN\n",
    "{'MAES_2012': [11.17, 23.33, 12.2, 16.07, 16.78, 17.89, 17.38, 16.59],\n",
    " 'MAES_FSSE': [10.53, 16.12, 10.41, 9.23, 10.76, 9.37, 12.62, 10.07],\n",
    " 'MAES_HWRF': [10.39, 37.12, 10.97, 11.8, 12.48, 16.58, 16.25, 15.48],\n",
    " 'MAES_OFCL': [7.23, 15.62, 7.62, 9.06, 9.77, 11.26, 11.65, 10.31],\n",
    " 'MAES_SHIP': [8.2, 14.62, 12.7, 10.04, 11.38, 11.85, 11.81, 12.3],\n",
    " 'MAEs_full': [11.05, 19.54, 12.24, 15.34, 17.2, 18.07, 17.68, 16.88],\n",
    " 'num_samples': [37, 4, 61, 101, 200, 200, 200, 179],\n",
    " 'std_2012': [13.25, 8.36, 14.72, 21.36, 20.42, 21.7, 22.88, 20.23],\n",
    " 'std_FSSE': [9.93, 9.36, 10.75, 12.95, 14.56, 12.63, 17.08, 12.78],\n",
    " 'std_HWRF': [12.46, 11.24, 12.74, 15.01, 17.19, 22.44, 20.24, 18.51],\n",
    " 'std_OFCL': [9.64, 2.07, 9.51, 12.34, 13.33, 14.9, 17.13, 13.26],\n",
    " 'std_SHIP': [9.99, 11.62, 14.58, 14.63, 16.17, 14.8, 17.3, 16.36],\n",
    " 'std_full': [12.09, 9.04, 14.51, 20.63, 20.63, 21.95, 23.03, 20.49],\n",
    " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table intensity AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "n = X_test_baseline.shape[0]\n",
    "X_test_total = X_test_total[-n:]\n",
    "tgt_intensity_test = tgt_intensity_test[-n:]\n",
    "X_test = X_test[-n:]\n",
    "X_test_embed = X_test_embed[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict6 = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[], 'MAES_GFSO':[], 'std_GFSO':[], 'MAES_DSHP':[], 'std_DSHP':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.9 14.19 14.5\n",
      "Hurr until 2012:  10.9 14.19 14.5\n",
      "SHIP 11.36 15.61 18.39\n",
      "HWRF 9.67 12.65 11.81\n",
      "OFCL 8.62 11.91 9.57\n",
      "FSSE 8.51 11.37 7.62\n",
      "GFSO 14.15 15.78 23.02\n",
      "DSHP 10.35 13.67 15.84\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.2 15.29 16.48\n",
      "Hurr until 2012:  11.2 15.29 16.48\n",
      "SHIP 12.04 15.31 18.58\n",
      "HWRF 10.05 14.11 14.37\n",
      "OFCL 9.62 13.06 11.88\n",
      "FSSE 9.32 12.49 11.11\n",
      "GFSO 17.13 19.83 33.33\n",
      "DSHP 11.92 15.21 18.58\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS + ONLY AN EP in training + only more than. 40kn winds\n",
    "index_t = X_train.loc[X_train['cat_basin_AN_0'] + X_train['cat_basin_EP_0'] == 1].loc[X_train['WMO_WIND_7'] > 34].index\n",
    "index_te = X_test[:17094].loc[X_test['cat_basin_AN_0'] + X_test['cat_basin_EP_0'] == 1].loc[X_test['WMO_WIND_7'] > 34].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te]), axis = 0)\n",
    "tgt_train = np.concatenate((tgt_intensity_train[index_t], tgt_intensity_test[index_te]), axis = 0)\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=6, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=1)\n",
    "xgb_total.fit(train, tgt_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.73 13.93 13.9\n",
      "Hurr until 2012:  10.73 13.93 13.9\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.09 15.07 15.52\n",
      "Hurr until 2012:  11.09 15.07 15.52\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "index_t = X_train.loc[X_train['cat_basin_AN_0'] + X_train['cat_basin_EP_0'] == 1].loc[X_train['WMO_WIND_7'] > 34].index\n",
    "index_te = X_test[:17094].loc[X_test['cat_basin_AN_0'] + X_test['cat_basin_EP_0'] == 1].loc[X_test['WMO_WIND_7'] > 34].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te]), axis = 0)\n",
    "tgt_train = np.array(((np.concatenate((tgt_intensity_train[index_t], tgt_intensity_test[index_te]), axis = 0))*float(std_intensity)+float(mean_intensity)-mean_)/std_)\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=1)\n",
    "xgb_total.fit(train, tgt_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.69 14.04 14.2\n",
      "Hurr until 2012:  10.69 14.04 14.2\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.11 15.17 16.86\n",
      "Hurr until 2012:  11.11 15.17 16.86\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS\n",
    "index_t = X_train.loc[X_train['WMO_WIND_7'] > 40].index\n",
    "index_te = X_test[:17094].loc[X_test['WMO_WIND_7'] > 40].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te]), axis = 0)\n",
    "tgt_train = np.concatenate((tgt_intensity_train[index_t], tgt_intensity_test[index_te]), axis = 0)\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=5)\n",
    "xgb_total.fit(train, tgt_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.06 14.57 14.95\n",
      "Hurr until 2012:  11.06 14.57 14.95\n",
      "SHIP 11.36 15.61 18.39\n",
      "HWRF 9.67 12.65 11.81\n",
      "OFCL 8.62 11.91 9.57\n",
      "FSSE 8.51 11.37 7.62\n",
      "GFSO 14.15 15.78 23.02\n",
      "DSHP 10.35 13.67 15.84\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.58 15.83 18.39\n",
      "Hurr until 2012:  11.58 15.83 18.39\n",
      "SHIP 12.04 15.31 18.58\n",
      "HWRF 10.05 14.11 14.37\n",
      "OFCL 9.62 13.06 11.88\n",
      "FSSE 9.32 12.49 11.11\n",
      "GFSO 17.13 19.83 33.33\n",
      "DSHP 11.92 15.21 18.58\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS\n",
    "train = np.concatenate((X_train_total, X_test_total[:17094]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=6)#9, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=1, colsample_bytree = 0.7)\n",
    "xgb_total.fit(train, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54']\nexpected f69, f536, f629, f402, f509, f623, f280, f606, f528, f514, f595, f256, f326, f203, f151, f322, f563, f179, f524, f209, f429, f494, f273, f305, f201, f122, f214, f481, f227, f332, f311, f582, f220, f462, f291, f288, f155, f589, f442, f210, f149, f444, f335, f124, f133, f74, f612, f419, f150, f178, f578, f600, f290, f503, f375, f191, f172, f553, f531, f331, f495, f182, f377, f418, f139, f85, f572, f217, f378, f471, f552, f603, f63, f261, f358, f483, f576, f625, f611, f321, f496, f107, f106, f545, f438, f363, f282, f417, f616, f89, f83, f500, f638, f207, f367, f535, f570, f310, f538, f519, f303, f268, f592, f537, f361, f385, f298, f405, f466, f497, f348, f265, f186, f617, f501, f518, f482, f81, f231, f181, f590, f391, f376, f511, f350, f243, f588, f468, f626, f394, f407, f318, f574, f287, f264, f488, f154, f90, f283, f477, f252, f520, f492, f432, f199, f505, f109, f381, f493, f548, f241, f156, f372, f349, f219, f408, f97, f235, f67, f275, f567, f403, f267, f594, f529, f307, f87, f60, f560, f176, f184, f440, f330, f541, f248, f568, f237, f164, f262, f66, f436, f258, f120, f457, f425, f131, f502, f631, f320, f61, f454, f615, f170, f57, f370, f453, f472, f387, f132, f206, f404, f474, f129, f533, f319, f424, f59, f628, f580, f369, f556, f450, f362, f301, f327, f224, f103, f56, f211, f234, f575, f415, f605, f610, f448, f126, f400, f412, f141, f229, f542, f153, f142, f115, f344, f162, f146, f489, f441, f98, f451, f455, f308, f384, f272, f266, f250, f86, f389, f91, f324, f608, f516, f508, f246, f285, f420, f323, f65, f426, f473, f452, f79, f355, f346, f459, f84, f619, f286, f294, f289, f382, f94, f117, f583, f160, f300, f490, f113, f523, f395, f380, f135, f134, f507, f598, f80, f185, f577, f521, f515, f564, f110, f165, f251, f75, f406, f315, f223, f467, f599, f187, f540, f218, f255, f630, f428, f137, f366, f82, f360, f121, f357, f602, f276, f392, f314, f561, f339, f510, f551, f192, f71, f435, f622, f233, f597, f102, f245, f338, f183, f585, f437, f447, f411, f180, f204, f423, f499, f546, f562, f458, f136, f299, f78, f364, f263, f143, f169, f398, f101, f215, f232, f105, f130, f636, f161, f383, f166, f174, f96, f337, f543, f491, f409, f433, f64, f208, f147, f416, f565, f621, f152, f88, f569, f116, f260, f302, f413, f480, f202, f484, f373, f228, f368, f62, f421, f593, f296, f464, f197, f293, f99, f340, f168, f465, f506, f138, f171, f352, f427, f469, f639, f242, f479, f157, f336, f158, f277, f354, f587, f58, f527, f279, f476, f77, f127, f284, f445, f460, f304, f434, f504, f325, f422, f443, f635, f550, f393, f177, f547, f313, f278, f414, f456, f173, f430, f581, f140, f112, f386, f334, f119, f114, f100, f200, f549, f269, f613, f539, f431, f359, f591, f125, f247, f557, f70, f371, f607, f216, f396, f341, f554, f55, f195, f586, f463, f198, f618, f244, f487, f73, f236, f167, f253, f144, f449, f624, f351, f205, f225, f475, f118, f534, f274, f240, f530, f190, f196, f333, f637, f92, f238, f525, f526, f634, f111, f532, f249, f297, f123, f222, f342, f498, f517, f343, f573, f486, f461, f571, f188, f410, f270, f470, f614, f221, f72, f633, f259, f401, f95, f632, f544, f356, f390, f512, f604, f317, f446, f522, f365, f312, f145, f379, f439, f68, f555, f271, f609, f108, f374, f93, f76, f175, f189, f345, f579, f281, f292, f627, f257, f316, f347, f397, f239, f212, f329, f128, f566, f388, f194, f309, f104, f478, f584, f596, f306, f485, f213, f148, f399, f353, f193, f559, f558, f230, f601, f295, f328, f163, f254, f226, f513, f159, f620 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-7158ae8b0aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxgb_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_train5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcompare_perf_intensity_per_year_6cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SHIP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HWRF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OFCL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FSSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'GFSO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DSHP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcompare_perf_intensity_per_year_6cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SHIP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'HWRF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'OFCL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FSSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'GFSO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DSHP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2017\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-f46c40355c47>\u001b[0m in \u001b[0;36mcompare_perf_intensity_per_year_6cast\u001b[0;34m(test, dict, xgb_tot, xgb_total, year, forecast2, forecast3, forecast4, forecast5, forecast6, basin, forecast)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total number of steps for comparison: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Basin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MAE intensity | std | busts > 20kn %\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mpreds_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_tot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_withBASELINE_total\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_withBASELINE_total\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m#print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                           validate_features=validate_features)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 2131\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m     def get_split_value_histogram(self, feature, fmap='', bins=None,\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499', 'f500', 'f501', 'f502', 'f503', 'f504', 'f505', 'f506', 'f507', 'f508', 'f509', 'f510', 'f511', 'f512', 'f513', 'f514', 'f515', 'f516', 'f517', 'f518', 'f519', 'f520', 'f521', 'f522', 'f523', 'f524', 'f525', 'f526', 'f527', 'f528', 'f529', 'f530', 'f531', 'f532', 'f533', 'f534', 'f535', 'f536', 'f537', 'f538', 'f539', 'f540', 'f541', 'f542', 'f543', 'f544', 'f545', 'f546', 'f547', 'f548', 'f549', 'f550', 'f551', 'f552', 'f553', 'f554', 'f555', 'f556', 'f557', 'f558', 'f559', 'f560', 'f561', 'f562', 'f563', 'f564', 'f565', 'f566', 'f567', 'f568', 'f569', 'f570', 'f571', 'f572', 'f573', 'f574', 'f575', 'f576', 'f577', 'f578', 'f579', 'f580', 'f581', 'f582', 'f583', 'f584', 'f585', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f592', 'f593', 'f594', 'f595', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f602', 'f603', 'f604', 'f605', 'f606', 'f607', 'f608', 'f609', 'f610', 'f611', 'f612', 'f613', 'f614', 'f615', 'f616', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f625', 'f626', 'f627', 'f628', 'f629', 'f630', 'f631', 'f632', 'f633', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54']\nexpected f69, f536, f629, f402, f509, f623, f280, f606, f528, f514, f595, f256, f326, f203, f151, f322, f563, f179, f524, f209, f429, f494, f273, f305, f201, f122, f214, f481, f227, f332, f311, f582, f220, f462, f291, f288, f155, f589, f442, f210, f149, f444, f335, f124, f133, f74, f612, f419, f150, f178, f578, f600, f290, f503, f375, f191, f172, f553, f531, f331, f495, f182, f377, f418, f139, f85, f572, f217, f378, f471, f552, f603, f63, f261, f358, f483, f576, f625, f611, f321, f496, f107, f106, f545, f438, f363, f282, f417, f616, f89, f83, f500, f638, f207, f367, f535, f570, f310, f538, f519, f303, f268, f592, f537, f361, f385, f298, f405, f466, f497, f348, f265, f186, f617, f501, f518, f482, f81, f231, f181, f590, f391, f376, f511, f350, f243, f588, f468, f626, f394, f407, f318, f574, f287, f264, f488, f154, f90, f283, f477, f252, f520, f492, f432, f199, f505, f109, f381, f493, f548, f241, f156, f372, f349, f219, f408, f97, f235, f67, f275, f567, f403, f267, f594, f529, f307, f87, f60, f560, f176, f184, f440, f330, f541, f248, f568, f237, f164, f262, f66, f436, f258, f120, f457, f425, f131, f502, f631, f320, f61, f454, f615, f170, f57, f370, f453, f472, f387, f132, f206, f404, f474, f129, f533, f319, f424, f59, f628, f580, f369, f556, f450, f362, f301, f327, f224, f103, f56, f211, f234, f575, f415, f605, f610, f448, f126, f400, f412, f141, f229, f542, f153, f142, f115, f344, f162, f146, f489, f441, f98, f451, f455, f308, f384, f272, f266, f250, f86, f389, f91, f324, f608, f516, f508, f246, f285, f420, f323, f65, f426, f473, f452, f79, f355, f346, f459, f84, f619, f286, f294, f289, f382, f94, f117, f583, f160, f300, f490, f113, f523, f395, f380, f135, f134, f507, f598, f80, f185, f577, f521, f515, f564, f110, f165, f251, f75, f406, f315, f223, f467, f599, f187, f540, f218, f255, f630, f428, f137, f366, f82, f360, f121, f357, f602, f276, f392, f314, f561, f339, f510, f551, f192, f71, f435, f622, f233, f597, f102, f245, f338, f183, f585, f437, f447, f411, f180, f204, f423, f499, f546, f562, f458, f136, f299, f78, f364, f263, f143, f169, f398, f101, f215, f232, f105, f130, f636, f161, f383, f166, f174, f96, f337, f543, f491, f409, f433, f64, f208, f147, f416, f565, f621, f152, f88, f569, f116, f260, f302, f413, f480, f202, f484, f373, f228, f368, f62, f421, f593, f296, f464, f197, f293, f99, f340, f168, f465, f506, f138, f171, f352, f427, f469, f639, f242, f479, f157, f336, f158, f277, f354, f587, f58, f527, f279, f476, f77, f127, f284, f445, f460, f304, f434, f504, f325, f422, f443, f635, f550, f393, f177, f547, f313, f278, f414, f456, f173, f430, f581, f140, f112, f386, f334, f119, f114, f100, f200, f549, f269, f613, f539, f431, f359, f591, f125, f247, f557, f70, f371, f607, f216, f396, f341, f554, f55, f195, f586, f463, f198, f618, f244, f487, f73, f236, f167, f253, f144, f449, f624, f351, f205, f225, f475, f118, f534, f274, f240, f530, f190, f196, f333, f637, f92, f238, f525, f526, f634, f111, f532, f249, f297, f123, f222, f342, f498, f517, f343, f573, f486, f461, f571, f188, f410, f270, f470, f614, f221, f72, f633, f259, f401, f95, f632, f544, f356, f390, f512, f604, f317, f446, f522, f365, f312, f145, f379, f439, f68, f555, f271, f609, f108, f374, f93, f76, f175, f189, f345, f579, f281, f292, f627, f257, f316, f347, f397, f239, f212, f329, f128, f566, f388, f194, f309, f104, f478, f584, f596, f306, f485, f213, f148, f399, f353, f193, f559, f558, f230, f601, f295, f328, f163, f254, f226, f513, f159, f620 in input data"
     ]
    }
   ],
   "source": [
    "select = SelectFromModel(xgb_total, threshold=\"mean\", prefit=True)\n",
    "X_train_sparse = select.transform(train)\n",
    "X_test_sparse = select.transform(X_test_total)\n",
    "xgb_sparse = XGBRegressor(max_depth=6, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=5, colsample_bytree = 0.7)\n",
    "xgb_sparse.fit(np.array(X_train_sparse), tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(np.array(X_test_sparse), dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_sparse, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.11 14.19 15.84\n",
      "Hurr until 2012:  11.11 14.19 15.84\n",
      "SHIP 11.36 15.61 18.39\n",
      "HWRF 9.67 12.65 11.81\n",
      "OFCL 8.62 11.91 9.57\n",
      "FSSE 8.51 11.37 7.62\n",
      "GFSO 14.15 15.78 23.02\n",
      "DSHP 10.35 13.67 15.84\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.99 16.21 19.54\n",
      "Hurr until 2012:  11.99 16.21 19.54\n",
      "SHIP 12.04 15.31 18.58\n",
      "HWRF 10.05 14.11 14.37\n",
      "OFCL 9.62 13.06 11.88\n",
      "FSSE 9.32 12.49 11.11\n",
      "GFSO 17.13 19.83 33.33\n",
      "DSHP 11.92 15.21 18.58\n"
     ]
    }
   ],
   "source": [
    "#TRAIN UNTIL 2012\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=5, colsample_bytree = 0.7)\n",
    "xgb_total.fit(X_train_total, tgt_intensity_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.68 13.82 14.05\n",
      "Hurr until 2012:  10.68 13.82 14.05\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.45 15.63 18.01\n",
      "Hurr until 2012:  11.45 15.63 18.01\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#TABULAR ONLY\n",
    "train2 = np.concatenate((X_train, X_test[:17094]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=150, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_total.fit(train2, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.27 14.57 15.4\n",
      "Hurr until 2012:  11.27 14.57 15.4\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.28 15.42 18.01\n",
      "Hurr until 2012:  11.28 15.42 18.01\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#EMBED ONLY\n",
    "train2 = np.concatenate((X_train_embed, X_test_embed[:17094]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=150, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_total.fit(train2, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test_embed, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_embed, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.83 14.65 15.7\n",
      "Hurr until 2012:  10.83 14.65 15.7\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.03 13.29 12.64\n",
      "Hurr until 2012:  10.03 13.29 12.64\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#USING OFCL\n",
    "train = np.concatenate((X_test_baseline[:17094], X_test_total[:17094]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[:17094]\n",
    "test = np.concatenate((X_test_baseline, X_test_total), axis = 1)\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=5)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  672\n",
      "Year 2017 MAE intensity basin AN\n",
      "Hurricast trained full:  9.37 with std  13.12 11.31\n",
      "Hurricast trained until 2012:  9.37 with std  13.12 11.31\n",
      "Official Forecast  SHIP 11.34 with std  15.62 17.41\n",
      " Official Forecast  HWRF 9.56 with std  12.56 11.16\n",
      " Official Forecast OFCL 8.55 with std  11.84 7.29\n",
      "Official Forecast FSSE 8.42 with std  11.27 7.29\n",
      "Total number of steps for comparison:  564\n",
      "Year 2017 MAE intensity basin EP\n",
      "Hurricast trained full:  9.41 with std  12.39 10.64\n",
      "Hurricast trained until 2012:  9.41 with std  12.39 10.64\n",
      "Official Forecast  SHIP 12.94 with std  17.1 19.5\n",
      " Official Forecast  HWRF 10.78 with std  15.66 16.31\n",
      " Official Forecast OFCL 10.74 with std  15.19 11.17\n",
      "Official Forecast FSSE 10.33 with std  14.59 13.12\n"
     ]
    }
   ],
   "source": [
    "#OFCL ONLY\n",
    "#train = np.array(X_test_baseline[:17094])\n",
    "#tgt_train3 = tgt_intensity_test[:17094]\n",
    "train = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "tgt_train3 = tgt_intensity_test[train.index]\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=300, learning_rate=0.03, subsample=0.55, min_child_weight=1)\n",
    "xgb_total.fit(np.array(train), tgt_train3)\n",
    "compare_perf_intensity_per_year_4cast(X_test_baseline, dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2017)\n",
    "#xgb_total = XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.7, min_child_weight=7)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_4cast(X_test_baseline, dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.32 14.04 14.05\n",
      "Hurr until 2012:  10.32 14.04 14.05\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.31 12.6 10.34\n",
      "Hurr until 2012:  9.31 12.6 10.34\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#OFCL with AN EP ONLY\n",
    "train_0 = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "train = np.concatenate((train_0, X_test_total[train_0.index]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[train_0.index]\n",
    "test = np.concatenate((X_test_baseline, X_test_total), axis = 1)\n",
    "#xgb_total = XGBRegressor(max_depth=5, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=1, colsample_bytree = 0.7)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "xgb_total = XGBRegressor(max_depth=6, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=2)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.31 14.01 13.6\n",
      "Hurr until 2012:  10.31 14.01 13.6\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.35 12.7 10.92\n",
      "Hurr until 2012:  9.35 12.7 10.92\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#OFCL with AN EP ONLY\n",
    "train_0 = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "train = np.concatenate((train_0, X_test_embed[train_0.index]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[train_0.index]\n",
    "test = np.concatenate((X_test_baseline, X_test_embed), axis = 1)\n",
    "#xgb_total = XGBRegressor(max_depth=5, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=2, colsample_bytree = 0.7)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "xgb_total = XGBRegressor(max_depth=6, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=2)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem with NaN\n",
    "#xgb2 = XGBRegressor(max_depth=8, n_estimators=140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "#xgb2.fit(train, tgt_train3)\n",
    "#select = SelectFromModel(xgb2, prefit=True)\n",
    "#X_train_sparse = select.transform(train)\n",
    "#X_test_sparse = select.transform(test)\n",
    "#xgb_sparse2 = XGBRegressor(max_depth=3, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=2, colsample_bytree = 0.7)\n",
    "#xgb_sparse2.fit(X_train_sparse, tgt_train3)\n",
    "#compare_perf_intensity_per_year_4cast(X_test_sparse, dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_sparse2, xgb_tot = xgb_sparse2, basin='AN', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.88 14.64 15.25\n",
      "Hurr until 2012:  10.88 14.64 15.25\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.93 13.43 12.45\n",
      "Hurr until 2012:  9.93 13.43 12.45\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS\n",
    "train = np.concatenate((X_test_baseline[:17094], X_test_embed[:17094]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[:17094]\n",
    "test = np.concatenate((X_test_baseline, X_test_embed), axis = 1)\n",
    "xgb_total = XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.7, min_child_weight=7)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  41\n",
      "Year  2012  MAE intensity basin AN Hurricast trained full:  9.13 with std  11.62\n",
      "Year  2012  MAE intensity basin AN Hurricast trained until 2012:  9.19 with std  11.32\n",
      "Year  2012  MAE intensity basin AN Official Forecast SHIP :  9.56 with std  10.79\n",
      "Year  2012  MAE intensity basin AN Official Forecast HWRF :  8.1 with std  11.14\n",
      "Year  2012  MAE intensity basin AN Official Forecast OFCL :  9.02 with std  11.36\n",
      "Year  2012  MAE intensity basin AN Official Forecast FSSE :  10.37 with std  11.62\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  8\n",
      "Year  2013  MAE intensity basin AN Hurricast trained full:  12.06 with std  11.75\n",
      "Year  2013  MAE intensity basin AN Hurricast trained until 2012:  11.28 with std  10.57\n",
      "Year  2013  MAE intensity basin AN Official Forecast SHIP :  19.31 with std  12.82\n",
      "Year  2013  MAE intensity basin AN Official Forecast HWRF :  9.31 with std  9.22\n",
      "Year  2013  MAE intensity basin AN Official Forecast OFCL :  14.06 with std  5.44\n",
      "Year  2013  MAE intensity basin AN Official Forecast FSSE :  8.56 with std  8.28\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  72\n",
      "Year  2014  MAE intensity basin AN Hurricast trained full:  6.73 with std  8.32\n",
      "Year  2014  MAE intensity basin AN Hurricast trained until 2012:  6.36 with std  8.0\n",
      "Year  2014  MAE intensity basin AN Official Forecast SHIP :  7.02 with std  8.36\n",
      "Year  2014  MAE intensity basin AN Official Forecast HWRF :  12.13 with std  13.58\n",
      "Year  2014  MAE intensity basin AN Official Forecast OFCL :  6.7 with std  8.39\n",
      "Year  2014  MAE intensity basin AN Official Forecast FSSE :  8.16 with std  8.09\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  122\n",
      "Year  2015  MAE intensity basin AN Hurricast trained full:  8.29 with std  11.25\n",
      "Year  2015  MAE intensity basin AN Hurricast trained until 2012:  8.48 with std  11.76\n",
      "Year  2015  MAE intensity basin AN Official Forecast SHIP :  9.52 with std  12.95\n",
      "Year  2015  MAE intensity basin AN Official Forecast HWRF :  9.44 with std  13.77\n",
      "Year  2015  MAE intensity basin AN Official Forecast OFCL :  7.93 with std  11.75\n",
      "Year  2015  MAE intensity basin AN Official Forecast FSSE :  8.0 with std  11.84\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  231\n",
      "Year  2016  MAE intensity basin AN Hurricast trained full:  11.42 with std  14.84\n",
      "Year  2016  MAE intensity basin AN Hurricast trained until 2012:  11.36 with std  14.99\n",
      "Year  2016  MAE intensity basin AN Official Forecast SHIP :  10.38 with std  14.57\n",
      "Year  2016  MAE intensity basin AN Official Forecast HWRF :  10.11 with std  14.34\n",
      "Year  2016  MAE intensity basin AN Official Forecast OFCL :  8.42 with std  11.4\n",
      "Year  2016  MAE intensity basin AN Official Forecast FSSE :  8.87 with std  12.22\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  228\n",
      "Year  2017  MAE intensity basin AN Hurricast trained full:  12.37 with std  15.73\n",
      "Year  2017  MAE intensity basin AN Hurricast trained until 2012:  12.42 with std  15.8\n",
      "Year  2017  MAE intensity basin AN Official Forecast SHIP :  12.32 with std  17.27\n",
      "Year  2017  MAE intensity basin AN Official Forecast HWRF :  10.05 with std  12.65\n",
      "Year  2017  MAE intensity basin AN Official Forecast OFCL :  8.59 with std  11.83\n",
      "Year  2017  MAE intensity basin AN Official Forecast FSSE :  7.72 with std  10.07\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  236\n",
      "Year  2018  MAE intensity basin AN Hurricast trained full:  9.78 with std  12.7\n",
      "Year  2018  MAE intensity basin AN Hurricast trained until 2012:  9.89 with std  12.82\n",
      "Year  2018  MAE intensity basin AN Official Forecast SHIP :  10.79 with std  14.97\n",
      "Year  2018  MAE intensity basin AN Official Forecast HWRF :  8.8 with std  12.37\n",
      "Year  2018  MAE intensity basin AN Official Forecast OFCL :  8.53 with std  12.1\n",
      "Year  2018  MAE intensity basin AN Official Forecast FSSE :  8.82 with std  12.16\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  208\n",
      "Year  2019  MAE intensity basin AN Hurricast trained full:  10.36 with std  13.38\n",
      "Year  2019  MAE intensity basin AN Hurricast trained until 2012:  10.52 with std  13.46\n",
      "Year  2019  MAE intensity basin AN Official Forecast SHIP :  10.89 with std  14.22\n",
      "Year  2019  MAE intensity basin AN Official Forecast HWRF :  9.89 with std  12.68\n",
      "Year  2019  MAE intensity basin AN Official Forecast OFCL :  8.55 with std  11.53\n",
      "Year  2019  MAE intensity basin AN Official Forecast FSSE :  8.73 with std  11.42\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [9.19, 11.28, 6.36, 8.48, 11.36, 12.42, 9.89, 10.52],\n",
       " 'MAES_FSSE': [10.37, 8.56, 8.16, 8.0, 8.87, 7.72, 8.82, 8.73],\n",
       " 'MAES_HWRF': [8.1, 9.31, 12.13, 9.44, 10.11, 10.05, 8.8, 9.89],\n",
       " 'MAES_OFCL': [9.02, 14.06, 6.7, 7.93, 8.42, 8.59, 8.53, 8.55],\n",
       " 'MAES_SHIP': [9.56, 19.31, 7.02, 9.52, 10.38, 12.32, 10.79, 10.89],\n",
       " 'MAEs_full': [9.13, 12.06, 6.73, 8.29, 11.42, 12.37, 9.78, 10.36],\n",
       " 'num_samples': [41, 8, 72, 122, 231, 228, 236, 208],\n",
       " 'std_2012': [11.32, 10.57, 8.0, 11.76, 14.99, 15.8, 12.82, 13.46],\n",
       " 'std_FSSE': [11.62, 8.28, 8.09, 11.84, 12.22, 10.07, 12.16, 11.42],\n",
       " 'std_HWRF': [11.14, 9.22, 13.58, 13.77, 14.34, 12.65, 12.37, 12.68],\n",
       " 'std_OFCL': [11.36, 5.44, 8.39, 11.75, 11.4, 11.83, 12.1, 11.53],\n",
       " 'std_SHIP': [10.79, 12.82, 8.36, 12.95, 14.57, 17.27, 14.97, 14.22],\n",
       " 'std_full': [11.62, 11.75, 8.32, 11.25, 14.84, 15.73, 12.7, 13.38],\n",
       " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_4cast(forecast = 'SHIP', basin_only = False, sparse = False, max_depth = 8, n_estimators = 100, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_train5 = tgt_train*std_+mean_\n",
    "mean_intensity2 = tgt_train5.mean()\n",
    "std_intensity2 = tgt_train5.std()\n",
    "tgt_train5 = (tgt_train5 - mean_intensity2)/std_intensity2\n",
    "tgt_intensity_test = (tgt_intensity_test*std_+mean_ - mean_intensity2)/std_intensity2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5812, -0.4775, -0.3738,  ..., -0.5812, -0.5812, -0.5812])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_intensity_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ = float(std_intensity2)\n",
    "mean_ = float(mean_intensity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  0\n",
      "Year 2012 Basin AN MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2012\n",
      "Total number of steps for comparison:  0\n",
      "Year 2013 Basin AN MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2013\n",
      "Total number of steps for comparison:  0\n",
      "Year 2014 Basin AN MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2014\n",
      "Total number of steps for comparison:  113\n",
      "Year 2015 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  8.25 11.46 11.5\n",
      "Hurr until 2012:  8.48 11.83 11.5\n",
      "SHIP 9.88 13.33 11.5\n",
      "HWRF 9.86 14.21 9.73\n",
      "OFCL 8.5 12.2 8.85\n",
      "FSSE 8.35 12.25 10.62\n",
      "GFSO 13.36 16.04 22.12\n",
      "DSHP 9.87 13.33 11.5\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  230\n",
      "Year 2016 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.49 15.0 16.09\n",
      "Hurr until 2012:  11.41 15.03 15.65\n",
      "SHIP 10.36 14.57 11.74\n",
      "HWRF 10.06 14.32 13.48\n",
      "OFCL 8.37 11.36 4.78\n",
      "FSSE 8.83 12.2 7.83\n",
      "GFSO 14.74 18.35 23.48\n",
      "DSHP 10.1 13.78 10.87\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  227\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  12.17 15.41 20.26\n",
      "Hurr until 2012:  12.3 15.56 18.94\n",
      "SHIP 12.13 16.94 19.82\n",
      "HWRF 10.06 12.67 12.33\n",
      "OFCL 8.56 11.82 6.61\n",
      "FSSE 7.74 10.09 5.73\n",
      "GFSO 17.29 17.77 31.28\n",
      "DSHP 10.02 13.38 13.66\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  234\n",
      "Year 2018 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.8 12.75 12.82\n",
      "Hurr until 2012:  9.82 12.8 12.82\n",
      "SHIP 10.84 15.02 14.53\n",
      "HWRF 8.85 12.42 9.83\n",
      "OFCL 8.56 12.13 8.12\n",
      "FSSE 8.87 12.21 8.97\n",
      "GFSO 11.21 12.87 14.96\n",
      "DSHP 10.24 13.42 14.1\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  208\n",
      "Year 2019 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.35 13.28 10.58\n",
      "Hurr until 2012:  10.42 13.34 12.02\n",
      "SHIP 10.89 14.22 17.79\n",
      "HWRF 9.89 12.68 11.54\n",
      "OFCL 8.55 11.53 7.21\n",
      "FSSE 8.73 11.42 7.21\n",
      "GFSO 13.54 15.47 21.15\n",
      "DSHP 10.6 13.9 16.83\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [8.48, 11.41, 12.3, 9.82, 10.42],\n",
       " 'MAES_DSHP': [9.87, 10.1, 10.02, 10.24, 10.6],\n",
       " 'MAES_FSSE': [8.35, 8.83, 7.74, 8.87, 8.73],\n",
       " 'MAES_GFSO': [13.36, 14.74, 17.29, 11.21, 13.54],\n",
       " 'MAES_HWRF': [9.86, 10.06, 10.06, 8.85, 9.89],\n",
       " 'MAES_OFCL': [8.5, 8.37, 8.56, 8.56, 8.55],\n",
       " 'MAES_SHIP': [9.88, 10.36, 12.13, 10.84, 10.89],\n",
       " 'MAEs_full': [8.25, 11.49, 12.17, 9.8, 10.35],\n",
       " 'num_samples': [113, 230, 227, 234, 208],\n",
       " 'std_2012': [11.83, 15.03, 15.56, 12.8, 13.34],\n",
       " 'std_DSHP': [13.33, 13.78, 13.38, 13.42, 13.9],\n",
       " 'std_FSSE': [12.25, 12.2, 10.09, 12.21, 11.42],\n",
       " 'std_GFSO': [16.04, 18.35, 17.77, 12.87, 15.47],\n",
       " 'std_HWRF': [14.21, 14.32, 12.67, 12.42, 12.68],\n",
       " 'std_OFCL': [12.2, 11.36, 11.82, 12.13, 11.53],\n",
       " 'std_SHIP': [13.33, 14.57, 16.94, 15.02, 14.22],\n",
       " 'std_full': [11.46, 15.0, 15.41, 12.75, 13.28],\n",
       " 'year': [2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_6cast(forecast = 'SHIP', max_depth = 8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  0\n",
      "Year 2012 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2012\n",
      "Total number of steps for comparison:  0\n",
      "Year 2013 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2013\n",
      "Total number of steps for comparison:  0\n",
      "Year 2014 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2014\n",
      "Total number of steps for comparison:  255\n",
      "Year 2015 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.65 16.07 17.65\n",
      "Hurr until 2012:  11.83 16.22 17.65\n",
      "SHIP 12.75 17.89 17.65\n",
      "HWRF 11.79 17.29 16.86\n",
      "OFCL 10.42 15.35 11.37\n",
      "FSSE 9.93 13.96 11.76\n",
      "GFSO 15.62 20.14 25.49\n",
      "DSHP 12.41 16.99 17.65\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  315\n",
      "Year 2016 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.64 13.24 13.97\n",
      "Hurr until 2012:  9.95 13.44 14.29\n",
      "SHIP 9.87 12.84 10.79\n",
      "HWRF 10.38 13.74 11.75\n",
      "OFCL 8.72 11.89 6.67\n",
      "FSSE 8.51 11.53 8.57\n",
      "GFSO 13.02 16.38 21.27\n",
      "DSHP 9.69 12.58 10.16\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  167\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.02 12.96 8.98\n",
      "Hurr until 2012:  9.1 13.04 10.18\n",
      "SHIP 9.97 13.0 10.78\n",
      "HWRF 7.87 11.61 8.38\n",
      "OFCL 8.14 11.67 4.79\n",
      "FSSE 7.92 10.67 4.79\n",
      "GFSO 11.93 16.27 17.96\n",
      "DSHP 9.49 12.71 10.18\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  355\n",
      "Year 2018 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  12.09 15.73 20.0\n",
      "Hurr until 2012:  12.4 16.1 21.13\n",
      "SHIP 12.91 15.83 19.72\n",
      "HWRF 10.94 14.86 16.9\n",
      "OFCL 10.22 13.48 9.3\n",
      "FSSE 9.83 12.64 12.39\n",
      "GFSO 19.32 20.45 38.59\n",
      "DSHP 12.96 15.85 20.0\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  0\n",
      "Year 2019 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [11.83, 9.95, 9.1, 12.4],\n",
       " 'MAES_DSHP': [12.41, 9.69, 9.49, 12.96],\n",
       " 'MAES_FSSE': [9.93, 8.51, 7.92, 9.83],\n",
       " 'MAES_GFSO': [15.62, 13.02, 11.93, 19.32],\n",
       " 'MAES_HWRF': [11.79, 10.38, 7.87, 10.94],\n",
       " 'MAES_OFCL': [10.42, 8.72, 8.14, 10.22],\n",
       " 'MAES_SHIP': [12.75, 9.87, 9.97, 12.91],\n",
       " 'MAEs_full': [11.65, 9.64, 9.02, 12.09],\n",
       " 'num_samples': [255, 315, 167, 355],\n",
       " 'std_2012': [16.22, 13.44, 13.04, 16.1],\n",
       " 'std_DSHP': [16.99, 12.58, 12.71, 15.85],\n",
       " 'std_FSSE': [13.96, 11.53, 10.67, 12.64],\n",
       " 'std_GFSO': [20.14, 16.38, 16.27, 20.45],\n",
       " 'std_HWRF': [17.29, 13.74, 11.61, 14.86],\n",
       " 'std_OFCL': [15.35, 11.89, 11.67, 13.48],\n",
       " 'std_SHIP': [17.89, 12.84, 13.0, 15.83],\n",
       " 'std_full': [16.07, 13.24, 12.96, 15.73],\n",
       " 'year': [2015, 2016, 2017, 2018]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_6cast(forecast = 'SHIP', max_depth = 8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'EP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
