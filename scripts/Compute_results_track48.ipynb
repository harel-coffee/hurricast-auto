{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import prepro, metrics, run, setup\n",
    "import src.models.factory as model_factory\n",
    "import config\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from src.utils import models\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from src.utils.data_processing import *\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "window_size = 8\n",
    "predict_at = 16\n",
    "full = True\n",
    "\n",
    "tgt_intensity_cat_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                      allow_pickle=True))\n",
    "tgt_intensity_cat_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "\n",
    "tgt_intensity_train = torch.Tensor(np.load('../data/y_train_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                  allow_pickle=True))\n",
    "tgt_intensity_test = torch.Tensor(np.load('../data/y_test_intensity_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                 allow_pickle=True))\n",
    "\n",
    "tgt_intensity_cat_baseline_train = torch.LongTensor(np.load('../data/y_train_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',  allow_pickle = True))\n",
    "tgt_intensity_cat_baseline_test = torch.LongTensor(np.load('../data/y_test_intensity_cat_baseline_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))\n",
    "\n",
    "tgt_displacement_train_unst = torch.Tensor(np.load('../data/y_train_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                     allow_pickle=True))\n",
    "tgt_displacement_test_unst = torch.Tensor(np.load('../data/y_test_displacement_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "                                    allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_24_2012_v2_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "X_test_baseline = pd.DataFrame(np.load('../data/X_test_stat_1980_34_20_120_forecast_48_2012_v2_w' + str(window_size) + '_at_' + str(predict_at) + '.npy', allow_pickle=True))\n",
    "\n",
    "\n",
    "#names_baselines = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'GFDL_24_lat', 'GFDL_24_lon', 'GFDL_24_vmax', 'GFDL_24_mslp', 'GFDL_24_COS_LAT', 'GFDL_24_SIN_LAT', 'GFDL_24_COS_LON', 'GFDL_24_SIN_LON', 'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'CMC_24_COS_LAT', 'CMC_24_SIN_LAT', 'CMC_24_COS_LON', 'CMC_24_SIN_LON', 'FSSE_24_lat', 'FSSE_24_lon', 'FSSE_24_vmax', 'FSSE_24_mslp', 'FSSE_24_COS_LAT', 'FSSE_24_SIN_LAT', 'FSSE_24_COS_LON', 'FSSE_24_SIN_LON', 'OFCL_24_lat', 'OFCL_24_lon', 'OFCL_24_vmax', 'OFCL_24_mslp', 'OFCL_24_COS_LAT', 'OFCL_24_SIN_LAT', 'OFCL_24_COS_LON', 'OFCL_24_SIN_LON', 'NGPS_24_lat', 'NGPS_24_lon', 'NGPS_24_vmax', 'NGPS_24_mslp', 'NGPS_24_COS_LAT', 'NGPS_24_SIN_LAT', 'NGPS_24_COS_LON', 'NGPS_24_SIN_LON', 'DSHP_24_lat', 'DSHP_24_lon', 'DSHP_24_vmax', 'DSHP_24_mslp', 'DSHP_24_COS_LAT', 'DSHP_24_SIN_LAT', 'DSHP_24_COS_LON', 'DSHP_24_SIN_LON', 'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'SHIP_24_COS_LAT', 'SHIP_24_SIN_LAT', 'SHIP_24_COS_LON', 'SHIP_24_SIN_LON', 'CLP5_24_lat', 'CLP5_24_lon', 'CLP5_24_vmax', 'CLP5_24_mslp', 'CLP5_24_COS_LAT', 'CLP5_24_SIN_LAT', 'CLP5_24_COS_LON', 'CLP5_24_SIN_LON', 'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'HWRF_24_COS_LAT', 'HWRF_24_SIN_LAT', 'HWRF_24_COS_LON', 'HWRF_24_SIN_LON', 'UKXI_24_lat', 'UKXI_24_lon', 'UKXI_24_vmax', 'UKXI_24_mslp', 'UKXI_24_COS_LAT', 'UKXI_24_SIN_LAT', 'UKXI_24_COS_LON', 'UKXI_24_SIN_LON', 'LBAR_24_lat', 'LBAR_24_lon', 'LBAR_24_vmax', 'LBAR_24_mslp', 'LBAR_24_COS_LAT', 'LBAR_24_SIN_LAT', 'LBAR_24_COS_LON', 'LBAR_24_SIN_LON', 'AEMN_24_lat', 'AEMN_24_lon', 'AEMN_24_vmax', 'AEMN_24_mslp', 'AEMN_24_COS_LAT', 'AEMN_24_SIN_LAT', 'AEMN_24_COS_LON', 'AEMN_24_SIN_LON', 'DISPLACEMENT_LAT_CLP5_24', 'DISPLACEMENT_LON_CLP5_24', 'DISPLACEMENT_LAT_SHIP_24', 'DISPLACEMENT_LON_SHIP_24', 'DISPLACEMENT_LAT_DSHP_24', 'DISPLACEMENT_LON_DSHP_24', 'DISPLACEMENT_LAT_LBAR_24', 'DISPLACEMENT_LON_LBAR_24', 'DISPLACEMENT_LAT_CMC_24', 'DISPLACEMENT_LON_CMC_24', 'DISPLACEMENT_LAT_NGPS_24', 'DISPLACEMENT_LON_NGPS_24', 'DISPLACEMENT_LAT_GFDL_24', 'DISPLACEMENT_LON_GFDL_24', 'DISPLACEMENT_LAT_HWRF_24', 'DISPLACEMENT_LON_HWRF_24', 'DISPLACEMENT_LAT_UKXI_24', 'DISPLACEMENT_LON_UKXI_24', 'DISPLACEMENT_LAT_FSSE_24', 'DISPLACEMENT_LON_FSSE_24', 'DISPLACEMENT_LAT_AEMN_24', 'DISPLACEMENT_LON_AEMN_24', 'DISPLACEMENT_LAT_OFCL_24', 'DISPLACEMENT_LON_OFCL_24', 'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp', 'EMXI_24_COS_LAT', 'EMXI_24_SIN_LAT', 'EMXI_24_COS_LON', 'EMXI_24_SIN_LON', 'DISPLACEMENT_LAT_EMXI_24', 'DISPLACEMENT_LON_EMXI_24', 'GFSO_24_lat', 'GFSO_24_lon', 'GFSO_24_vmax', 'GFSO_24_mslp', 'GFSO_24_COS_LAT', 'GFSO_24_SIN_LAT', 'GFSO_24_COS_LON', 'GFSO_24_SIN_LON', 'DISPLACEMENT_LAT_GFSO_24', 'DISPLACEMENT_LON_GFSO_24', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SI', 'basin_SP', 'basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "names_baselines = ['YEAR', 'MONTH', 'DAY', 'HOUR', 'LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND', 'STORM_SPEED', 'cos_day', 'sin_day', 'COS_STORM_DIR', 'SIN_STORM_DIR', 'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'wind_category', 'DSHP_24_lat', 'DSHP_24_lon', 'DSHP_24_vmax', 'DSHP_24_mslp', 'DSHP_24_COS_LAT', 'DSHP_24_SIN_LAT', 'DSHP_24_COS_LON', 'DSHP_24_SIN_LON', 'OFCL_24_lat', 'OFCL_24_lon', 'OFCL_24_vmax', 'OFCL_24_mslp', 'OFCL_24_COS_LAT', 'OFCL_24_SIN_LAT', 'OFCL_24_COS_LON', 'OFCL_24_SIN_LON', 'UKXI_24_lat', 'UKXI_24_lon', 'UKXI_24_vmax', 'UKXI_24_mslp', 'UKXI_24_COS_LAT', 'UKXI_24_SIN_LAT', 'UKXI_24_COS_LON', 'UKXI_24_SIN_LON', 'CMC_24_lat', 'CMC_24_lon', 'CMC_24_vmax', 'CMC_24_mslp', 'CMC_24_COS_LAT', 'CMC_24_SIN_LAT', 'CMC_24_COS_LON', 'CMC_24_SIN_LON', 'SHIP_24_lat', 'SHIP_24_lon', 'SHIP_24_vmax', 'SHIP_24_mslp', 'SHIP_24_COS_LAT', 'SHIP_24_SIN_LAT', 'SHIP_24_COS_LON', 'SHIP_24_SIN_LON', 'FSSE_24_lat', 'FSSE_24_lon', 'FSSE_24_vmax', 'FSSE_24_mslp', 'FSSE_24_COS_LAT', 'FSSE_24_SIN_LAT', 'FSSE_24_COS_LON', 'FSSE_24_SIN_LON', 'CLP5_24_lat', 'CLP5_24_lon', 'CLP5_24_vmax', 'CLP5_24_mslp', 'CLP5_24_COS_LAT', 'CLP5_24_SIN_LAT', 'CLP5_24_COS_LON', 'CLP5_24_SIN_LON', 'AEMN_24_lat', 'AEMN_24_lon', 'AEMN_24_vmax', 'AEMN_24_mslp', 'AEMN_24_COS_LAT', 'AEMN_24_SIN_LAT', 'AEMN_24_COS_LON', 'AEMN_24_SIN_LON', 'LBAR_24_lat', 'LBAR_24_lon', 'LBAR_24_vmax', 'LBAR_24_mslp', 'LBAR_24_COS_LAT', 'LBAR_24_SIN_LAT', 'LBAR_24_COS_LON', 'LBAR_24_SIN_LON', 'GFDL_24_lat', 'GFDL_24_lon', 'GFDL_24_vmax', 'GFDL_24_mslp', 'GFDL_24_COS_LAT', 'GFDL_24_SIN_LAT', 'GFDL_24_COS_LON', 'GFDL_24_SIN_LON', 'HWRF_24_lat', 'HWRF_24_lon', 'HWRF_24_vmax', 'HWRF_24_mslp', 'HWRF_24_COS_LAT', 'HWRF_24_SIN_LAT', 'HWRF_24_COS_LON', 'HWRF_24_SIN_LON', 'NGPS_24_lat', 'NGPS_24_lon', 'NGPS_24_vmax', 'NGPS_24_mslp', 'NGPS_24_COS_LAT', 'NGPS_24_SIN_LAT', 'NGPS_24_COS_LON', 'NGPS_24_SIN_LON', 'DISPLACEMENT_LAT_CLP5_24', 'DISPLACEMENT_LON_CLP5_24', 'DISPLACEMENT_LAT_SHIP_24', 'DISPLACEMENT_LON_SHIP_24', 'DISPLACEMENT_LAT_DSHP_24', 'DISPLACEMENT_LON_DSHP_24', 'DISPLACEMENT_LAT_LBAR_24', 'DISPLACEMENT_LON_LBAR_24', 'DISPLACEMENT_LAT_CMC_24', 'DISPLACEMENT_LON_CMC_24', 'DISPLACEMENT_LAT_NGPS_24', 'DISPLACEMENT_LON_NGPS_24', 'DISPLACEMENT_LAT_GFDL_24', 'DISPLACEMENT_LON_GFDL_24', 'DISPLACEMENT_LAT_HWRF_24', 'DISPLACEMENT_LON_HWRF_24', 'DISPLACEMENT_LAT_UKXI_24', 'DISPLACEMENT_LON_UKXI_24', 'DISPLACEMENT_LAT_FSSE_24', 'DISPLACEMENT_LON_FSSE_24', 'DISPLACEMENT_LAT_AEMN_24', 'DISPLACEMENT_LON_AEMN_24', 'DISPLACEMENT_LAT_OFCL_24', 'DISPLACEMENT_LON_OFCL_24', 'EMXI_24_lat', 'EMXI_24_lon', 'EMXI_24_vmax', 'EMXI_24_mslp', 'EMXI_24_COS_LAT', 'EMXI_24_SIN_LAT', 'EMXI_24_COS_LON', 'EMXI_24_SIN_LON', 'DISPLACEMENT_LAT_EMXI_24', 'DISPLACEMENT_LON_EMXI_24', 'GFSO_24_lat', 'GFSO_24_lon', 'GFSO_24_vmax', 'GFSO_24_mslp', 'GFSO_24_COS_LAT', 'GFSO_24_SIN_LAT', 'GFSO_24_COS_LON', 'GFSO_24_SIN_LON', 'DISPLACEMENT_LAT_GFSO_24', 'DISPLACEMENT_LON_GFSO_24', 'cat_basin_AN', 'cat_basin_EP', 'basin_NI', 'basin_SI', 'basin_SP', 'basin_WP', 'DISPLACEMENT_LAT', 'DISPLACEMENT_LON']\n",
    "names_all_baselines = names_baselines * 8#args.window_size\n",
    "\n",
    "for i in range(len(names_all_baselines)):\n",
    "    names_all_baselines[i] += '_' + str(i // 167)\n",
    "\n",
    "X_test_baseline.columns = names_all_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## PREPARING DATA FOR XGB\n",
    "\n",
    "X_train = np.load('../data/X_train_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "X_test = np.load('../data/X_test_stat_1980_34_20_120_w' + str(window_size) + '_at_' + str(predict_at) + '.npy',\n",
    "            allow_pickle=True)\n",
    "\n",
    "names = ['LAT', 'LON', 'WMO_WIND', 'WMO_PRES', 'DIST2LAND',\n",
    "         'STORM_SPEED', 'cat_cos_day', 'cat_sign_day', 'COS_STORM_DIR', 'SIN_STORM_DIR',\n",
    "         'COS_LAT', 'SIN_LAT', 'COS_LON', 'SIN_LON', 'cat_storm_category', 'cat_basin_AN',\n",
    "         'cat_basin_EP', 'cat_basin_NI', 'cat_basin_SA',\n",
    "         'cat_basin_SI', 'cat_basin_SP', 'cat_basin_WP', 'cat_nature_DS', 'cat_nature_ET',\n",
    "         'cat_nature_MX', 'cat_nature_NR', 'cat_nature_SS', 'cat_nature_TS',\n",
    "         'STORM_DISPLACEMENT_X', 'STORM_DISPLACEMENT_Y']\n",
    "\n",
    "names_all = names * window_size\n",
    "\n",
    "for i in range(len(names_all)):\n",
    "    names_all[i] += '_' + str(i // 30)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.columns = names_all\n",
    "X_test.columns = names_all\n",
    "\n",
    "cols = [c for c in X_train.columns if c.lower()[-2:] == '_0' or c.lower()[:3] != 'cat']\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_embed = np.load('../data/embeddings/X_train_embeds_1980_34_20_120_results8_16_20_44_28.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embeds_1980_34_20_120_results8_16_20_44_28.npy', allow_pickle = True)\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity.npy', allow_pickle = True)\n",
    "\n",
    "#48\n",
    "#X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "#X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_intensity_48.npy', allow_pickle = True)\n",
    "\n",
    "X_train_embed = np.load('../data/embeddings/X_train_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "X_test_embed = np.load('../data/embeddings/X_test_embed_1980_34_20_120_track_48.npy', allow_pickle = True)\n",
    "\n",
    "X_train_total = np.concatenate((X_train, X_train_embed), axis = 1)\n",
    "X_test_total = np.concatenate((X_test, X_test_embed), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_baseline = X_test_baseline[30:]\n",
    "n = X_test_baseline.shape[0]\n",
    "X_test_total = X_test_total[-n:]\n",
    "#tgt_intensity_test = tgt_intensity_test[-n:]\n",
    "X_test = X_test[-n:]\n",
    "X_test_embed = X_test_embed[-n:]\n",
    "tgt_displacement_test = tgt_displacement_test[-n:]\n",
    "m = 14512\n",
    "\n",
    "if full:\n",
    "    tgt_displacement_train = np.concatenate((tgt_displacement_train, tgt_displacement_test[:m]), axis = 0)\n",
    "    X_train = pd.concat((X_train, X_test[:m]), axis = 0)\n",
    "    X_train_embed = np.concatenate((X_train_embed, X_test_embed[:m]), axis = 0)\n",
    "    X_train_total = np.concatenate((X_train_total, X_test_total[:m]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TRACK\n",
    "mean_dx = tgt_displacement_train[:,0].mean()\n",
    "std_dx = tgt_displacement_train[:,0].std()\n",
    "tgt_displacement_train[:,0] = (tgt_displacement_train[:,0] - mean_dx)/std_dx\n",
    "tgt_displacement_test[:,0] = (tgt_displacement_test[:,0] - mean_dx)/std_dx\n",
    "std_dx = float(std_dx)\n",
    "mean_dx = float(mean_dx)\n",
    "\n",
    "mean_dy = tgt_displacement_train[:,1].mean()\n",
    "std_dy = tgt_displacement_train[:,1].std()\n",
    "tgt_displacement_train[:,1] = (tgt_displacement_train[:,1] - mean_dy)/std_dy\n",
    "tgt_displacement_test[:,1] = (tgt_displacement_test[:,1] - mean_dy)/std_dy\n",
    "std_dy = float(std_dy)\n",
    "mean_dy = float(mean_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = X_train[np.round(X_train['WMO_WIND_7']*1000%10, decimals = 2) == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104651, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[np.round(X_train['WMO_WIND_7']*1000%10, decimals = 2) == 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_total = X_train_total[index]\n",
    "tgt_displacement_train = tgt_displacement_train[index]\n",
    "X_train_embed = X_train_embed[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  7.8533998\n",
      "MAE intensity:  7.4758453\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBRegressor(max_depth=6, n_estimators=140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "xgb2.fit(X_train, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb2.predict(X_test))*std_+mean_))\n",
    "\n",
    "xgb = XGBRegressor(max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight = 1)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[17:38:21] /workspace/src/data/data.cc:373: Check failed: labels_.Size() == num_row_ (90139 vs. 104621) : Size of labels must equal to number of rows.\nStack trace:\n  [bt] (0) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xa0c64) [0x7fed20153c64]\n  [bt] (1) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xfc92b) [0x7fed201af92b]\n  [bt] (2) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x1952e4) [0x7fed202482e4]\n  [bt] (3) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x199442) [0x7fed2024c442]\n  [bt] (4) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x59) [0x7fed20143d39]\n  [bt] (5) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fedbaac0ec0]\n  [bt] (6) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fedbaac087d]\n  [bt] (7) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fedbacd6ede]\n  [bt] (8) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x13915) [0x7fedbacd7915]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-69cac3ec5e68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_intensity_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAE intensity: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_intensity_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [17:38:21] /workspace/src/data/data.cc:373: Check failed: labels_.Size() == num_row_ (90139 vs. 104621) : Size of labels must equal to number of rows.\nStack trace:\n  [bt] (0) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xa0c64) [0x7fed20153c64]\n  [bt] (1) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0xfc92b) [0x7fed201af92b]\n  [bt] (2) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x1952e4) [0x7fed202482e4]\n  [bt] (3) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(+0x199442) [0x7fed2024c442]\n  [bt] (4) /home/gridsan/leobix/.local/lib/python3.6/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x59) [0x7fed20143d39]\n  [bt] (5) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fedbaac0ec0]\n  [bt] (6) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fedbaac087d]\n  [bt] (7) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fedbacd6ede]\n  [bt] (8) /state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x13915) [0x7fedbacd7915]\n\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight = 1)\n",
    "xgb.fit(X_train_total, tgt_intensity_train)\n",
    "print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_intensity_test)*std_+mean_, np.array(xgb.predict(X_test_total))*std_+mean_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26800, 740)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EP:\n",
    "We beat: SHIP, HWRF, GFSO, AEMN, DSHP, (GFDL, UKXI, CMC)\n",
    "We lose: OFCL, FSSE\n",
    "\n",
    "AN:\n",
    "We beat: SHIP, HWRF, GFSO, AEMN, GFDL, DSHP, (UKXI, CMC) \n",
    "We lose: HWRF, OFCL, FSSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_track(basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    train_x = X_train_total\n",
    "    train_y = X_train_total\n",
    "    test_x = X_test_total\n",
    "    test_y = X_test_total\n",
    "    tgt_train = tgt_displacement_train\n",
    "    if sparse:\n",
    "        train_x, train_y = X_train_total_sparse_x, X_train_total_sparse_y\n",
    "        test_x, test_y = X_test_total_sparse_x, X_test_total_sparse_y\n",
    "    if basin_only:\n",
    "        train_x = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        train_y = train_x\n",
    "        tgt_train = tgt_displacement_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "    xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "    DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "    DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "    LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "    LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "    compare_perf_track(basin=basin, forecast=forecast, forecast2 = forecast2, LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "\n",
    "def train_xgb_track_all_years(use_forecast = False, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    train_x = X_train_total\n",
    "    train_y = X_train_total\n",
    "    test_x = X_test_total\n",
    "    test_y = X_test_total\n",
    "    tgt_train = tgt_displacement_train\n",
    "    if sparse:\n",
    "        train_x, train_y = X_train_total_sparse_x, X_train_total_sparse_y\n",
    "        test_x, test_y = X_test_total_sparse_x, X_test_total_sparse_y\n",
    "    if basin_only:\n",
    "        train_x = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        train_y = train_x\n",
    "        tgt_train = tgt_displacement_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    if use_forecast:\n",
    "        train_for = X_train_forecasts\n",
    "        tgt_train_for = tgt_train_dis_forecasts\n",
    "        test_for = X_test_forecasts\n",
    "        xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_x.fit(train_for, tgt_train_for[:, 0])\n",
    "        xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_y.fit(train_for, tgt_train_for[:, 1])\n",
    "        DLATS_PRED = np.array(xgb_x.predict(X_new)) * std_dx + mean_dx\n",
    "        DLONS_PRED = np.array(xgb_y.predict(X_new)) * std_dy + mean_dy\n",
    "    else:\n",
    "        xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "        xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "        xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "        DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "        DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "    LATS_PRED_2012 = X_test['LAT_7'] + DLATS_PRED\n",
    "    LONS_PRED_2012 = X_test['LON_7'] + DLONS_PRED\n",
    "    compare_perf_track(basin=basin, forecast=forecast, forecast2 = forecast2, LATS_PRED_=LATS_PRED_2012, LONS_PRED_=LONS_PRED_2012)\n",
    "    dict = {'year': [], 'num_samples': [], 'MAEs_full': [], 'std_full': [], 'MAES_2012': [], 'std_2012': [],\n",
    "            'MAES_SHIP': [], 'std_SHIP': [], 'MAES_HWRF': [], 'std_HWRF': []}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[\n",
    "                X_test_baseline['YEAR'] < year].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis=0)\n",
    "            tgt_train = np.concatenate((tgt_displacement_train, tgt_displacement_test[index]), axis=0)\n",
    "            xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_x.fit(train, tgt_train[:, 0])\n",
    "            xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_y.fit(train, tgt_train[:, 1])\n",
    "            DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "            DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "            LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "            LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "            compare_perf_track_per_year(dict, LATS_PRED_, LONS_PRED_, LATS_PRED_2012, LONS_PRED_2012, forecast=forecast,\n",
    "                                            forecast2=forecast2, basin=basin,  year=year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_xgb_intensity(forecast = 'SHIP', basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = None):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total.fit(train, tgt_train)\n",
    "    compare_perf_intensity(xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', forecast2 = forecast2)\n",
    "\n",
    "#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.12, subsample = 0.7, min_child_weight = 5, basin = 'AN', forecast = 'HWRF') 82.14 and 117.26\n",
    "#train_xgb_track(n_estimators = 90, max_depth = 7, learning_rate = 0.1, subsample = 0.7, min_child_weight = 5, basin = 'EP', forecast = 'HWRF')\n",
    "\n",
    "LATS_TEST = X_test['LAT_7'] + np.array(tgt_displacement_test[:,0])*std_dx+mean_dx\n",
    "LONS_TEST = X_test['LON_7'] + np.array(tgt_displacement_test[:,1])*std_dy+mean_dy\n",
    "\n",
    "def compare_perf_track(LATS_PRED_, LONS_PRED_, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    LATS_TEST_ = np.array(X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx)[index]\n",
    "    LONS_TEST_ = np.array(X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy)[index]\n",
    "    baseline_1_x = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_1_y = baseline_[forecast + '_24_lon_7']\n",
    "    LATS_BASE = np.array(baseline_1_x)\n",
    "    LONS_BASE = np.array(baseline_1_y)\n",
    "    LATS_PRED_ = np.array(LATS_PRED_)[index]\n",
    "    LONS_PRED_ = np.array(LONS_PRED_)[index]\n",
    "    d_km_baseline = np.zeros(len(LATS_BASE))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_BASE))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    print(LATS_BASE_2)\n",
    "    print(LONS_BASE_2)\n",
    "    print(LATS_TEST_)\n",
    "    print(LONS_TEST_)\n",
    "    for i in range(len(LATS_BASE)):\n",
    "        d_km_baseline[i] = get_distance_km(LONS_BASE[i], LATS_BASE[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        if forecast2 != None:\n",
    "            d_km_baseline2[i] = get_distance_km(LONS_BASE_2[i], LATS_BASE_2[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Number of timesteps:\", len(LATS_BASE))\n",
    "    print(basin, 'Model | MAE | std')\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2))\n",
    "    print(str(forecast2), np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2))\n",
    "    print(\"Hurricast\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2))\n",
    "    print(\"\\nModel | Number of Busts > 200km | Percentage Bust\")\n",
    "    print(forecast, sum(d_km_baseline > 200), np.around(sum(d_km_baseline > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    print(str(forecast2), sum(d_km_baseline2 > 200), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_BASE), decimals =2))\n",
    "    print(\"Hurricast\", sum(d_km_pred > 200), np.around(sum(d_km_pred > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "\n",
    "\n",
    "\n",
    "def compare_perf_intensity(xgb_total, basin = 'AN', forecast = 'SHIP', last_storms = 1000, mode = 'vmax', forecast2 = 'HWRF'):\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    else:\n",
    "        index = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    X_test_withBASELINE_total = X_test_total[index]\n",
    "    baseline_1 = baseline_[forecast + '_24_' + mode + '_7']\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Timesteps\", len(tgt_))\n",
    "        print(\"MAE intensity basin \" + basin + \" Hurricast : \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds), decimals=2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \" + str(forecast2) + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_2), decimals=2), \"with std \",\n",
    "              np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "        print(\"Percentage of missed intensification > 20kn Hurricast: \", np.around(sum(abs(tgt_ - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "        print(\"Percentage of missed intensification > 20kn Official Forecast\"+ forecast + \" : \", np.around(sum(abs(tgt_ - baseline_1) > 20) / len(baseline_1) * 100, decimals =2))\n",
    "        print(\"Percentage of missed intensification > 20kn Official Forecast 2\"+ str(forecast2) + \" : \", np.around(sum(abs(tgt_ - baseline_2) > 20) / len(baseline_2) * 100, decimals =2))\n",
    "        print(\"\\nMAE intensity basin \" + basin + \" Hurricast last\", last_storms, \": \", np.around(mean_absolute_error(tgt_[-last_storms:], preds[-last_storms:]), decimals=2))\n",
    "        print(\"MAE intensity basin \" + basin + \" Official Forecast \" + forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_[-last_storms:], baseline_1[-last_storms:]), decimals=2))\n",
    "\n",
    "\n",
    "#train_xgb_intensity(forecast = 'SHIP', basin = 'EP', max_depth=8, n_estimators = 120, learning_rate = 0.07, subsample = 0.8, min_child_weight = 1)\n",
    "#train_xgb_intensity(forecast = 'SHIP', basin = 'AN', max_depth=8, n_estimators = 150, learning_rate = 0.07, subsample = 0.8, min_child_weight = 1, forecast2 = 'HWRF')\n",
    "\n",
    "\n",
    "def compare_perf_intensity_per_year(dict, xgb_tot, xgb_total, year, forecast2, basin = 'AN', forecast = 'HWRF', mode = 'vmax'):\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        # X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        #X_test_withBASELINE = X_test.loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    X_test_withBASELINE_total = X_test_total[index]\n",
    "    baseline_1 = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    if mode == 'vmax':\n",
    "        tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "        print(\"Total number of steps for comparison: \", len(tgt_))\n",
    "        preds_1 = xgb_tot.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "        #print(\"MAE intensity basin \" + basin + \" X stat vs \"+ forecast + \" : \", mean_absolute_error(tgt_intensity_test_withBASELINE * std_ + mean_,\n",
    "                                                     #xgb.predict(X_test_withBASELINE) * std_ + mean_))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Hurricast trained full: \", np.around(mean_absolute_error(tgt_, preds), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds), decimals=2))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Hurricast trained until 2012: \", np.around(mean_absolute_error(tgt_, preds_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "        print(\"Year \", year, \" MAE intensity basin \" + basin + \" Official Forecast \"+ forecast + \" : \",\n",
    "              np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2), \"with std \", np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "        if forecast2 != None:\n",
    "            print(\"Year \", year, \" MAE intensity basin \" + basin + \" Official Forecast \" + forecast2 + \" : \",\n",
    "                np.around(mean_absolute_error(tgt_, baseline_2), decimals=2), \"with std \",\n",
    "                np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "        append_dict_intensity(dict, tgt_, preds, preds_1, baseline_1, baseline_2, year)\n",
    "        #print(\"Year \", year, \" Percentage of missed intensification > 20kn Hurricast: \", np.around(sum(tgt_ - preds > 20)/len(preds) * 100, decimals = 2))\n",
    "        #print(\"Year \", year, \" Percentage of missed intensification > 20kn Official Forecast: \", np.around(sum(tgt_ - baseline_1 > 20) / len(baseline_1) * 100, decimals =2))\n",
    "\n",
    "\n",
    "def compare_perf_track_per_year(dict, LATS_PRED_, LONS_PRED_, LATS_PRED_2012, LONS_PRED_2012, year, basin = 'AN', forecast = 'SHIP', forecast2 = None):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] >= year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[\n",
    "                                                                             'cat_basin_' + basin + '_0'] == 1].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    else:\n",
    "        index = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1].index#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR'] == year].loc[X_test_baseline[forecast + '_24_'+mode+'_7'] > -320].loc[X_test_baseline['cat_basin_'+basin+'_0'] == 1]#.loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0]\n",
    "    LATS_TEST_ = X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx\n",
    "    LONS_TEST_ = X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy\n",
    "    baseline_1_x = baseline_[forecast + '_24_'+mode+'_7']\n",
    "    baseline_1_y = baseline_[forecast + '_24_lon_7']\n",
    "    LATS_BASE = np.array(baseline_1_x)\n",
    "    LONS_BASE = np.array(baseline_1_y)\n",
    "    LATS_TEST_ = np.array(LATS_TEST_[index])\n",
    "    LONS_TEST_ = np.array(LONS_TEST_[index])\n",
    "    LATS_PRED_ = np.array(LATS_PRED_[index])\n",
    "    LONS_PRED_ = np.array(LONS_PRED_[index])\n",
    "    LATS_PRED_2012 = np.array(LATS_PRED_2012[index])\n",
    "    LONS_PRED_2012 = np.array(LONS_PRED_2012[index])\n",
    "    d_km_baseline = np.zeros(len(LATS_BASE))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_BASE))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    d_km_pred_2012 = np.zeros(len(LONS_PRED_))\n",
    "    for i in range(len(LATS_BASE)):\n",
    "        d_km_baseline[i] = get_distance_km(LONS_BASE[i], LATS_BASE[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred_2012[i] = get_distance_km(LONS_PRED_2012[i], LATS_PRED_2012[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        if forecast2 != None:\n",
    "            d_km_baseline2[i] = get_distance_km(LONS_BASE_2[i], LATS_BASE_2[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Year\", year, \"Number of timesteps:\", len(LATS_BASE))\n",
    "    print(basin, 'Model | MAE | std')\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2))\n",
    "    print(str(forecast2), np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2))\n",
    "    print(\"Hurricast Max Data\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2))\n",
    "    print(\"Hurricast Until 2012\", np.around(d_km_pred_2012.mean(), decimals=2), np.around(d_km_pred_2012.std(), decimals=2))\n",
    "    print(\"\\nModel | Number of Busts > 200km | Percentage Bust\")\n",
    "    print(forecast, sum(d_km_baseline > 200), np.around(sum(d_km_baseline > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    print(str(forecast2), sum(d_km_baseline2 > 200), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_BASE), decimals =2))\n",
    "    print(\"Hurricast\", sum(d_km_pred > 200), np.around(sum(d_km_pred > 200)*100/len(LATS_BASE), decimals = 2))\n",
    "    append_dict_track(dict, d_km_baseline, d_km_baseline2, d_km_pred, d_km_pred_2012, year)\n",
    "\n",
    "def append_dict_track(dict, d_km_baseline, d_km_baseline2, d_km_pred, d_km_pred_2012, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(d_km_baseline))\n",
    "    dict['MAEs_full'].append(np.around(d_km_pred.mean(), decimals = 2))\n",
    "    dict['std_full'].append(np.around(d_km_pred.std(), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(d_km_pred_2012.mean(), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(d_km_pred_2012.std(), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(d_km_baseline.mean(), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(d_km_baseline.std(), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(d_km_baseline2.mean(), decimals =2))\n",
    "    dict['std_HWRF'].append(np.around(d_km_baseline2.std(), decimals=2))\n",
    "\n",
    "def append_dict_intensity(dict, tgt_, preds, preds_1, baseline_1, baseline_2, year):\n",
    "    dict['year'].append(year)\n",
    "    dict['num_samples'].append(len(tgt_))\n",
    "    dict['MAEs_full'].append(np.around(mean_absolute_error(tgt_, preds), decimals = 2))\n",
    "    dict['std_full'].append(np.around(np.std(tgt_ - preds), decimals = 2))\n",
    "    dict['MAES_2012'].append(np.around(mean_absolute_error(tgt_, preds_1), decimals = 2))\n",
    "    dict['std_2012'].append(np.around(np.std(tgt_ - preds_1), decimals=2))\n",
    "    dict['MAES_SHIP'].append(np.around(mean_absolute_error(tgt_, baseline_1), decimals = 2))\n",
    "    dict['std_SHIP'].append(np.around(np.std(tgt_ - baseline_1), decimals = 2))\n",
    "    dict['MAES_HWRF'].append(np.around(mean_absolute_error(tgt_, baseline_2), decimals=2))\n",
    "    dict['std_HWRF'].append(np.around(np.std(tgt_ - baseline_2), decimals=2))\n",
    "\n",
    "\n",
    "def train_xgb_intensity_all_years(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total.fit(train, tgt_train)\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            compare_perf_intensity_per_year(forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "\n",
    "def train_xgb_intensity_all_years_full_train(forecast2 = None, basin_only = False, sparse = False, max_depth = 8, n_estimators = 140, learning_rate = 0.15, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast = 'HWRF'):\n",
    "    train = X_train_total\n",
    "    #test = X_test_total\n",
    "    tgt_train = tgt_intensity_train\n",
    "    if sparse:\n",
    "        train = X_train_total_sparse_x\n",
    "        #test = X_test_total_sparse_x\n",
    "    if basin_only:\n",
    "        train = X_train_total[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "        tgt_train = tgt_intensity_train[X_train['cat_basin_'+basin+'_0'] == 1]\n",
    "    xgb_total_1 = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                             subsample=subsample, min_child_weight=min_child_weight)\n",
    "    xgb_total_1.fit(train, tgt_train)\n",
    "    dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[]}\n",
    "    for year in range(2012, 2020):\n",
    "        try:\n",
    "            index = X_test_baseline.loc[X_test_baseline['YEAR_0'] < year].index  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "            X_test_to_train = X_test_total[index]\n",
    "            train = np.concatenate((X_train_total, X_test_to_train), axis = 0)\n",
    "            tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[index]), axis = 0)\n",
    "            xgb_total = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                     subsample=subsample, min_child_weight=min_child_weight)\n",
    "            xgb_total.fit(train, tgt_train)\n",
    "            compare_perf_intensity_per_year(dict = dict, xgb_tot = xgb_total_1, forecast2 = forecast2, xgb_total = xgb_total, basin=basin, forecast=forecast, mode='vmax', year = year)\n",
    "            print(\"\\n\")\n",
    "        except:\n",
    "            print(\"\\n No forecasts for year \", year)\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_perf_track_7cast(LATS_PRED_, LONS_PRED_, year = 2017, basin = 'AN', forecast = 'SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'DSHP', forecast6 = 'GFSO', forecast7 = 'CLP5'):\n",
    "    mode = 'lat'\n",
    "    if forecast2 != None:\n",
    "        \n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast7 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        if basin == 'EP':\n",
    "            baseline_ = baseline_.loc[X_test_baseline['YEAR_0'] < 2019]\n",
    "        index = baseline_.index\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "        LATS_BASE_3 = np.array(baseline_[forecast3 + '_24_lat_7'])\n",
    "        LONS_BASE_3 = np.array(baseline_[forecast3 + '_24_lon_7'])\n",
    "        LATS_BASE_4 = np.array(baseline_[forecast4 + '_24_lat_7'])\n",
    "        LONS_BASE_4 = np.array(baseline_[forecast4 + '_24_lon_7'])\n",
    "        LATS_BASE_5 = np.array(baseline_[forecast5 + '_24_lat_7'])\n",
    "        LONS_BASE_5 = np.array(baseline_[forecast5 + '_24_lon_7'])\n",
    "        LATS_BASE_6 = np.array(baseline_[forecast6 + '_24_lat_7'])\n",
    "        LONS_BASE_6 = np.array(baseline_[forecast6 + '_24_lon_7'])\n",
    "        LATS_BASE_7 = np.array(baseline_[forecast7 + '_24_lat_7'])\n",
    "        LONS_BASE_7 = np.array(baseline_[forecast7 + '_24_lon_7'])\n",
    "        \n",
    "    LATS_TEST_ = np.array(X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx)[index]\n",
    "    LONS_TEST_ = np.array(X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy)[index]\n",
    "    baseline_1_x = np.array(baseline_[forecast + '_24_'+mode+'_7'])\n",
    "    baseline_1_y = np.array(baseline_[forecast + '_24_lon_7'])\n",
    "    baseline_2_x = np.array(baseline_[forecast2 + '_24_'+mode+'_7'])\n",
    "    baseline_2_y = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    baseline_3_x = np.array(baseline_[forecast3 + '_24_'+mode+'_7'])\n",
    "    baseline_3_y = np.array(baseline_[forecast3 + '_24_lon_7'])\n",
    "    baseline_4_x = np.array(baseline_[forecast4 + '_24_'+mode+'_7'])\n",
    "    baseline_4_y = np.array(baseline_[forecast4 + '_24_lon_7'])\n",
    "    baseline_5_x = np.array(baseline_[forecast5 + '_24_'+mode+'_7'])\n",
    "    baseline_5_y = np.array(baseline_[forecast5 + '_24_lon_7'])\n",
    "    baseline_6_x = np.array(baseline_[forecast6 + '_24_'+mode+'_7'])\n",
    "    baseline_6_y = np.array(baseline_[forecast6 + '_24_lon_7'])\n",
    "    baseline_7_x = np.array(baseline_[forecast7 + '_24_'+mode+'_7'])\n",
    "    baseline_7_y = np.array(baseline_[forecast7 + '_24_lon_7'])\n",
    "    LATS_PRED_ = np.array(LATS_PRED_)[index]\n",
    "    LONS_PRED_ = np.array(LONS_PRED_)[index]\n",
    "    d_km_baseline = np.zeros(len(LATS_PRED_))\n",
    "    d_km_baseline2 = np.zeros(len(LATS_PRED_))\n",
    "    d_km_baseline3 = np.zeros(len(LATS_PRED_))\n",
    "    d_km_baseline4 = np.zeros(len(LATS_PRED_))\n",
    "    d_km_baseline5 = np.zeros(len(LATS_PRED_))\n",
    "    d_km_baseline6 = np.zeros(len(LATS_PRED_))\n",
    "    d_km_baseline7 = np.zeros(len(LATS_PRED_))\n",
    "    d_km_consensus_ofcl, d_km_consensus_hurr = np.zeros(len(LATS_PRED_)), np.zeros(len(LATS_PRED_))\n",
    "    d_km_pred = np.zeros(len(LONS_PRED_))\n",
    "    for i in range(len(LATS_PRED_)):\n",
    "        if baseline_1_y[i] > 150:\n",
    "            baseline_1_y[i] -= 360\n",
    "            baseline_6_y[i] -= 360\n",
    "            baseline_5_y[i] -= 360\n",
    "            baseline_3_y[i] -= 360\n",
    "        if baseline_2_y[i] > 150:\n",
    "            baseline_2_y[i] -= 360\n",
    "            \n",
    "        if LONS_TEST_[i] > 150:\n",
    "            LONS_PRED_[i] -= 360\n",
    "        d_km_baseline[i] = get_distance_km(baseline_1_y[i], baseline_1_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_pred[i] = get_distance_km(LONS_PRED_[i], LATS_PRED_[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_baseline2[i] = get_distance_km(baseline_2_y[i], baseline_2_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_baseline3[i] = get_distance_km(baseline_3_y[i], baseline_3_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_baseline4[i] = get_distance_km(baseline_4_y[i], baseline_4_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_baseline5[i] = get_distance_km(baseline_5_y[i], baseline_5_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_baseline6[i] = get_distance_km(baseline_6_y[i], baseline_6_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_baseline7[i] = get_distance_km(baseline_7_y[i], baseline_7_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Number of timesteps:\", len(LATS_PRED_))\n",
    "    print(basin, 'Model | MAE | std | %age busts (>200km)')\n",
    "    print(\"Hurricast\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2), np.around(sum(d_km_pred > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(forecast, np.around(d_km_baseline.mean(), decimals = 2), np.around(d_km_baseline.std(), decimals = 2), np.around(sum(d_km_baseline > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(forecast2, np.around(d_km_baseline2.mean(), decimals = 2), np.around(d_km_baseline2.std(), decimals = 2), np.around(sum(d_km_baseline2 > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(str(forecast3), np.around(d_km_baseline3.mean(), decimals = 2), np.around(d_km_baseline3.std(), decimals = 2), np.around(sum(d_km_baseline3 > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(str(forecast4), np.around(d_km_baseline4.mean(), decimals = 2), np.around(d_km_baseline4.std(), decimals = 2), np.around(sum(d_km_baseline4 > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(str(forecast5), np.around(d_km_baseline5.mean(), decimals = 2), np.around(d_km_baseline5.std(), decimals = 2), np.around(sum(d_km_baseline5 > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(forecast6, np.around(d_km_baseline6.mean(), decimals = 2), np.around(d_km_baseline6.std(), decimals = 2), np.around(sum(d_km_baseline6 > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(forecast7, np.around(d_km_baseline7.mean(), decimals = 2), np.around(d_km_baseline7.std(), decimals = 2), np.around(sum(d_km_baseline7 > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    consensus_ofcl_x = (baseline_1_x+baseline_2_x+baseline_3_x+baseline_4_x + baseline_5_x + baseline_6_x)/6\n",
    "    consensus_ofcl_y = (baseline_1_y+baseline_2_y+baseline_3_y+baseline_4_y + baseline_5_y + baseline_6_y)/6\n",
    "    consensus_hurr_x = (consensus_ofcl_x*6+LATS_PRED_)/7\n",
    "    consensus_hurr_y = (consensus_ofcl_y*6+LONS_PRED_)/7\n",
    "    for i in range(len(LATS_PRED_)):\n",
    "        d_km_consensus_ofcl[i] = get_distance_km(consensus_ofcl_y[i], consensus_ofcl_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "        d_km_consensus_hurr[i] = get_distance_km(consensus_hurr_y[i], consensus_hurr_x[i], LONS_TEST_[i], LATS_TEST_[i])\n",
    "    print(\"Consensus OFCL only\", np.around(d_km_consensus_ofcl.mean(), decimals = 2), np.around(d_km_consensus_ofcl.std(), decimals = 2), np.around(sum(d_km_consensus_ofcl > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    print(\"Consensus OFCL + Hurricast\", np.around(d_km_consensus_hurr.mean(), decimals = 2), np.around(d_km_consensus_hurr.std(), decimals = 2), np.around(sum(d_km_consensus_hurr > 200)*100/len(LATS_PRED_), decimals = 2))\n",
    "    #return LONS_PRED_, baseline_1_y, baseline_2_y, baseline_3_y, baseline_4_y, baseline_5_y, baseline_6_y\n",
    "    #return d_km_pred, np.array(X_test)[index]\n",
    "    #return d_km_consensus_ofcl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 353.18 237.21 73.88\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 130.25 104.63 17.47\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 234.62 154.17 50.55\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 96.07 62.17 5.49\n",
      "Consensus OFCL + Hurricast 98.99 62.81 6.37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-113.896095, -113.35424 , -113.81416 , -113.71246 , -118.871025,\n",
       "        -117.32559 , -119.69119 , -119.92336 , -119.70785 , -120.48424 ,\n",
       "        -122.019226, -122.57149 , -124.30609 , -125.517204, -126.37299 ,\n",
       "        -125.86198 , -127.954994, -127.541504, -129.80507 , -132.62218 ,\n",
       "        -133.70149 , -133.55533 , -134.68195 , -135.4887  , -136.09929 ,\n",
       "        -135.99869 , -136.43723 , -135.9923  , -135.83348 , -137.20183 ,\n",
       "        -138.16698 , -138.53195 , -139.91226 , -140.64418 , -142.1431  ,\n",
       "        -141.76706 , -142.80746 , -144.09819 , -146.20631 , -147.34523 ,\n",
       "        -148.13853 , -148.30122 , -119.82945 , -121.30429 , -121.83786 ,\n",
       "        -122.71592 , -123.34465 , -124.263435, -123.8698  , -125.121864,\n",
       "        -126.245316, -127.30112 , -130.42972 , -132.13223 , -134.04724 ,\n",
       "        -135.94655 , -137.4131  , -139.15878 , -139.19934 , -137.97804 ,\n",
       "        -139.15869 , -138.51611 , -139.41913 , -140.47815 , -141.80225 ,\n",
       "        -106.73873 , -107.190056, -107.83348 , -108.7763  , -108.95467 ,\n",
       "        -110.675285, -112.14495 , -114.51938 , -115.31884 , -116.84216 ,\n",
       "        -117.97813 , -120.03706 , -120.58829 , -120.79298 , -121.3052  ,\n",
       "        -122.39387 , -121.89968 , -122.47864 , -122.636444, -123.79415 ,\n",
       "        -124.00727 , -124.30852 , -125.95769 , -126.6119  , -120.38794 ,\n",
       "        -120.07559 , -119.947876, -120.46985 , -122.86861 , -124.28772 ,\n",
       "        -125.22453 , -126.772385, -127.23506 , -128.70827 , -128.87196 ,\n",
       "        -127.17577 , -128.04451 , -129.25072 , -128.97585 , -128.53856 ,\n",
       "        -128.62619 , -126.99097 , -125.94056 , -127.052795, -127.15651 ,\n",
       "        -127.29144 , -128.39865 , -129.62273 , -131.00612 , -130.58731 ,\n",
       "        -131.98332 , -131.23654 , -112.66125 , -112.1073  , -113.36851 ,\n",
       "        -113.647736, -128.98447 , -127.466064, -125.149574, -125.788666,\n",
       "        -125.954765, -109.73775 , -111.55094 , -112.01261 , -110.220955,\n",
       "        -108.17767 , -109.25049 , -110.69003 , -111.39997 , -111.853874,\n",
       "        -113.398125, -114.445076, -115.04092 , -115.11403 , -116.20005 ,\n",
       "        -113.03826 , -114.39051 , -114.49879 , -113.84014 , -115.165085,\n",
       "        -114.78274 , -115.7991  , -116.43769 , -117.38258 , -117.55114 ,\n",
       "        -106.36088 , -108.72526 , -109.06051 , -107.79037 , -108.697914,\n",
       "        -110.285736, -110.671715, -111.62696 , -110.62025 , -111.762474,\n",
       "        -111.85574 , -111.43341 , -111.531555, -115.51762 , -117.9402  ,\n",
       "        -118.93081 , -120.36268 , -123.32299 , -122.99373 , -124.33042 ,\n",
       "        -124.471825, -124.75967 , -126.37032 , -129.01851 , -130.44484 ,\n",
       "        -133.09178 , -130.53386 , -132.45891 , -133.74916 , -134.89395 ,\n",
       "        -134.78833 , -135.74965 , -137.96019 , -138.98349 , -138.60019 ,\n",
       "        -139.72255 , -140.40627 , -142.21239 , -144.93987 , -147.51328 ,\n",
       "        -148.38431 , -149.27676 , -150.23145 , -151.4482  , -152.31688 ,\n",
       "        -152.53384 , -153.20605 , -156.59628 , -157.87569 , -159.4813  ,\n",
       "        -161.5249  , -163.57936 , -163.84016 , -165.48204 , -166.89445 ,\n",
       "        -169.38242 , -170.31985 , -171.65042 , -172.20337 , -173.0507  ,\n",
       "        -172.41302 , -173.9154  , -173.97638 , -174.12383 , -176.59442 ,\n",
       "        -178.36719 , -179.833   , -180.49164 , -181.08986 , -181.73727 ,\n",
       "        -184.0924  , -186.79663 , -114.62784 , -116.366585, -116.290924,\n",
       "        -117.428406, -118.12666 , -119.235725, -120.64306 , -120.96854 ,\n",
       "        -122.22329 , -124.868935, -125.79387 , -125.30626 , -124.48857 ,\n",
       "        -133.42018 , -134.77007 , -134.2721  , -133.98372 , -131.71536 ,\n",
       "        -132.5801  , -132.5097  , -131.74991 , -131.87129 , -131.74812 ,\n",
       "        -132.26433 , -132.35411 , -133.31503 , -136.41708 , -138.3532  ,\n",
       "        -139.86873 , -142.55968 , -143.80017 , -145.18484 , -144.81218 ,\n",
       "        -146.88087 , -146.51897 , -149.0215  , -149.97206 , -151.80482 ,\n",
       "        -152.166   , -152.67891 , -153.46526 , -154.99098 , -155.74872 ,\n",
       "        -156.26671 , -158.6512  , -159.48544 , -159.60547 , -158.74437 ,\n",
       "        -157.72185 , -159.41599 , -161.17519 , -161.12263 , -161.02405 ,\n",
       "        -158.8117  , -159.11888 , -159.01341 , -158.87253 , -160.2936  ,\n",
       "        -160.72719 , -161.08209 , -162.41042 , -164.52766 , -166.1731  ,\n",
       "        -166.43124 , -167.11421 , -140.34732 , -140.88605 , -140.8998  ,\n",
       "        -142.74709 , -143.33385 , -142.96298 , -144.65297 , -146.56891 ,\n",
       "        -145.55971 , -145.58955 , -146.3828  , -145.90083 , -142.66106 ,\n",
       "        -139.66362 , -138.87929 , -139.6987  , -137.94414 , -139.8229  ,\n",
       "        -138.35849 , -121.97345 , -121.81304 , -122.93254 , -123.53619 ,\n",
       "        -125.29713 , -125.63642 , -126.2679  , -127.47957 , -128.5817  ,\n",
       "        -130.2753  , -131.2284  , -132.72336 , -134.19606 , -136.21005 ,\n",
       "        -138.31096 , -140.21779 , -141.77258 , -143.6568  , -145.77419 ,\n",
       "        -147.25682 , -148.62936 , -150.42104 , -150.65927 , -153.2818  ,\n",
       "        -152.7652  , -152.04292 , -154.368   , -156.30794 , -155.22566 ,\n",
       "        -155.02736 , -155.69186 , -155.2876  , -155.22852 , -156.52415 ,\n",
       "        -158.53497 , -157.8964  , -156.70073 , -156.65265 , -158.23743 ,\n",
       "        -118.63274 , -120.85433 , -121.39505 , -122.25745 , -123.05192 ,\n",
       "        -124.8147  , -125.92982 , -127.156296, -128.11246 , -129.51515 ,\n",
       "        -131.50484 , -132.06345 , -132.78938 , -135.29321 , -137.5413  ,\n",
       "        -138.85063 , -140.84164 , -142.00664 , -143.0861  , -143.90265 ,\n",
       "        -145.49638 , -147.46918 , -148.54039 , -148.90556 , -148.87523 ,\n",
       "        -150.81024 , -152.04283 , -152.43872 , -153.44206 , -152.65674 ,\n",
       "        -154.72772 , -156.59663 , -155.42334 , -157.6637  , -159.39067 ,\n",
       "        -162.76797 , -116.44232 , -118.99191 , -120.41539 , -119.742165,\n",
       "        -121.6935  , -121.27454 , -121.36895 , -120.51037 , -121.62152 ,\n",
       "        -122.06037 , -121.71289 , -121.03022 , -120.83443 , -119.25229 ,\n",
       "        -117.12477 , -114.09811 , -113.87305 , -111.99581 , -111.98087 ,\n",
       "        -113.99632 , -114.826065, -117.23295 , -117.99311 , -119.196075,\n",
       "        -119.40539 , -120.99734 , -121.878456, -122.24799 , -121.1091  ,\n",
       "        -121.13618 , -122.178154, -122.72239 , -121.447815, -122.6727  ,\n",
       "        -122.99554 , -123.527084, -124.49684 , -125.746155, -125.978714,\n",
       "        -127.63027 , -126.871284, -129.66377 , -130.5996  , -130.88608 ,\n",
       "        -130.70293 , -130.93251 , -131.49687 , -131.69655 , -129.84053 ,\n",
       "        -129.15317 , -129.51659 , -128.44968 , -126.76421 , -127.47577 ,\n",
       "        -126.072556, -124.30898 , -122.667336, -121.441505, -120.76243 ,\n",
       "        -117.749664,  -99.925186, -101.35943 , -103.28899 , -104.45193 ,\n",
       "        -109.70743 , -108.98568 , -107.23728 , -104.4396  , -109.31256 ,\n",
       "        -108.83183 , -110.01837 , -110.9837  , -111.61628 , -112.482666],\n",
       "       dtype=float32),\n",
       " array([-112.5, -113. , -113.5, -114.2, -118. , -118.5, -119. , -119.7,\n",
       "        -120.2, -120.5, -121. , -121. , -123.5, -124.5, -125.8, -126.9,\n",
       "        -128.5, -129.4, -130.5, -132. , -132.7, -133.4, -133.5, -134.3,\n",
       "        -134.5, -134.8, -135.2, -135.7, -136.3, -136.5, -137.4, -138.2,\n",
       "        -139. , -139.8, -140.8, -141.4, -142.2, -143.3, -143.9, -145.7,\n",
       "        -146.9, -148.3, -120.4, -120.5, -121.8, -123.2, -123.4, -124.2,\n",
       "        -125.5, -126.5, -127. , -128.9, -131.5, -132.4, -132.5, -134. ,\n",
       "        -135.4, -136.3, -136.9, -137.5, -138. , -138.7, -139.7, -140.2,\n",
       "        -141. , -108. , -108.5, -109.4, -110.2, -110.9, -111.8, -112.9,\n",
       "        -114. , -116. , -116.9, -117.7, -118.4, -119. , -119.4, -120.5,\n",
       "        -121.4, -122.5, -123.7, -124.5, -125.3, -125.9, -126.5, -127.8,\n",
       "        -128.9, -120.8, -120.8, -121. , -121.8, -122. , -122.8, -123.3,\n",
       "        -123.8, -123.8, -124.7, -125.5, -125.7, -125.5, -124.3, -124.7,\n",
       "        -125.2, -124.7, -125.2, -125.5, -126. , -126.7, -127.8, -128. ,\n",
       "        -128.7, -129.7, -130.7, -130.5, -131.2, -114.4, -115. , -116.2,\n",
       "        -117.3, -127.5, -128. , -127.8, -128.7, -128.8, -110.4, -110.7,\n",
       "        -111.3, -111.3, -111.3, -111.9, -112.2, -112.3, -113.3, -113.7,\n",
       "        -114.5, -114.8, -115.4, -116. , -112.8, -112.7, -112.9, -113.5,\n",
       "        -114. , -114.4, -115.4, -115.8, -116.9, -117.5, -107.7, -108.2,\n",
       "        -108.2, -108.8, -108.7, -109.7, -109.9, -110. , -110. , -110. ,\n",
       "        -109.9, -109.9, -109.7, -118.2, -119. , -120. , -121.3, -123.9,\n",
       "        -124.5, -125.5, -126.9, -128.2, -129.2, -130.2, -131.3, -132.4,\n",
       "        -130.9, -132. , -133.2, -134.3, -135.3, -136. , -136.8, -137.5,\n",
       "        -139. , -140.3, -141.5, -142.8, -144.2, -145.8, -147. , -148.5,\n",
       "        -150. , -152.3, -153.3, -154.4, -156. , -157.2, -159. , -160.7,\n",
       "        -162. , -163.5, -165. , -166.3, -167. , -168.9, -169.9, -171. ,\n",
       "        -171.9, -173.3, -174.3, -175. , -176.2, -177. , -179.4, -180.5,\n",
       "        -182. , -183.3, -184.7, -186.8, -188.7, -190.4, -113.8, -115. ,\n",
       "        -116.2, -117.2, -118.3, -118.8, -120. , -121.4, -122.3, -123.3,\n",
       "        -124. , -124.5, -124.9, -130.2, -130.2, -130.5, -130. , -130. ,\n",
       "        -129.4, -128.9, -128.4, -128.5, -129.3, -129.7, -130.5, -132. ,\n",
       "        -137.7, -138.8, -140.4, -141.8, -143. , -144.5, -145.2, -146.2,\n",
       "        -146.3, -147.5, -148.5, -149.5, -150.7, -151.9, -153. , -154. ,\n",
       "        -154.5, -155.4, -156. , -156.4, -156.5, -156.9, -157.3, -157.3,\n",
       "        -157.8, -158.3, -157.9, -158.3, -158.8, -159.3, -159.2, -160.3,\n",
       "        -160.9, -161.8, -162.3, -163.9, -165. , -166. , -166.8, -138. ,\n",
       "        -138.9, -139.2, -139.9, -141.3, -141.5, -141.7, -141.9, -142. ,\n",
       "        -141.7, -141.5, -141.9, -142.5, -142.5, -143. , -143.8, -144.3,\n",
       "        -145.4, -145.4, -122. , -122.2, -123.5, -124. , -125. , -126. ,\n",
       "        -127.3, -128.4, -130. , -131.3, -133.2, -134.2, -136.5, -138. ,\n",
       "        -139. , -141.3, -142.9, -143.7, -145. , -146.4, -147.9, -148.7,\n",
       "        -149.3, -149.9, -150.4, -150.8, -151.5, -152. , -152.7, -153. ,\n",
       "        -153.8, -154.7, -155.3, -155.7, -155.7, -156. , -155.9, -154.5,\n",
       "        -154.3, -119.5, -120.3, -121. , -123. , -123.9, -125.7, -127. ,\n",
       "        -128.5, -129.8, -131.4, -132.3, -133.5, -134.5, -135.5, -137. ,\n",
       "        -138.3, -139.4, -141. , -142.2, -143.5, -144.7, -146. , -147.3,\n",
       "        -148. , -149.3, -150.5, -151.5, -152.4, -153.4, -154.7, -155.8,\n",
       "        -156.8, -158. , -159. , -159.5, -165.2, -116.5, -117.5, -118. ,\n",
       "        -118. , -118.4, -119.4, -118.9, -119.2, -118.5, -118.4, -118.5,\n",
       "        -117.9, -117.5, -117. , -116.4, -115.5, -114.5, -113.7, -113.3,\n",
       "        -114.3, -115. , -116. , -116.5, -117.8, -118.5, -119.2, -119.4,\n",
       "        -120.5, -121. , -121.8, -121.9, -122.5, -122.9, -123.5, -124. ,\n",
       "        -124.8, -125. , -125.4, -126. , -126.2, -126.5, -126.9, -127. ,\n",
       "        -126.8, -127.3, -127. , -126.8, -126.8, -126. , -125. , -124. ,\n",
       "        -122.8, -122. , -120.8, -119.3, -117.8, -116.5, -115. , -113. ,\n",
       "        -111.4, -101.3, -101.7, -102.2, -102.6, -107.4, -107.2, -106.4,\n",
       "        -105.2, -107.3, -108.5, -110.2, -110.3, -110.9, -111.5],\n",
       "       dtype=float32),\n",
       " array([-112.1, -112.4, -114.2, -116. , -118. , -119. , -119.3, -119.5,\n",
       "        -120. , -120.3, -120.4, -121.1, -123.4, -124.9, -126.4, -127.3,\n",
       "        -129.3, -130.4, -131.6, -132.5, -132.7, -133.1, -133.7, -133.6,\n",
       "        -133.8, -134.6, -135.9, -136.1, -136.8, -136.9, -137.2, -138.3,\n",
       "        -138.9, -139.9, -140.4, -141. , -141.8, -143.5, -144.5, -145.5,\n",
       "        -146. , -148.1, -118.1, -119.7, -120.1, -121.4, -122.5, -123.4,\n",
       "        -124.2, -125.8, -127.1, -128.8, -131.3, -132.6, -134.1, -134.9,\n",
       "        -135.3, -136. , -136.3, -136.7, -137.3, -138. , -138.5, -138.7,\n",
       "        -139.9, -107.7, -108.7, -109.3, -110.5, -111. , -112.2, -113.6,\n",
       "        -115.2, -115.5, -116.6, -117.1, -118.1, -118.6, -119.1, -120.5,\n",
       "        -120.7, -121.3, -122.4, -122.8, -122.7, -124.3, -126.5, -127.6,\n",
       "        -129.3, -120.9, -121.5, -122.5, -123.1, -123.6, -124. , -124.6,\n",
       "        -125.4, -125.9, -126. , -126. , -125.5, -126.2, -126.4, -125.2,\n",
       "        -124.3, -125.5, -126. , -125.6, -125.3, -126.3, -127.2, -128.2,\n",
       "        -128.6, -128.9, -130.1, -130.7, -130.8, -116.6, -118.3, -118.3,\n",
       "        -118.4, -128.7, -129.1, -129.3, -129.6, -129.9, -110. , -110.5,\n",
       "        -111.2, -111.3, -112.1, -113.3, -113.9, -114.2, -114.5, -115.4,\n",
       "        -115.7, -116.5, -116.6, -117.3, -111.8, -112.3, -113. , -113.4,\n",
       "        -114.3, -115. , -115.5, -116.2, -117. , -117.7, -106.7, -107.6,\n",
       "        -108.2, -109.2, -109.5, -110.9, -110.1, -110.5, -110.2, -111.1,\n",
       "        -110.6, -111.1, -110.8, -117.5, -118.3, -119.3, -120.7, -123.8,\n",
       "        -124.8, -125.8, -127. , -127.9, -128.9, -129.9, -131.6, -133.1,\n",
       "        -130.4, -131. , -131.8, -132.8, -134.6, -135.3, -136.7, -137.7,\n",
       "        -138.8, -139.9, -141.5, -142.4, -144. , -145.3, -146.3, -149. ,\n",
       "        -150.4, -151.5, -152.5, -154. , -156.5, -158.1, -159.6, -160.7,\n",
       "        -162.3, -163.3, -164.6, -166. , -167.8, -168.5, -169.2, -169.7,\n",
       "        -171. , -171.9, -172.8, -174.2, -176.3, -177.1, -178.5, -179.8,\n",
       "        -181.6, -183.3, -185.4, -186.7, -188.8, -190.7, -113.5, -115. ,\n",
       "        -116.1, -117.4, -118.4, -120.1, -120.8, -122.5, -123.3, -124.2,\n",
       "        -125.2, -125.7, -125. , -129.8, -129.7, -128.3, -129.1, -127.5,\n",
       "        -127.2, -126.9, -128.2, -128.9, -129.2, -129.8, -131.5, -132.3,\n",
       "        -136.8, -138.5, -139.5, -141.4, -141.9, -143.1, -143.8, -144.3,\n",
       "        -145.6, -147.3, -147.7, -149.3, -150.6, -151.4, -153.1, -154.1,\n",
       "        -154.6, -154.7, -155.2, -155.8, -156.3, -156.4, -156.2, -156.3,\n",
       "        -156.3, -156.5, -156.2, -157.1, -156.1, -156.9, -158.5, -158.8,\n",
       "        -159.4, -160.5, -162.7, -163.9, -165.7, -165.9, -167.4, -137.8,\n",
       "        -138.6, -139.4, -140.4, -140.9, -141.1, -141. , -141. , -141.1,\n",
       "        -141.5, -141.5, -140.9, -141.2, -141.9, -142.3, -142.9, -143.8,\n",
       "        -145. , -145.7, -122. , -122.7, -123.3, -123.9, -125.5, -126.7,\n",
       "        -128.1, -128.8, -130.4, -133.3, -134.6, -135.5, -137.3, -139.2,\n",
       "        -140.7, -141.8, -142.9, -144.4, -145.6, -146.5, -147.2, -148.1,\n",
       "        -149.3, -149.7, -150.9, -151.2, -152. , -150.6, -151.4, -152.9,\n",
       "        -152.4, -152.7, -154.7, -155.3, -155.2, -155.3, -155.4, -154.2,\n",
       "        -153.8, -119.1, -120.9, -121.3, -122.6, -123.7, -125.1, -126.1,\n",
       "        -127.6, -128.4, -129.8, -131.1, -132.2, -133.7, -135.9, -136.8,\n",
       "        -138. , -139.3, -140.5, -141.7, -144.2, -145.1, -146.1, -147.4,\n",
       "        -148.8, -149.5, -150.2, -151.3, -152.1, -153.3, -154.7, -155.2,\n",
       "        -157.3, -158.6, -160.7, -161.7, -167.2, -116.7, -116.8, -117.2,\n",
       "        -117.8, -118.4, -118.4, -117.6, -118.8, -118.8, -118.6, -117.8,\n",
       "        -117.4, -117.2, -116.3, -116.1, -115.6, -114.1, -114. , -113.8,\n",
       "        -114.4, -115.1, -116.5, -117.1, -118.2, -117.9, -118.8, -119.5,\n",
       "        -120.5, -121. , -121.6, -121.5, -121.9, -122.8, -123.4, -124.2,\n",
       "        -124.7, -125.4, -125.7, -126. , -126.4, -126.8, -127.7, -127.7,\n",
       "        -128.1, -128. , -127.8, -127. , -126.7, -125.6, -124.2, -124. ,\n",
       "        -123. , -121.5, -120.7, -119.8, -119.3, -117.2, -115.5, -113.2,\n",
       "        -112.9, -100.9, -102. , -102.5, -102.8, -108.4, -107.7, -107.2,\n",
       "        -106.4, -107.8, -108. , -110. , -110.7, -111. , -111.6],\n",
       "       dtype=float32),\n",
       " array([-112.1, -112.7, -113.7, -114.7, -118.2, -118.4, -119.2, -119.6,\n",
       "        -120. , -120.6, -120.8, -120.9, -123.5, -124.6, -125.8, -127.3,\n",
       "        -128.4, -129.5, -131. , -131.9, -132.3, -133.3, -133.5, -134. ,\n",
       "        -134.2, -134.6, -135. , -135.6, -136. , -136.7, -137.6, -138.3,\n",
       "        -139.1, -139.8, -140.6, -141.3, -142.2, -143.3, -144.2, -145.8,\n",
       "        -147.3, -148.4, -119.7, -120.5, -121.7, -122.4, -122.9, -124.3,\n",
       "        -125.3, -126.1, -127.4, -129. , -131.6, -132. , -133.1, -134.6,\n",
       "        -135.5, -136.2, -136.8, -137.6, -137.8, -138.7, -139.5, -140.2,\n",
       "        -140.8, -107.9, -108.5, -109.5, -110. , -110.9, -112. , -113. ,\n",
       "        -114.8, -116. , -116.8, -117.5, -118.2, -118.9, -119.7, -120.5,\n",
       "        -121.7, -122.8, -123.5, -124.3, -124.9, -125.4, -126.5, -127.8,\n",
       "        -128.8, -120.5, -120.6, -121.3, -121.7, -122.2, -122.8, -123.6,\n",
       "        -124. , -124.7, -125.5, -126. , -125.3, -124.3, -125. , -125. ,\n",
       "        -124.8, -124.5, -125.5, -126. , -125.9, -127. , -127.8, -128. ,\n",
       "        -128.9, -129.8, -130. , -130.5, -131.1, -114.4, -115.5, -116.7,\n",
       "        -117.5, -128. , -127.9, -128.3, -128.6, -129. , -110.3, -111. ,\n",
       "        -111.3, -111.3, -111.3, -112. , -112.1, -113. , -113.2, -114.2,\n",
       "        -114.5, -115.3, -115.8, -116.3, -112.5, -112.7, -113. , -113.7,\n",
       "        -114. , -114.8, -115.4, -116.3, -116.9, -117.4, -107.6, -107.9,\n",
       "        -108.5, -109. , -109.2, -109.5, -109.9, -110.1, -110. , -110. ,\n",
       "        -109.9, -109.9, -109.8, -118.3, -119. , -120.2, -121. , -123.7,\n",
       "        -124.7, -125.7, -127. , -128.2, -129.2, -130.2, -131.2, -132.5,\n",
       "        -131. , -132. , -133.3, -134.3, -135.1, -135.8, -136.6, -137.8,\n",
       "        -139.1, -140.1, -141.4, -142.7, -144.2, -145.6, -147.1, -148.4,\n",
       "        -150.3, -151.7, -153. , -154.1, -155.7, -157.6, -159.2, -160.4,\n",
       "        -162. , -163.5, -165. , -165.9, -167.4, -168.7, -169.9, -170.7,\n",
       "        -172.2, -172.9, -173.8, -174.9, -176. , -177.7, -179.3, -180.4,\n",
       "        -181.8, -183.2, -185.1, -187.2, -188.6, -190.2, -114. , -114.9,\n",
       "        -116.1, -117.3, -118.1, -119. , -120.2, -121.4, -122.2, -123.4,\n",
       "        -124. , -124.5, -124.8, -130.1, -130.5, -130.4, -130. , -129.7,\n",
       "        -128.9, -128.6, -128.6, -129.1, -129.4, -130.1, -131.5, -132.4,\n",
       "        -137.6, -139.1, -140.3, -141.9, -143.3, -144.1, -145. , -145.5,\n",
       "        -146.3, -147.5, -148.9, -149.7, -150.8, -152. , -152.9, -153.8,\n",
       "        -154.8, -155.3, -155.9, -156. , -156.5, -156.9, -157.3, -157.6,\n",
       "        -158. , -157.8, -158.2, -158.1, -158.6, -158.7, -159.6, -160.1,\n",
       "        -160.9, -160.8, -163.4, -163.7, -165.3, -166. , -166.2, -138.1,\n",
       "        -139. , -139.5, -140.1, -141.3, -141.7, -141.8, -142. , -142.1,\n",
       "        -141.5, -141.6, -141.9, -142.3, -142.5, -143. , -143.6, -144.4,\n",
       "        -144.7, -145.6, -122. , -122.5, -123.3, -124.1, -125.1, -126.3,\n",
       "        -127.4, -128.6, -129.9, -131.8, -132.9, -134.6, -136.5, -137.8,\n",
       "        -139.7, -141.5, -142.7, -144. , -145.4, -146.9, -147.9, -148.7,\n",
       "        -149.2, -149.9, -150.3, -151. , -151.4, -152.3, -152.7, -153.4,\n",
       "        -154.1, -154.8, -155. , -155.7, -155.4, -156. , -154.7, -154.4,\n",
       "        -154. , -119.3, -120.3, -121.7, -123. , -124.2, -125.9, -127.2,\n",
       "        -128.5, -129.7, -130.8, -132.1, -133.3, -134.5, -135.5, -137. ,\n",
       "        -138.2, -139.5, -140.9, -142.3, -143.7, -145. , -146.2, -147.2,\n",
       "        -148.1, -149.4, -150.6, -151.2, -152.5, -153.7, -154.5, -155.7,\n",
       "        -156.8, -158.1, -158.5, -160.2, -164.4, -116.7, -117.5, -117.7,\n",
       "        -118.2, -118.8, -119.4, -119. , -118.8, -118.8, -118.8, -118.4,\n",
       "        -117.9, -117.3, -116.7, -116. , -115.3, -114.5, -114. , -113.5,\n",
       "        -114.5, -115.2, -116.1, -116.8, -118. , -118.5, -119. , -119.6,\n",
       "        -120.5, -121.1, -121.5, -122. , -122.4, -122.8, -123.5, -124.1,\n",
       "        -124.5, -125. , -125.5, -126. , -126.3, -126.5, -127. , -127. ,\n",
       "        -127.4, -127.4, -127.2, -127.3, -126.7, -125.8, -124.8, -124. ,\n",
       "        -123.2, -122.1, -120.7, -119.3, -118.2, -116.5, -114.7, -113. ,\n",
       "        -111. , -101. , -101.2, -102.1, -102.3, -107.5, -107.1, -106.2,\n",
       "        -104.6, -107.7, -109. , -109.9, -110.6, -111. , -111.2],\n",
       "       dtype=float32),\n",
       " array([-111.9, -112.5, -113.8, -114.8, -118.3, -118.4, -119.3, -119.6,\n",
       "        -120.1, -120.6, -120.6, -121. , -123.2, -124.6, -125.9, -127.5,\n",
       "        -128.5, -129.9, -131. , -131.8, -132.2, -133. , -133.1, -133.5,\n",
       "        -133.7, -134. , -134.6, -135.3, -135.8, -136.6, -137.4, -138.3,\n",
       "        -139.1, -140.3, -140.6, -141.5, -142.5, -143.5, -144.3, -146. ,\n",
       "        -146.5, -147.1, -118.9, -119.4, -121.2, -122.2, -122.2, -123.6,\n",
       "        -125.2, -125.6, -127.2, -128.7, -131.3, -132. , -133.2, -134.9,\n",
       "        -135.6, -136. , -136.5, -136.9, -137.5, -138.3, -139. , -139.3,\n",
       "        -139.9, -107.7, -108.2, -109.5, -110.3, -111.1, -111.8, -113.3,\n",
       "        -114.7, -116.3, -116.9, -117.5, -117.8, -118.6, -119.6, -120.6,\n",
       "        -121.6, -122.4, -123.2, -124.5, -124.6, -124.8, -126.3, -128.2,\n",
       "        -129.4, -120.4, -120.7, -121.3, -122.1, -122.6, -122.8, -123.1,\n",
       "        -123.9, -124.3, -125. , -125.3, -124.8, -124.4, -124.8, -124.1,\n",
       "        -124. , -124.3, -125.7, -125.9, -126. , -127.2, -127.6, -128.5,\n",
       "        -129.3, -129.8, -130. , -130.8, -131.3, -114.3, -115.8, -117. ,\n",
       "        -117.8, -127.5, -127.7, -128.1, -128.5, -128.7, -110.1, -110.4,\n",
       "        -110.9, -111.1, -111.3, -111.9, -112.4, -113.1, -113.1, -114.2,\n",
       "        -114.3, -115.1, -115.5, -115.9, -112.3, -112.3, -112.9, -113.4,\n",
       "        -113.8, -114.4, -115.1, -115.9, -116.6, -117.3, -106.9, -107.4,\n",
       "        -108.2, -108.7, -108.8, -109.3, -109.9, -109.9, -109.8, -109.6,\n",
       "        -110. , -109.7, -110. , -118.4, -119. , -120.2, -121.1, -123.6,\n",
       "        -124.7, -125.8, -127. , -128.4, -129.2, -130.3, -131.1, -132.8,\n",
       "        -131.1, -132.1, -133.3, -134.1, -135.1, -135.9, -136.6, -137.7,\n",
       "        -138.7, -140. , -141.3, -142.5, -144.1, -145.4, -147.2, -148.2,\n",
       "        -150.1, -151.7, -152.8, -154. , -155.8, -157.8, -159.1, -160.5,\n",
       "        -162. , -163.7, -164.7, -166. , -167.5, -168.8, -169.8, -170.4,\n",
       "        -171.5, -172. , -173.4, -172. , -171.5, -175.4, -179.6, -180. ,\n",
       "        -178.9, -176.2, -174.2, -172.4, -170.8, -168.4, -113.7, -114.9,\n",
       "        -116.1, -117.3, -118.2, -119.1, -120.4, -121.5, -122.3, -123.4,\n",
       "        -123.9, -124.5, -124.6, -129.4, -130. , -130. , -129.4, -128.8,\n",
       "        -128. , -127.8, -128. , -128.7, -129.1, -129.7, -131.2, -132.3,\n",
       "        -137.3, -138.8, -140.2, -141.9, -142.9, -143.9, -144.8, -145.6,\n",
       "        -146.4, -148. , -149. , -149.8, -151.2, -152.1, -152.9, -154. ,\n",
       "        -154.8, -155. , -155.5, -155.8, -156.1, -156.3, -157. , -157.5,\n",
       "        -158. , -158.1, -157.8, -157.5, -158.4, -157.6, -158.5, -160.4,\n",
       "        -160.6, -160.2, -163.5, -163.9, -164.8, -165.8, -166.5, -137.9,\n",
       "        -138.9, -139.4, -140.1, -141.5, -141.7, -141.9, -142.2, -142. ,\n",
       "        -141.6, -141.6, -142. , -142.6, -142.6, -143.4, -143.6, -144. ,\n",
       "        -144.7, -145.3, -121.6, -122. , -123.1, -123.5, -124.4, -125.7,\n",
       "        -126.9, -128. , -129.6, -131.6, -133. , -134.6, -136.4, -137.7,\n",
       "        -139.1, -141. , -142.7, -144.1, -145.2, -146.8, -147.8, -148.6,\n",
       "        -149.1, -149.8, -150.2, -150.8, -151.3, -152.2, -152.5, -153.3,\n",
       "        -154.3, -154.8, -154.9, -156. , -155.8, -155.9, -155.7, -155.1,\n",
       "        -154.3, -119. , -119.9, -121.4, -122.8, -123.9, -125.5, -127. ,\n",
       "        -128.1, -129.2, -130.4, -131.7, -133.1, -134.2, -135.5, -136.8,\n",
       "        -138. , -139.4, -140.7, -142.2, -143.3, -145. , -146.1, -147.1,\n",
       "        -148.2, -149.3, -150.3, -151.1, -152.3, -153.4, -154.4, -155.8,\n",
       "        -156.6, -158.3, -159. , -160.8, -164.9, -116.7, -117.6, -117.8,\n",
       "        -118. , -118.7, -119.2, -118.8, -118.4, -118.7, -118.6, -118.4,\n",
       "        -117.9, -117.2, -116.8, -116.3, -115.6, -114.8, -114.2, -113.2,\n",
       "        -114.3, -115. , -115.9, -116.5, -117.7, -118.2, -118.7, -119.2,\n",
       "        -120.4, -120.9, -121.3, -121.6, -122.1, -122.5, -123.4, -123.9,\n",
       "        -124.4, -124.8, -125.5, -125.9, -126.1, -126.5, -126.8, -126.8,\n",
       "        -127.1, -127.5, -127.3, -127. , -126.5, -125.7, -124.9, -123.8,\n",
       "        -122.9, -121.8, -120.8, -119.4, -117.9, -117.3, -115. , -113.2,\n",
       "        -111.6, -100.5, -101.2, -102. , -102.3, -107.4, -107.2, -106.6,\n",
       "        -105.7, -107.6, -108.8, -110.1, -110.3, -110.9, -111.2],\n",
       "       dtype=float32),\n",
       " array([-112.2, -113.1, -114.3, -114.5, -118. , -118.6, -118.9, -119.1,\n",
       "        -120. , -120.1, -120.6, -120.8, -123.2, -124.6, -125.8, -126.8,\n",
       "        -128.5, -129.6, -130.8, -131.4, -131.8, -133. , -133.1, -133.2,\n",
       "        -133.8, -134.4, -135.4, -135.5, -136.5, -136.8, -136.8, -138.8,\n",
       "        -138.9, -140.1, -140.5, -141.3, -142.3, -144. , -144.5, -146. ,\n",
       "        -146. , -147.8, -118.4, -119.4, -120.4, -121.6, -122.6, -124.1,\n",
       "        -124.8, -126.4, -127.3, -128.6, -130.6, -132.3, -133.5, -134.7,\n",
       "        -135. , -135.2, -135.5, -136.6, -137.3, -137.7, -138.5, -139.3,\n",
       "        -140.1, -107. , -108. , -109.2, -110. , -111. , -112.3, -113.5,\n",
       "        -114.6, -115.2, -116. , -116.7, -117.7, -118.5, -119.5, -120.5,\n",
       "        -120.3, -121.2, -122.6, -123.3, -122.8, -125. , -127. , -128.1,\n",
       "        -129.3, -120. , -120.4, -121.1, -122.1, -122.5, -123.1, -123.7,\n",
       "        -124.4, -125.1, -125.3, -125.2, -125. , -125.9, -125.3, -124.3,\n",
       "        -123.7, -126.3, -126. , -125.1, -126.2, -126.5, -127.9, -129. ,\n",
       "        -129.9, -129.7, -130.8, -131.2, -131.3, -115.6, -116.7, -117.4,\n",
       "        -117.6, -127.6, -127.6, -127.8, -128.5, -129.3, -110.2, -110.4,\n",
       "        -110.7, -111.1, -111.7, -112.7, -113.2, -113.3, -113.7, -113.9,\n",
       "        -114.3, -114.6, -115.5, -116. , -111.9, -112.8, -113. , -113.5,\n",
       "        -113.6, -114.7, -115. , -115.7, -116.3, -117. , -107.4, -108.6,\n",
       "        -108.8, -109.3, -109.3, -110.1, -110.1, -110.2, -110. , -110.6,\n",
       "        -110.5, -110.7, -110.5, -117.5, -118.4, -119.3, -120.9, -123.5,\n",
       "        -124.9, -125.8, -127. , -128. , -129. , -129.9, -131.3, -132.7,\n",
       "        -130.9, -132.3, -132.7, -133.5, -134.9, -135.6, -136.7, -137.2,\n",
       "        -138.4, -139.4, -140.6, -142.5, -143.5, -145. , -146.4, -148.3,\n",
       "        -150. , -150.8, -152.4, -153.8, -156.4, -157.8, -159.4, -161.1,\n",
       "        -162.2, -163.3, -164.3, -165.7, -167.6, -168.8, -169.8, -171. ,\n",
       "        -171.9, -172.7, -173.7, -175.1, -176.4, -177.7, -179.2, -180.6,\n",
       "        -182.1, -183.8, -185.3, -186.3, -188.8, -190.1, -113.7, -115.1,\n",
       "        -116.3, -116.4, -117.8, -119.5, -120.5, -121.8, -122.9, -123.4,\n",
       "        -124.8, -124.9, -124.3, -129.3, -129.8, -129.5, -128.4, -127.3,\n",
       "        -127. , -127.5, -128.6, -129.5, -130. , -131. , -131.2, -132.7,\n",
       "        -138. , -139.3, -140.8, -141.8, -143.2, -143.7, -144.6, -145.6,\n",
       "        -147.3, -147.7, -148.9, -149.4, -150.9, -152.3, -153.1, -154.4,\n",
       "        -154.6, -154.9, -155.6, -155.8, -156.4, -157.2, -157.4, -158. ,\n",
       "        -158.3, -158.6, -157.8, -157.8, -158.4, -158.6, -159.4, -159.1,\n",
       "        -159.4, -160.8, -162.6, -162.8, -164.9, -165.2, -165.8, -138.7,\n",
       "        -139.6, -140.6, -141.4, -142. , -142.2, -142.6, -142.2, -142.1,\n",
       "        -141.3, -141.5, -141.7, -142.1, -142.3, -142.7, -143.4, -144.1,\n",
       "        -145. , -145.4, -120.7, -121.4, -122.3, -123.4, -124.4, -125.8,\n",
       "        -127.7, -128.5, -130.5, -131.7, -134.3, -135.5, -136.9, -138.3,\n",
       "        -139.9, -141.5, -142.5, -143.9, -145.7, -146.7, -147.4, -148. ,\n",
       "        -149.1, -150.2, -150.5, -151.2, -151.9, -152.4, -153.2, -153.7,\n",
       "        -154.4, -155.3, -156. , -156. , -156. , -155.9, -156.1, -155. ,\n",
       "        -155.1, -119.1, -120.5, -121.6, -122.7, -124.1, -125.1, -125.8,\n",
       "        -127. , -128.3, -129.9, -131.2, -132.5, -134.2, -135.7, -136.6,\n",
       "        -138. , -139.3, -141.2, -142.6, -144.4, -145.3, -146.3, -147.4,\n",
       "        -148.4, -149.3, -150.3, -151.5, -152.4, -153.7, -154.5, -155.6,\n",
       "        -157.3, -157.8, -159.7, -161.5, -165.8, -116.5, -117.1, -117.8,\n",
       "        -118.2, -118.2, -118. , -117.1, -117.9, -118.8, -118.6, -118.3,\n",
       "        -117.7, -117. , -116.6, -115.5, -115.1, -115. , -113.8, -113.6,\n",
       "        -114.2, -114.8, -116. , -116.7, -117.1, -117.1, -117.8, -119.1,\n",
       "        -120.3, -121.1, -121.3, -121.9, -122.5, -123.2, -123.8, -123.9,\n",
       "        -124.6, -125. , -125.3, -125.7, -126.3, -126.9, -127.5, -127.9,\n",
       "        -128. , -128. , -128. , -127.3, -126.7, -126.2, -125.1, -124.3,\n",
       "        -123.5, -122.2, -121.1, -119.8, -118.4, -116.8, -115.3, -113.5,\n",
       "        -111.8,  -99.9, -101.4, -102.1, -102.1, -107.3, -106.8, -106.1,\n",
       "        -104.4, -108.8, -109. , -110.3, -109.9, -110. , -111.3],\n",
       "       dtype=float32),\n",
       " array([-112.3, -113.2, -114. , -114.7, -118.5, -118.9, -119. , -119.5,\n",
       "        -120.2, -120.3, -120.7, -121. , -123.4, -124.7, -125.8, -126.8,\n",
       "        -128.8, -129.5, -130.7, -131.2, -132. , -133. , -133.3, -133.4,\n",
       "        -134.1, -134.2, -135.3, -135.4, -136.3, -136.6, -136.5, -137.7,\n",
       "        -138.3, -139.6, -140.1, -140.4, -141.2, -142.9, -143.5, -144.9,\n",
       "        -145.7, -146.9, -118.1, -119.2, -120.3, -121.5, -122.8, -123.8,\n",
       "        -124.6, -126.5, -127.5, -128.2, -129.8, -132.2, -133.2, -134.7,\n",
       "        -135. , -135.5, -135.7, -136.6, -137.3, -137.7, -138.3, -138.8,\n",
       "        -139.6, -106.6, -107.7, -108.7, -109.5, -110.5, -111.9, -113.3,\n",
       "        -114.3, -114.7, -115.5, -116.5, -117.4, -118.2, -118.9, -120.1,\n",
       "        -119.8, -120.7, -121.8, -122.9, -122.5, -124.8, -126.4, -128.6,\n",
       "        -129.6, -120.2, -120.6, -121.2, -121.9, -122. , -123.1, -124.1,\n",
       "        -124.9, -126. , -125.9, -125.6, -125. , -125.7, -125.1, -125.8,\n",
       "        -123.3, -125.8, -125.9, -125.5, -125.3, -126.1, -127.1, -127.8,\n",
       "        -128.8, -128.5, -130. , -130.5, -130.6, -116.1, -116.5, -117.1,\n",
       "        -117.4, -127.8, -128.3, -128.2, -128.4, -128.9, -110.1, -110.2,\n",
       "        -110.4, -110.9, -111.7, -112.4, -112.8, -112.8, -113.6, -113.8,\n",
       "        -114.4, -114.6, -115.3, -115.8, -112.1, -112.5, -112.7, -113.2,\n",
       "        -113.6, -114.8, -115.6, -115.9, -116.6, -117.9, -107.2, -108.4,\n",
       "        -108.6, -109.2, -109.5, -110. , -110.1, -109.9, -109.5, -110.3,\n",
       "        -110.2, -110.1, -110.5, -117.2, -118.3, -119.2, -120.9, -123.3,\n",
       "        -124.9, -125.8, -126.8, -127.6, -128.7, -130. , -131.4, -132.5,\n",
       "        -130.5, -131.6, -132.5, -133.4, -135. , -135.3, -136.5, -137.1,\n",
       "        -138.3, -139.2, -140.6, -142.4, -143.7, -145.4, -146.9, -148.7,\n",
       "        -149.8, -150.7, -152.5, -153.8, -156.5, -157.9, -158.9, -160.8,\n",
       "        -161.7, -162.7, -164.2, -165.7, -167.2, -168.6, -169.5, -170.1,\n",
       "        -170.9, -172.2, -173.2, -174.4, -175.8, -177. , -179. , -180.6,\n",
       "        -181.5, -183.5, -185. , -186.5, -189.1, -190.5, -113.7, -114.9,\n",
       "        -116.2, -116.3, -117.8, -119.3, -120.3, -121.7, -122.9, -123.5,\n",
       "        -124.7, -124.5, -124.4, -129.2, -129.1, -129.1, -128.1, -127.1,\n",
       "        -126.6, -127.2, -128.2, -128. , -128.9, -130. , -130.3, -131.6,\n",
       "        -137.2, -138.8, -140.4, -141.1, -142.1, -142.9, -143.5, -144.2,\n",
       "        -145.8, -147.3, -147.8, -149.3, -150.3, -151.6, -152.5, -154. ,\n",
       "        -154.4, -154.5, -155.1, -155.6, -155.9, -156.5, -156.8, -157.3,\n",
       "        -157.6, -157. , -156. , -156.5, -156.7, -158.1, -159.2, -159.4,\n",
       "        -158.9, -160.7, -162.3, -162.3, -164.4, -165.1, -165.7, -138.2,\n",
       "        -139. , -139.9, -140.6, -141.5, -141.6, -141.6, -141.4, -141.6,\n",
       "        -140.6, -141. , -140.9, -141.3, -141.6, -142. , -143.3, -144. ,\n",
       "        -144.9, -145.4, -121.2, -122. , -122.6, -124.2, -125.6, -126.7,\n",
       "        -128.6, -129.5, -131.1, -132.7, -134.4, -136.1, -137.6, -139. ,\n",
       "        -140.2, -141.5, -142.6, -143.8, -145.7, -146.7, -147.2, -148. ,\n",
       "        -148.9, -149.5, -150.3, -150.8, -151.6, -152.2, -153. , -153. ,\n",
       "        -154.3, -154.3, -155.7, -154.9, -154.8, -154.9, -154.9, -155. ,\n",
       "        -154.7, -119.5, -120.5, -121.8, -122.9, -124.4, -125.2, -126.2,\n",
       "        -127.5, -128.4, -129.9, -131.3, -132.7, -134.2, -135.5, -136.5,\n",
       "        -137.9, -139.4, -141. , -142.7, -144.3, -145. , -146.5, -147.2,\n",
       "        -148.2, -148.9, -149.7, -151.1, -151.7, -152.6, -153.4, -154.2,\n",
       "        -155.5, -156.7, -158.9, -161.1, -166. , -115.9, -116.2, -117.5,\n",
       "        -117.9, -118.2, -117.9, -117.3, -117.8, -118.8, -118.5, -118.2,\n",
       "        -117.4, -116.7, -116.3, -115.4, -114.5, -113.6, -114.1, -113.4,\n",
       "        -114.2, -114.5, -115.9, -116.6, -116.7, -117.1, -118.5, -119.3,\n",
       "        -120.4, -121.1, -121.5, -121.9, -122.4, -123.2, -123.5, -123.8,\n",
       "        -124.5, -124.7, -125.3, -125.8, -126.3, -126.8, -127.2, -127.6,\n",
       "        -127.8, -128. , -128.1, -127. , -126.4, -125.8, -124.8, -123.8,\n",
       "        -123.2, -122. , -120.5, -119.8, -118.2, -117. , -115.5, -113.3,\n",
       "        -111.7, -100.5, -101.4, -102.2, -103. , -107.6, -106.9, -106.1,\n",
       "        -103. , -108.6, -109.1, -110.1, -110.2, -110.1, -111.4],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAIN TOTAL\n",
    "max_depth = 8\n",
    "n_estimators = 150\n",
    "learning_rate = 0.03\n",
    "subsample = 0.8\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = X_train_total\n",
    "train_y = X_train_total\n",
    "test_x = X_test_total\n",
    "test_y = X_test_total\n",
    "tgt_train = tgt_displacement_train\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 348.97 235.65 72.49\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 129.81 104.62 17.13\n"
     ]
    }
   ],
   "source": [
    "a, b, c, d, e, f, g = compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(a)\n",
    "plt.plot(g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 333.78 233.49 68.86\n",
      "SHIP 3932.27 3783.35 99.65\n",
      "HWRF 3906.48 3761.84 99.48\n",
      "OFCL 3929.04 3783.23 99.48\n",
      "FSSE 3928.37 3782.14 99.31\n",
      "AEMN 3926.15 3781.86 99.31\n",
      "GFSO 3919.81 3776.73 99.13\n",
      "CLP5 3951.42 3855.61 98.44\n",
      "Consensus OFCL only 3923.13 3778.43 99.13\n",
      "Consensus OFCL + Hurricast 3576.86 3718.6 99.13\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 256.8 170.81 56.92\n",
      "SHIP 5140.6 4653.62 99.78\n",
      "HWRF 5160.57 4643.14 99.78\n",
      "OFCL 5141.39 4651.16 99.78\n",
      "FSSE 5174.15 4644.75 99.78\n",
      "AEMN 5163.28 4651.75 100.0\n",
      "GFSO 5171.37 4651.53 100.0\n",
      "CLP5 5162.31 4671.95 99.34\n",
      "Consensus OFCL only 5169.26 4650.76 100.0\n",
      "Consensus OFCL + Hurricast 6021.61 5681.53 99.56\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "train_x = ss.fit_transform(X_train_total)\n",
    "test_x = ss.transform(X_test_total)\n",
    "tgt_train = tgt_displacement_train\n",
    "    \n",
    "xgb_x = Lasso(alpha = 0.0001)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = Lasso(alpha = 0.0001)\n",
    "xgb_y.fit(train_x, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_x)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 333.78 233.49 68.86\n",
      "SHIP 3932.27 3783.35 99.65\n",
      "HWRF 3906.48 3761.84 99.48\n",
      "OFCL 3929.04 3783.23 99.48\n",
      "FSSE 3928.37 3782.14 99.31\n",
      "AEMN 3926.15 3781.86 99.31\n",
      "GFSO 3919.81 3776.73 99.13\n",
      "CLP5 3951.42 3855.61 98.44\n",
      "Consensus OFCL only 3923.13 3778.43 99.13\n",
      "Consensus OFCL + Hurricast 3576.86 3718.6 99.13\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 256.8 170.81 56.92\n",
      "SHIP 5140.6 4653.62 99.78\n",
      "HWRF 5160.57 4643.14 99.78\n",
      "OFCL 5141.39 4651.16 99.78\n",
      "FSSE 5174.15 4644.75 99.78\n",
      "AEMN 5163.28 4651.75 100.0\n",
      "GFSO 5171.37 4651.53 100.0\n",
      "CLP5 5162.31 4671.95 99.34\n",
      "Consensus OFCL only 5169.26 4650.76 100.0\n",
      "Consensus OFCL + Hurricast 6021.61 5681.53 99.56\n"
     ]
    }
   ],
   "source": [
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 343.94 234.09 71.8\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 129.4 104.51 17.13\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 233.55 151.97 51.87\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 120.83 530.72 5.71\n",
      "Consensus OFCL + Hurricast 128.11 636.81 6.37\n"
     ]
    }
   ],
   "source": [
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_=LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 424.02 284.84 76.12\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 138.2 101.69 19.38\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 260.71 148.92 61.98\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 96.07 62.17 5.49\n",
      "Consensus OFCL + Hurricast 99.08 61.01 6.37\n"
     ]
    }
   ],
   "source": [
    "#TRAIN TABULAR ONLY\n",
    "max_depth = 6\n",
    "n_estimators = 150\n",
    "learning_rate = 0.03\n",
    "subsample = 0.7\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = np.array(X_train)#[:,1:]\n",
    "train_y = train_x\n",
    "test_x = np.array(X_test)\n",
    "test_y = test_x\n",
    "tgt_train = tgt_displacement_train\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 351.33 238.42 73.01\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 130.02 105.08 17.82\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 238.62 154.8 50.11\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 96.07 62.17 5.49\n",
      "Consensus OFCL + Hurricast 98.39 62.63 6.15\n"
     ]
    }
   ],
   "source": [
    "#TRAIN EMBED ONLY\n",
    "max_depth = 7\n",
    "n_estimators = 150\n",
    "learning_rate = 0.05\n",
    "subsample = 0.7\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = X_train_embed\n",
    "train_y = train_x\n",
    "test_x = X_test_embed\n",
    "test_y = test_x\n",
    "tgt_train = tgt_displacement_train\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 307.21 206.32 65.57\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 129.09 101.07 16.26\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 177.28 108.44 33.19\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 96.07 62.17 5.49\n",
      "Consensus OFCL + Hurricast 96.27 60.84 5.93\n"
     ]
    }
   ],
   "source": [
    "#OFCL + TABULAR ONLY\n",
    "max_depth = 6\n",
    "n_estimators = 150\n",
    "learning_rate = 0.05\n",
    "subsample = 0.7\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = X_test_baseline[:m]\n",
    "train_y = train_x\n",
    "test_x = X_test_baseline\n",
    "test_y = test_x\n",
    "tgt_train = tgt_displacement_test[:m]\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 279.76 203.14 58.3\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 124.14 102.44 14.88\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 175.9 119.1 34.73\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 96.07 62.17 5.49\n",
      "Consensus OFCL + Hurricast 96.75 61.87 5.71\n"
     ]
    }
   ],
   "source": [
    "#OFCL + EMBED\n",
    "max_depth = 7\n",
    "n_estimators = 200\n",
    "learning_rate = 0.05\n",
    "subsample = 0.8\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = np.concatenate((X_test_baseline[:m], X_test_embed[:m]), axis = 1)\n",
    "train_y = train_x\n",
    "test_x = np.concatenate((X_test_baseline, X_test_embed), axis = 1)\n",
    "test_y = test_x\n",
    "tgt_train = tgt_displacement_test[:m]\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-447aed3f504d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_viz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/X_test_vision_comp_1980_34_20_120.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_viz_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_viz_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_viz_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_total_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_viz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test_total_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_viz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "x_viz_train = np.load('../data/X_train_vision_comp_1980_34_20_120.npy', allow_pickle=True).reshape(-1, 3*5*3*3)\n",
    "x_viz_test = np.load('../data/X_test_vision_comp_1980_34_20_120.npy', allow_pickle=True).reshape(-1, 3*5*3*3)[-n:]\n",
    "x_viz_train = np.concatenate((x_viz_train, x_viz_test[:m]), axis = 0)\n",
    "X_train_total_comp = np.concatenate((X_train, x_viz_train), axis = 1)\n",
    "X_test_total_comp = np.concatenate((X_test, x_viz_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 669\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 134.37 96.2 17.64\n",
      "SHIP 77.06 64.11 4.04\n",
      "HWRF 72.01 47.85 2.39\n",
      "OFCL 70.36 57.78 2.84\n",
      "FSSE 67.53 53.48 3.44\n",
      "AEMN 72.81 57.98 2.54\n",
      "GFSO 70.47 56.01 3.74\n",
      "CLP5 197.76 142.19 36.17\n",
      "Consensus OFCL only 62.67 50.49 2.09\n",
      "Consensus OFCL + Hurricast 63.73 47.34 2.24\n",
      "Number of timesteps: 522\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 83.35 47.74 1.53\n",
      "SHIP 57.78 33.53 0.38\n",
      "HWRF 70.1 43.23 2.11\n",
      "OFCL 54.11 31.63 0.19\n",
      "FSSE 55.85 53.93 0.96\n",
      "AEMN 62.05 36.83 0.57\n",
      "GFSO 67.11 45.03 1.34\n",
      "CLP5 125.37 70.95 15.13\n",
      "Consensus OFCL only 53.04 33.46 0.38\n",
      "Consensus OFCL + Hurricast 49.45 30.4 0.19\n"
     ]
    }
   ],
   "source": [
    "#TRAIN TOTAL COMP\n",
    "max_depth = 9\n",
    "n_estimators = 150\n",
    "learning_rate = 0.05\n",
    "subsample = 0.8\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = X_train_total_comp\n",
    "train_y = train_x\n",
    "test_x = X_test_total_comp\n",
    "test_y = test_x\n",
    "tgt_train = tgt_displacement_train\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "forecast='SHIP'\n",
    "forecast2 = 'HWRF'\n",
    "forecast3 = 'OFCL'\n",
    "forecast4 = 'FSSE'\n",
    "forecast5 = 'GFSO'\n",
    "forecast6 = 'AEMN'\n",
    "forecast7 = 'CLP5'\n",
    "mode = 'lat'\n",
    "basin = 'AN'\n",
    "test = X_test_total\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "\n",
    "if forecast2 != None:\n",
    "    if True: \n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] <= 2017].loc[\n",
    "            X_test_baseline[forecast7 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        if basin == 'EP':\n",
    "            baseline_ = baseline_.loc[X_test_baseline['YEAR_0'] < 2019]\n",
    "        index = baseline_.index\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "        LATS_BASE_3 = np.array(baseline_[forecast3 + '_24_lat_7'])\n",
    "        LONS_BASE_3 = np.array(baseline_[forecast3 + '_24_lon_7'])\n",
    "        LATS_BASE_4 = np.array(baseline_[forecast4 + '_24_lat_7'])\n",
    "        LONS_BASE_4 = np.array(baseline_[forecast4 + '_24_lon_7'])\n",
    "        LATS_BASE_5 = np.array(baseline_[forecast5 + '_24_lat_7'])\n",
    "        LONS_BASE_5 = np.array(baseline_[forecast5 + '_24_lon_7'])\n",
    "        LATS_BASE_6 = np.array(baseline_[forecast6 + '_24_lat_7'])\n",
    "        LONS_BASE_6 = np.array(baseline_[forecast6 + '_24_lon_7'])\n",
    "        LATS_BASE_7 = np.array(baseline_[forecast7 + '_24_lat_7'])\n",
    "        LONS_BASE_7 = np.array(baseline_[forecast7 + '_24_lon_7'])\n",
    "        \n",
    "    LATS_TEST_t = np.array(X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx)[index]\n",
    "    LONS_TEST_t = np.array(X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy)[index]\n",
    "    tgt_x = (np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx)[index]\n",
    "    tgt_y = (np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy)[index]\n",
    "    baseline_1_x = np.array(baseline_[forecast + '_24_'+mode+'_7'])\n",
    "    baseline_1_y = np.array(baseline_[forecast + '_24_lon_7'])\n",
    "    baseline_2_x = np.array(baseline_[forecast2 + '_24_'+mode+'_7'])\n",
    "    baseline_2_y = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    baseline_3_x = np.array(baseline_[forecast3 + '_24_'+mode+'_7'])\n",
    "    baseline_3_y = np.array(baseline_[forecast3 + '_24_lon_7'])\n",
    "    baseline_4_x = np.array(baseline_[forecast4 + '_24_'+mode+'_7'])\n",
    "    baseline_4_y = np.array(baseline_[forecast4 + '_24_lon_7'])\n",
    "    baseline_5_x = np.array(baseline_[forecast5 + '_24_'+mode+'_7'])\n",
    "    baseline_5_y = np.array(baseline_[forecast5 + '_24_lon_7'])\n",
    "    baseline_6_x = np.array(baseline_[forecast6 + '_24_'+mode+'_7'])\n",
    "    baseline_6_y = np.array(baseline_[forecast6 + '_24_lon_7'])\n",
    "    baseline_7_x = np.array(baseline_[forecast7 + '_24_'+mode+'_7'])\n",
    "    baseline_7_y = np.array(baseline_[forecast7 + '_24_lon_7'])\n",
    "    LATS_PRED_t = np.array(LATS_PRED_)[index]\n",
    "    LONS_PRED_t = np.array(LONS_PRED_)[index]\n",
    "    \n",
    "    for i in range(len(LATS_PRED_t)):\n",
    "        if baseline_1_y[i] > 150:\n",
    "            baseline_1_y[i] -= 360\n",
    "            baseline_6_y[i] -= 360\n",
    "            baseline_5_y[i] -= 360\n",
    "            baseline_3_y[i] -= 360\n",
    "        if baseline_2_y[i] > 150:\n",
    "            baseline_2_y[i] -= 360\n",
    "            \n",
    "        if LONS_TEST_t[i] > 150:\n",
    "            LONS_PRED_t[i] -= 360\n",
    "            \n",
    "            \n",
    "    train_consensus_x = np.stack((baseline_1_x, baseline_2_x, baseline_3_x, baseline_4_x, baseline_5_x, baseline_6_x), axis = 1)\n",
    "    train_consensus_y = np.stack((baseline_1_y, baseline_2_y, baseline_3_y, baseline_4_y, baseline_5_y, baseline_6_y), axis = 1)\n",
    "    train_consensus_hurr_x = np.stack((baseline_1_x, baseline_2_x, baseline_3_x, baseline_4_x, baseline_5_x, baseline_6_x, LATS_PRED_t), axis = 1)\n",
    "    train_consensus_hurr_y = np.stack((baseline_1_y, baseline_2_y, baseline_3_y, baseline_4_y, baseline_5_y, baseline_6_y, LONS_PRED_t), axis = 1)\n",
    "\n",
    "base = np.array(X_test['LAT_7'])[index]\n",
    "for a in base:\n",
    "    if a > 160:\n",
    "        a-=360\n",
    "base_x = np.stack((base, base, base, base, base, base), axis = 1)\n",
    "train_consensus_x = train_consensus_x - base_x\n",
    "base_x = np.stack((base, base, base, base, base, base, base), axis = 1)\n",
    "train_consensus_hurr_x = train_consensus_hurr_x - base_x\n",
    "\n",
    "base = np.array(X_test['LON_7'])[index]\n",
    "for a in base:\n",
    "    if a > 160:\n",
    "        a-=360\n",
    "base_y = np.stack((base, base, base, base, base, base), axis = 1)\n",
    "train_consensus_y = train_consensus_y - base_y\n",
    "base_y = np.stack((base, base, base, base, base, base, base), axis = 1)\n",
    "train_consensus_hurr_y = train_consensus_hurr_y - base_y\n",
    "\n",
    "if forecast2 != None:\n",
    "    if True:\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] >= 2017].loc[\n",
    "            X_test_baseline[forecast7 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "        if basin == 'EP':\n",
    "            baseline_ = baseline_.loc[X_test_baseline['YEAR_0'] < 2019]\n",
    "        index = baseline_.index\n",
    "        LATS_BASE_2 = np.array(baseline_[forecast2 + '_24_lat_7'])\n",
    "        LONS_BASE_2 = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "        LATS_BASE_3 = np.array(baseline_[forecast3 + '_24_lat_7'])\n",
    "        LONS_BASE_3 = np.array(baseline_[forecast3 + '_24_lon_7'])\n",
    "        LATS_BASE_4 = np.array(baseline_[forecast4 + '_24_lat_7'])\n",
    "        LONS_BASE_4 = np.array(baseline_[forecast4 + '_24_lon_7'])\n",
    "        LATS_BASE_5 = np.array(baseline_[forecast5 + '_24_lat_7'])\n",
    "        LONS_BASE_5 = np.array(baseline_[forecast5 + '_24_lon_7'])\n",
    "        LATS_BASE_6 = np.array(baseline_[forecast6 + '_24_lat_7'])\n",
    "        LONS_BASE_6 = np.array(baseline_[forecast6 + '_24_lon_7'])\n",
    "        LATS_BASE_7 = np.array(baseline_[forecast7 + '_24_lat_7'])\n",
    "        LONS_BASE_7 = np.array(baseline_[forecast7 + '_24_lon_7'])\n",
    "        \n",
    "    LATS_TEST_te = np.array(X_test['LAT_7'] + np.array(tgt_displacement_test[:, 0])*std_dx+mean_dx)[index]\n",
    "    LONS_TEST_te = np.array(X_test['LON_7'] + np.array(tgt_displacement_test[:, 1])*std_dy+mean_dy)[index]\n",
    "    or_te_x = np.array(X_test['LAT_7'])[index]\n",
    "    or_te_y = np.array(X_test['LON_7'])[index]\n",
    "    baseline_1_x = np.array(baseline_[forecast + '_24_'+mode+'_7'])\n",
    "    baseline_1_y = np.array(baseline_[forecast + '_24_lon_7'])\n",
    "    baseline_2_x = np.array(baseline_[forecast2 + '_24_'+mode+'_7'])\n",
    "    baseline_2_y = np.array(baseline_[forecast2 + '_24_lon_7'])\n",
    "    baseline_3_x = np.array(baseline_[forecast3 + '_24_'+mode+'_7'])\n",
    "    baseline_3_y = np.array(baseline_[forecast3 + '_24_lon_7'])\n",
    "    baseline_4_x = np.array(baseline_[forecast4 + '_24_'+mode+'_7'])\n",
    "    baseline_4_y = np.array(baseline_[forecast4 + '_24_lon_7'])\n",
    "    baseline_5_x = np.array(baseline_[forecast5 + '_24_'+mode+'_7'])\n",
    "    baseline_5_y = np.array(baseline_[forecast5 + '_24_lon_7'])\n",
    "    baseline_6_x = np.array(baseline_[forecast6 + '_24_'+mode+'_7'])\n",
    "    baseline_6_y = np.array(baseline_[forecast6 + '_24_lon_7'])\n",
    "    baseline_7_x = np.array(baseline_[forecast7 + '_24_'+mode+'_7'])\n",
    "    baseline_7_y = np.array(baseline_[forecast7 + '_24_lon_7'])\n",
    "    LATS_PRED_te = np.array(LATS_PRED_)[index]\n",
    "    LONS_PRED_te = np.array(LONS_PRED_)[index]\n",
    "    \n",
    "    for i in range(len(LATS_PRED_te)):\n",
    "        if baseline_1_y[i] > 150:\n",
    "            baseline_1_y[i] -= 360\n",
    "            baseline_6_y[i] -= 360\n",
    "            baseline_5_y[i] -= 360\n",
    "            baseline_3_y[i] -= 360\n",
    "        if baseline_2_y[i] > 150:\n",
    "            baseline_2_y[i] -= 360\n",
    "            \n",
    "        if LONS_TEST_te[i] > 150:\n",
    "            LONS_PRED_te[i] -= 360\n",
    "            \n",
    "    test_consensus_x = np.stack((baseline_1_x, baseline_2_x, baseline_3_x, baseline_4_x, baseline_5_x, baseline_6_x), axis = 1)\n",
    "    test_consensus_y = np.stack((baseline_1_y, baseline_2_y, baseline_3_y, baseline_4_y, baseline_5_y, baseline_6_y), axis = 1)\n",
    "    test_consensus_hurr_x = np.stack((baseline_1_x, baseline_2_x, baseline_3_x, baseline_4_x, baseline_5_x, baseline_6_x, LATS_PRED_te), axis = 1)\n",
    "    test_consensus_hurr_y = np.stack((baseline_1_y, baseline_2_y, baseline_3_y, baseline_4_y, baseline_5_y, baseline_6_y, LONS_PRED_te), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.array(X_test['LAT_7'])[index]\n",
    "for a in base:\n",
    "    if a > 160:\n",
    "        a-=360\n",
    "base_x = np.stack((base, base, base, base, base, base), axis = 1)\n",
    "test_consensus_x = test_consensus_x - base_x\n",
    "base_x = np.stack((base, base, base, base, base, base, base), axis = 1)\n",
    "test_consensus_hurr_x = test_consensus_hurr_x - base_x\n",
    "\n",
    "base = np.array(X_test['LON_7'])[index]\n",
    "for i in range(len(base)):\n",
    "    if base[i] > 160:\n",
    "        base[i]-=360\n",
    "base_y = np.stack((base, base, base, base, base, base), axis = 1)\n",
    "test_consensus_y = test_consensus_y - base_y\n",
    "base_y = np.stack((base, base, base, base, base, base, base), axis = 1)\n",
    "test_consensus_hurr_y = test_consensus_hurr_y - base_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "train_consensus_x = ss.fit_transform(train_consensus_x)\n",
    "test_consensus_x = ss.transform(test_consensus_x)\n",
    "ss2 = StandardScaler()\n",
    "train_consensus_y = ss.fit_transform(train_consensus_y)\n",
    "test_consensus_y = ss.transform(test_consensus_y)\n",
    "\n",
    "ss3 = StandardScaler()\n",
    "train_consensus_hurr_x = ss3.fit_transform(train_consensus_hurr_x)\n",
    "test_consensus_hurr_x = ss3.transform(test_consensus_hurr_x)\n",
    "\n",
    "ss4 = StandardScaler()\n",
    "train_consensus_hurr_y = ss4.fit_transform(train_consensus_hurr_y)\n",
    "test_consensus_hurr_y = ss4.transform(test_consensus_hurr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Lasso consensus w/o hurricast 116.73 104.54 12.11\n"
     ]
    }
   ],
   "source": [
    "#AN\n",
    "m_x = Lasso(alpha = 0.001)\n",
    "m_x.fit(train_consensus_x, tgt_x)\n",
    "preds_x = np.array(m_x.predict(test_consensus_x))+np.array(X_test['LAT_7'])[index]\n",
    "\n",
    "m_y = Lasso(alpha = 0.01)\n",
    "m_y.fit(train_consensus_y, tgt_y)\n",
    "preds_y = np.array(m_y.predict(test_consensus_y)) + base\n",
    "d_km_pred = np.zeros(len(preds_y))\n",
    "for i in range(len(LATS_PRED_te)):\n",
    "    d_km_pred[i] = get_distance_km(preds_y[i], preds_x[i], LONS_TEST_te[i], LATS_TEST_te[i])\n",
    "    \n",
    "print(\"Number of timesteps:\", len(LATS_PRED_te))\n",
    "print(basin, 'Model | MAE | std | %age busts (>200km)')\n",
    "print(\"Lasso consensus w/o hurricast\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2), np.around(sum(d_km_pred > 200)*100/len(LATS_PRED_te), decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.21300206,  0.76481366,  1.147674  ,  0.3719764 , -0.5293032 ,\n",
       "        0.6864948 ], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_x.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Lasso consensus w/ hurricast 117.16 102.77 11.59\n"
     ]
    }
   ],
   "source": [
    "#AN\n",
    "m_x = Lasso(alpha = 0.001)\n",
    "m_x.fit(train_consensus_hurr_x, tgt_x)\n",
    "preds_x = np.array(m_x.predict(test_consensus_hurr_x))+np.array(X_test['LAT_7'])[index]\n",
    "\n",
    "m_y = Lasso(alpha = 0.001)\n",
    "m_y.fit(train_consensus_hurr_y, tgt_y)\n",
    "preds_y = np.array(m_y.predict(test_consensus_hurr_y)) + base\n",
    "d_km_pred = np.zeros(len(preds_y))\n",
    "for i in range(len(LATS_PRED_te)):\n",
    "    d_km_pred[i] = get_distance_km(preds_y[i], preds_x[i], LONS_TEST_te[i], LATS_TEST_te[i])\n",
    "    \n",
    "print(\"Number of timesteps:\", len(LATS_PRED_te))\n",
    "print(basin, 'Model | MAE | std | %age busts (>200km)')\n",
    "print(\"Lasso consensus w/ hurricast\", np.around(d_km_pred.mean(), decimals = 2), np.around(d_km_pred.std(), decimals = 2), np.around(sum(d_km_pred > 200)*100/len(LATS_PRED_te), decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31968802,  1.0979068 ,  1.4015273 , -0.08218948, -0.43961585,\n",
       "        0.88553125,  0.10718425], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_y.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_t = X_train.loc[X_train['cat_basin_AN_0'] + X_train['cat_basin_EP_0'] == 1].index\n",
    "index_te = X_test[:m].loc[X_test['cat_basin_AN_0'] + X_test['cat_basin_EP_0'] == 1].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te-765]), axis = 0)\n",
    "tgt_train_ = np.concatenate((tgt_displacement_train[index_t], tgt_displacement_test[index_te]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  768,   769,   770,   771,   772,   773,   774,   775,   776,\n",
       "              777,\n",
       "            ...\n",
       "            15138, 15139, 15140, 15141, 15142, 15143, 15144, 15145, 15146,\n",
       "            15147],\n",
       "           dtype='int64', length=5591)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 578\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 412.85 294.16 78.55\n",
      "SHIP 139.04 127.53 18.86\n",
      "HWRF 136.45 104.79 20.42\n",
      "OFCL 125.63 112.28 15.22\n",
      "FSSE 117.53 103.8 13.15\n",
      "AEMN 137.81 119.96 17.99\n",
      "GFSO 137.97 125.4 19.2\n",
      "CLP5 486.37 334.87 82.35\n",
      "Consensus OFCL only 118.04 104.31 13.49\n",
      "Consensus OFCL + Hurricast 136.71 109.01 18.86\n",
      "Number of timesteps: 455\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 278.66 192.35 61.54\n",
      "SHIP 101.27 59.79 7.47\n",
      "HWRF 116.69 74.57 13.19\n",
      "OFCL 93.28 54.12 5.49\n",
      "FSSE 113.11 167.23 7.69\n",
      "AEMN 103.23 64.11 8.35\n",
      "GFSO 117.76 74.91 12.53\n",
      "CLP5 303.59 170.98 71.21\n",
      "Consensus OFCL only 96.07 62.17 5.49\n",
      "Consensus OFCL + Hurricast 104.36 65.04 7.47\n"
     ]
    }
   ],
   "source": [
    "#TRAIN TOTAL\n",
    "max_depth = 7\n",
    "n_estimators = 150\n",
    "learning_rate = 0.05\n",
    "subsample = 0.8\n",
    "min_child_weight=5\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = train\n",
    "train_y = train_x\n",
    "test_x = X_test_total\n",
    "test_y = X_test_total\n",
    "tgt_train = tgt_train_\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_t = X_test_baseline[:m].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1].index\n",
    "train = np.concatenate((np.array(X_test_baseline[:m])[index_t], X_test_embed[index_t]), axis = 1)\n",
    "tgt_train_ = tgt_displacement_test[index_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps: 669\n",
      "AN Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 100.64 82.46 8.52\n",
      "SHIP 77.06 64.11 4.04\n",
      "HWRF 72.01 47.85 2.39\n",
      "OFCL 70.36 57.78 2.84\n",
      "FSSE 67.53 53.48 3.44\n",
      "AEMN 72.81 57.98 2.54\n",
      "GFSO 70.47 56.01 3.74\n",
      "CLP5 197.76 142.19 36.17\n",
      "Consensus OFCL only 62.67 50.49 2.09\n",
      "Consensus OFCL + Hurricast 61.57 48.15 1.49\n",
      "Number of timesteps: 522\n",
      "EP Model | MAE | std | %age busts (>200km)\n",
      "Hurricast 58.91 32.78 0.38\n",
      "SHIP 57.78 33.53 0.38\n",
      "HWRF 70.1 43.23 2.11\n",
      "OFCL 54.11 31.63 0.19\n",
      "FSSE 55.85 53.93 0.96\n",
      "AEMN 62.05 36.83 0.57\n",
      "GFSO 67.11 45.03 1.34\n",
      "CLP5 125.37 70.95 15.13\n",
      "Consensus OFCL only 53.04 33.46 0.38\n",
      "Consensus OFCL + Hurricast 50.4 31.16 0.38\n"
     ]
    }
   ],
   "source": [
    "#TRAIN TOTAL\n",
    "max_depth = 8\n",
    "n_estimators = 150\n",
    "learning_rate = 0.07\n",
    "subsample = 0.7\n",
    "min_child_weight=1\n",
    "#col_sample_by_tree = 0.7\n",
    "train_x = train\n",
    "train_y = train_x\n",
    "test_x = np.concatenate((X_test_baseline, X_test_embed), axis = 1)\n",
    "test_y = test_x\n",
    "tgt_train = tgt_train_\n",
    "    \n",
    "xgb_x = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_x.fit(train_x, tgt_train[:, 0])\n",
    "xgb_y = XGBRegressor(max_depth=max_depth, n_estimators=n_estimators, learning_rate=learning_rate, subsample=subsample, min_child_weight=min_child_weight)\n",
    "xgb_y.fit(train_y, tgt_train[:, 1])\n",
    "DLATS_PRED = np.array(xgb_x.predict(test_x)) * std_dx + mean_dx\n",
    "DLONS_PRED = np.array(xgb_y.predict(test_y)) * std_dy + mean_dy\n",
    "LATS_PRED_ = X_test['LAT_7'] + DLATS_PRED\n",
    "LONS_PRED_ = X_test['LON_7'] + DLONS_PRED\n",
    "a, b = compare_perf_track_7cast(year = 2017, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)\n",
    "c, d = compare_perf_track_7cast(year = 2017, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3='OFCL', forecast4 = 'FSSE', forecast5='AEMN', forecast6 = 'GFSO', forecast7 = 'CLP5', LATS_PRED_= LATS_PRED_, LONS_PRED_=LONS_PRED_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[217:220] > 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(b)\n",
    "b.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e75b29160>]"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a, b['STORM_DISPLACEMENT_Y_7'], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.570558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.404688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144.106247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.543451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.600302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>356.724132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>81.134094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>306.872005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>303.261238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>391.611776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target\n",
       "0     29.570558\n",
       "1     94.404688\n",
       "2    144.106247\n",
       "3    110.543451\n",
       "4     30.600302\n",
       "..          ...\n",
       "664  356.724132\n",
       "665   81.134094\n",
       "666  306.872005\n",
       "667  303.261238\n",
       "668  391.611776\n",
       "\n",
       "[669 rows x 1 columns]"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = pd.DataFrame(a)\n",
    "e.columns = ['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((b, e), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STORM_DISPLACEMENT_Y_5       0.566200\n",
       "LAT_6                       32.985100\n",
       "LON_6                      -30.674999\n",
       "WMO_WIND_6                  90.000000\n",
       "WMO_PRES_6                 966.500000\n",
       "DIST2LAND_6               1425.000000\n",
       "STORM_SPEED_6               17.000000\n",
       "COS_STORM_DIR_6              0.469472\n",
       "SIN_STORM_DIR_6              0.882948\n",
       "COS_LAT_6                    0.838812\n",
       "SIN_LAT_6                    0.544421\n",
       "COS_LON_6                    0.860075\n",
       "SIN_LON_6                   -0.510168\n",
       "STORM_DISPLACEMENT_X_6       0.385100\n",
       "STORM_DISPLACEMENT_Y_6       0.825000\n",
       "LAT_7                       33.400002\n",
       "LON_7                      -29.700001\n",
       "WMO_WIND_7                  95.000000\n",
       "WMO_PRES_7                 963.000000\n",
       "DIST2LAND_7               1353.000000\n",
       "STORM_SPEED_7               18.000000\n",
       "COS_STORM_DIR_7              0.438371\n",
       "SIN_STORM_DIR_7              0.898794\n",
       "COS_LAT_7                    0.834848\n",
       "SIN_LAT_7                    0.550481\n",
       "COS_LON_7                    0.868632\n",
       "SIN_LON_7                   -0.495459\n",
       "STORM_DISPLACEMENT_X_7       0.414900\n",
       "STORM_DISPLACEMENT_Y_7       0.975000\n",
       "Target                     417.674352\n",
       "Name: 217, dtype: float64"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[217][-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STORM_DISPLACEMENT_Y_5    0.528886\n",
       "LAT_6                     0.361303\n",
       "LON_6                     0.257946\n",
       "WMO_WIND_6               -0.213017\n",
       "WMO_PRES_6                0.156788\n",
       "DIST2LAND_6               0.181879\n",
       "STORM_SPEED_6             0.430201\n",
       "COS_STORM_DIR_6           0.030040\n",
       "SIN_STORM_DIR_6           0.443096\n",
       "COS_LAT_6                -0.404716\n",
       "SIN_LAT_6                 0.349151\n",
       "COS_LON_6                 0.249357\n",
       "SIN_LON_6                 0.263808\n",
       "STORM_DISPLACEMENT_X_6    0.304211\n",
       "STORM_DISPLACEMENT_Y_6    0.543905\n",
       "LAT_7                     0.369798\n",
       "LON_7                     0.274303\n",
       "WMO_WIND_7               -0.215459\n",
       "WMO_PRES_7                0.160926\n",
       "DIST2LAND_7               0.183372\n",
       "STORM_SPEED_7             0.450341\n",
       "COS_STORM_DIR_7           0.029825\n",
       "SIN_STORM_DIR_7           0.435316\n",
       "COS_LAT_7                -0.414633\n",
       "SIN_LAT_7                 0.356799\n",
       "COS_LON_7                 0.263034\n",
       "SIN_LON_7                 0.285186\n",
       "STORM_DISPLACEMENT_X_7    0.318487\n",
       "STORM_DISPLACEMENT_Y_7    0.552833\n",
       "Target                    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['Target'])[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('all the input array dimensions except for the concatenation axis must match exactly', 'occurred at index LAT_0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-575-93279bb20291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6926\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6927\u001b[0m         )\n\u001b[0;32m-> 6928\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-575-93279bb20291>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, other, method, min_periods)\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kendall\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2454\u001b[0m             return nanops.nancorr(\n\u001b[0;32m-> 2455\u001b[0;31m                 \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2456\u001b[0m             )\n\u001b[1;32m   2457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnancorr\u001b[0;34m(a, b, method, min_periods)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corr_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_pearson\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pearson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_kendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof)\u001b[0m\n\u001b[1;32m   2520\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[1;32m   2521\u001b[0m                       DeprecationWarning, stacklevel=2)\n\u001b[0;32m-> 2522\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrowvar\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2386\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mddof\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('all the input array dimensions except for the concatenation axis must match exactly', 'occurred at index LAT_0')"
     ]
    }
   ],
   "source": [
    "b.apply(lambda x: x.corr(pd.DataFrame(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table intensity AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "n = X_test_baseline.shape[0]\n",
    "X_test_total = X_test_total[-n:]\n",
    "tgt_intensity_test = tgt_intensity_test[-n:]\n",
    "X_test = X_test[-n:]\n",
    "X_test_embed = X_test_embed[-n:]\n",
    "tgt_displacement_test = tgt_displacement_test[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict6 = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[], 'MAES_GFSO':[], 'std_GFSO':[], 'MAES_DSHP':[], 'std_DSHP':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "tgt_train5 = tgt_train*std_+mean_\n",
    "mean_intensity2 = tgt_train5.mean()\n",
    "std_intensity2 = tgt_train5.std()\n",
    "tgt_train5 = (tgt_train5 - mean_intensity2)/std_intensity2\n",
    "tgt_intensity_test = (tgt_intensity_test*std_+mean_ - mean_intensity2)/std_intensity2\n",
    "std_ = float(std_intensity2)\n",
    "mean_ = float(mean_intensity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.93 14.14 14.65\n",
      "Hurr until 2012:  10.93 14.14 14.65\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Consensus ofcl 8.27\n",
      "Consensus Hurr 10.09\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.36 15.31 18.01\n",
      "Hurr until 2012:  11.36 15.31 18.01\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n",
      "Consensus ofcl 9.24\n",
      "Consensus Hurr 10.98\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS + ONLY AN EP in training + only more than. 40kn winds\n",
    "index_t = X_train.loc[X_train['cat_basin_AN_0'] + X_train['cat_basin_EP_0'] == 1].loc[X_train['WMO_WIND_7'] > 34].index\n",
    "index_te = X_test[:17094].loc[X_test['cat_basin_AN_0'] + X_test['cat_basin_EP_0'] == 1].loc[X_test['WMO_WIND_7'] > 34].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train[index_t], tgt_intensity_test[index_te]), axis = 0)\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=6, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=1)\n",
    "xgb_total.fit(train, tgt_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.8 13.98 14.5\n",
      "Hurr until 2012:  10.8 13.98 14.5\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Consensus ofcl 8.27\n",
      "Consensus Hurr 10.3\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.13 15.08 16.09\n",
      "Hurr until 2012:  11.13 15.08 16.09\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n",
      "Consensus ofcl 9.24\n",
      "Consensus Hurr 11.18\n"
     ]
    }
   ],
   "source": [
    "index_t = X_train.loc[X_train['cat_basin_AN_0'] + X_train['cat_basin_EP_0'] == 1].loc[X_train['WMO_WIND_7'] > 34].index\n",
    "index_te = X_test[:17094].loc[X_test['cat_basin_AN_0'] + X_test['cat_basin_EP_0'] == 1].loc[X_test['WMO_WIND_7'] > 34].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te]), axis = 0)\n",
    "tgt_train = np.array(((np.concatenate((tgt_intensity_train[index_t], tgt_intensity_test[index_te]), axis = 0))*float(std_intensity)+float(mean_intensity)-mean_)/std_)\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=1)\n",
    "xgb_total.fit(train, tgt_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.68 13.84 12.71\n",
      "Hurr until 2012:  10.68 13.84 12.71\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Consensus ofcl 8.27\n",
      "Consensus Hurr 10.08\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.24 15.15 17.05\n",
      "Hurr until 2012:  11.24 15.15 17.05\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n",
      "Consensus ofcl 9.24\n",
      "Consensus Hurr 11.0\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS\n",
    "index_t = X_train.loc[X_train['WMO_WIND_7'] > 40].index\n",
    "index_te = X_test[:17094].loc[X_test['WMO_WIND_7'] > 40].index\n",
    "train = np.concatenate((X_train_total[index_t], X_test_total[index_te]), axis = 0)\n",
    "tgt_train = np.concatenate((tgt_intensity_train[index_t], tgt_intensity_test[index_te]), axis = 0)\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=5)\n",
    "xgb_total.fit(train, tgt_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.54 13.79 13.0\n",
      "Hurr until 2012:  10.54 13.79 13.0\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Consensus ofcl 8.39\n",
      "Consensus Hurr 8.27\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.27 15.24 16.28\n",
      "Hurr until 2012:  11.27 15.24 16.28\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n",
      "Consensus ofcl 9.79\n",
      "Consensus Hurr 9.64\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS\n",
    "train = np.concatenate((X_train_total, X_test_total[:17094]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=250, learning_rate=0.07, subsample=0.8, min_child_weight=1, colsample_bytree = 0.7)\n",
    "xgb_total.fit(train, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.54 13.79 13.0\n",
      "Hurr until 2012:  10.54 13.79 13.0\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Consensus ofcl 8.44 11.35 8.52\n",
      "Consensus Hurr 8.33 11.21 8.37\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.27 15.24 16.28\n",
      "Hurr until 2012:  11.27 15.24 16.28\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n",
      "Consensus ofcl 9.39 12.52 10.73\n",
      "Consensus Hurr 9.35 12.54 10.73\n"
     ]
    }
   ],
   "source": [
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "forecast='SHIP'\n",
    "forecast2 = 'HWRF'\n",
    "forecast3 = 'OFCL'\n",
    "forecast4 = 'FSSE'\n",
    "forecast5 = 'GFSO'\n",
    "forecast6 = 'AEMN'\n",
    "mode = 'vmax'\n",
    "basin = 'AN'\n",
    "test = X_test_total\n",
    "if True:\n",
    "    baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] < year].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "    if basin == 'EP':\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] < year].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]\n",
    "    index = baseline_.index\n",
    "    baseline_1 = baseline_[forecast + '_24_'+ mode + '_7']\n",
    "    baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    baseline_3 = baseline_[forecast3 + '_24_' + mode + '_7']\n",
    "    baseline_4 = baseline_[forecast4 + '_24_' + mode + '_7']\n",
    "    baseline_5 = baseline_[forecast5 + '_24_' + mode + '_7']\n",
    "    baseline_6 = baseline_[forecast6 + '_24_' + mode + '_7']\n",
    "    X_test_withBASELINE_total = np.array(test)[index]\n",
    "    \n",
    "    tgt_ = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "    preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "    train_consensus = np.stack((baseline_1, baseline_2, baseline_3, baseline_4, baseline_5, baseline_6), axis = 1)\n",
    "    train_consensus_hurr = np.stack((baseline_1, baseline_2, baseline_3, baseline_4, baseline_5, baseline_6, preds), axis = 1)\n",
    "   \n",
    "if True:\n",
    "    baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]  # .loc[#X_test_baseline['SHIP_24_'+mode+'_7'] > 0].index\n",
    "    if basin == 'EP':\n",
    "        baseline_ = X_test_baseline.loc[X_test_baseline['YEAR_0'] < 2019].loc[X_test_baseline['YEAR_0'] >= year].loc[\n",
    "            X_test_baseline[forecast6 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast5 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast4 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast3 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast2 + '_24_' + mode + '_7'] > -320].loc[\n",
    "            X_test_baseline[forecast + '_24_' + mode + '_7'] > -320].loc[X_test_baseline['cat_basin_' + basin + '_0'] == 1]\n",
    "    index = baseline_.index\n",
    "    baseline_1 = baseline_[forecast + '_24_'+ mode + '_7']\n",
    "    baseline_2 = baseline_[forecast2 + '_24_' + mode + '_7']\n",
    "    baseline_3 = baseline_[forecast3 + '_24_' + mode + '_7']\n",
    "    baseline_4 = baseline_[forecast4 + '_24_' + mode + '_7']\n",
    "    baseline_5 = baseline_[forecast5 + '_24_' + mode + '_7']\n",
    "    baseline_6 = baseline_[forecast6 + '_24_' + mode + '_7']\n",
    "    X_test_withBASELINE_total = np.array(test)[index]\n",
    "    \n",
    "    tgt_test = np.array(tgt_intensity_test[index] * std_ + mean_)\n",
    "    preds = xgb_total.predict(X_test_withBASELINE_total) * std_ + mean_\n",
    "    test_consensus = np.stack((baseline_1, baseline_2, baseline_3, baseline_4, baseline_5, baseline_6), axis = 1)\n",
    "    test_consensus_hurr = np.stack((baseline_1, baseline_2, baseline_3, baseline_4, baseline_5, baseline_6, preds), axis = 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE intensity:  8.195159\n",
      "[ 0.          0.13361378  0.64414746  0.2184808   0.06403179 -0.        ]\n",
      "MAE intensity:  8.025881\n",
      "[-0.          0.11876066  0.5839296   0.28978214  0.11706416 -0.23846142\n",
      "  0.25588316]\n"
     ]
    }
   ],
   "source": [
    "#AN\n",
    "m = Lasso(alpha = 10)\n",
    "m.fit(train_consensus, tgt_)\n",
    "preds = np.array(m.predict(test_consensus))\n",
    "\n",
    "print(\"consensus without Hurricast\",\n",
    "                np.around(mean_absolute_error(np.array(tgt_test), preds), decimals=2),\n",
    "                np.around(np.std(tgt_test - preds), decimals=2),\n",
    "                np.around(sum(abs(tgt_test - preds) > 20)/len(preds) * 100, decimals = 2))print(m.coef_)\n",
    "\n",
    "m = Lasso(alpha = 3)\n",
    "m.fit(train_consensus_hurr, tgt_)\n",
    "preds = np.array(m.predict(test_consensus_hurr))\n",
    "\n",
    "\n",
    "print(\"consensus with Hurricast\",\n",
    "                np.around(mean_absolute_error(np.array(tgt_test), preds), decimals=2),\n",
    "                np.around(np.std(tgt_test - preds), decimals=2),\n",
    "                np.around(sum(abs(tgt_test - preds) > 20)/len(preds) * 100, decimals = 2))print(m.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consensus without Hurricast 8.2 11.0 8.67\n",
      "consensus with Hurricast 8.02 10.74 8.37\n"
     ]
    }
   ],
   "source": [
    "#AN\n",
    "m = Lasso(alpha = 10)\n",
    "m.fit(train_consensus, tgt_)\n",
    "preds = np.array(m.predict(test_consensus))\n",
    "\n",
    "print(\"consensus without Hurricast\",\n",
    "                np.around(mean_absolute_error(np.array(tgt_test), preds), decimals=2),\n",
    "                np.around(np.std(tgt_test - preds), decimals=2),\n",
    "                np.around(sum(abs(tgt_test - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "\n",
    "m = Lasso(alpha = 3)\n",
    "m.fit(train_consensus_hurr, tgt_)\n",
    "preds = np.array(m.predict(test_consensus_hurr))\n",
    "\n",
    "\n",
    "print(\"consensus with Hurricast\",\n",
    "                np.around(mean_absolute_error(np.array(tgt_test), preds), decimals=2),\n",
    "                np.around(np.std(tgt_test - preds), decimals=2),\n",
    "                np.around(sum(abs(tgt_test - preds) > 20)/len(preds) * 100, decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consensus without Hurricast 8.6 11.93 10.73\n",
      "consensus with Hurricast 8.56 11.76 10.34\n"
     ]
    }
   ],
   "source": [
    "#EP\n",
    "m = Lasso(alpha = 0.9)\n",
    "m.fit(train_consensus, tgt_)\n",
    "#print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_test), np.array(m.predict(test_consensus))))\n",
    "#print(m.coef_)\n",
    "preds = np.array(m.predict(test_consensus))\n",
    "print(\"consensus without Hurricast\",\n",
    "                np.around(mean_absolute_error(np.array(tgt_test), preds), decimals=2),\n",
    "                np.around(np.std(tgt_test - preds), decimals=2),\n",
    "                np.around(sum(abs(tgt_test - preds) > 20)/len(preds) * 100, decimals = 2))\n",
    "\n",
    "m = Lasso(alpha = 2.)\n",
    "m.fit(train_consensus_hurr, tgt_)\n",
    "#print(\"MAE intensity: \", mean_absolute_error(np.array(tgt_test), np.array(m.predict(test_consensus_hurr))))\n",
    "#print(m.coef_)\n",
    "preds = np.array(m.predict(test_consensus_hurr))\n",
    "print(\"consensus with Hurricast\",\n",
    "                np.around(mean_absolute_error(np.array(tgt_test), preds), decimals=2),\n",
    "                np.around(np.std(tgt_test - preds), decimals=2),\n",
    "                np.around(sum(abs(tgt_test - preds) > 20)/len(preds) * 100, decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-808056b18fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_train5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2020a/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_total = RandomForestRegressor(max_depth=8, n_estimators=250, criterion = 'mae')\n",
    "xgb_total.fit(train, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  42\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.55 14.03 16.67\n",
      "Hurr until 2012:  11.55 14.03 16.67\n",
      "SHIP 10.74 12.94 11.9\n",
      "HWRF 7.74 10.23 14.29\n",
      "OFCL 8.45 10.79 2.38\n",
      "FSSE 6.64 8.01 0.0\n",
      "GFDL 17.38 18.83 33.33\n",
      "DSHP 10.74 12.94 11.9\n"
     ]
    }
   ],
   "source": [
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFDL', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.8 13.91 14.5\n",
      "Hurr until 2012:  10.8 13.91 14.5\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Consensus ofcl 8.27\n",
      "Consensus Hurr 10.03\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.59 15.67 19.16\n",
      "Hurr until 2012:  11.59 15.67 19.16\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n",
      "Consensus ofcl 9.24\n",
      "Consensus Hurr 11.0\n"
     ]
    }
   ],
   "source": [
    "#TRAIN UNTIL 2012\n",
    "#AN\n",
    "#xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=5, colsample_bytree = 0.7)\n",
    "#EP\n",
    "#xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.05, subsample=0.7, min_child_weight=5, colsample_bytree = 0.7)\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=5, colsample_bytree = 0.7)\n",
    "xgb_total.fit(X_train_total, tgt_intensity_train)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_total, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.68 13.82 14.05\n",
      "Hurr until 2012:  10.68 13.82 14.05\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.45 15.63 18.01\n",
      "Hurr until 2012:  11.45 15.63 18.01\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#TABULAR ONLY\n",
    "train2 = np.concatenate((X_train, X_test[:17094]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=150, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_total.fit(train2, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.27 14.57 15.4\n",
      "Hurr until 2012:  11.27 14.57 15.4\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.28 15.42 18.01\n",
      "Hurr until 2012:  11.28 15.42 18.01\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#EMBED ONLY\n",
    "train2 = np.concatenate((X_train_embed, X_test_embed[:17094]), axis = 0)\n",
    "#tgt_train = np.concatenate((tgt_intensity_train, tgt_intensity_test[:17094]), axis = 0)\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=150, learning_rate=0.07, subsample=0.7, min_child_weight=5)\n",
    "xgb_total.fit(train2, tgt_train5)\n",
    "compare_perf_intensity_per_year_6cast(X_test_embed, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_embed, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.83 14.65 15.7\n",
      "Hurr until 2012:  10.83 14.65 15.7\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.03 13.29 12.64\n",
      "Hurr until 2012:  10.03 13.29 12.64\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#USING OFCL\n",
    "train = np.concatenate((X_test_baseline[:17094], X_test_total[:17094]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[:17094]\n",
    "test = np.concatenate((X_test_baseline, X_test_total), axis = 1)\n",
    "xgb_total = XGBRegressor(max_depth=8, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=5)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.46 13.28 11.66\n",
      "Hurr until 2012:  9.46 13.28 11.66\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.29 12.46 11.88\n",
      "Hurr until 2012:  9.29 12.46 11.88\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#OFCL ONLY\n",
    "#train = np.array(X_test_baseline[:17094])\n",
    "#tgt_train3 = tgt_intensity_test[:17094]\n",
    "train = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "tgt_train3 = tgt_intensity_test[train.index]\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=300, learning_rate=0.03, subsample=0.55, min_child_weight=1)\n",
    "xgb_total.fit(np.array(train), tgt_train3)\n",
    "#xgb_total = XGBRegressor(max_depth=7, n_estimators=300, learning_rate=0.03, subsample=0.55, min_child_weight=1)\n",
    "#xgb_total.fit(np.array(train), tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(X_test_baseline, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(X_test_baseline, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "#compare_perf_intensity_per_year_4cast(X_test_baseline, dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2017)\n",
    "#xgb_total = XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.7, min_child_weight=7)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "#compare_perf_intensity_per_year_4cast(X_test_baseline, dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.9957805907173"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11.02/11.85*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.32 13.99 13.75\n",
      "Hurr until 2012:  10.32 13.99 13.75\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.44 12.7 10.54\n",
      "Hurr until 2012:  9.44 12.7 10.54\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#OFCL with AN EP ONLY\n",
    "train_0 = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "train = np.concatenate((train_0, X_test_total[train_0.index]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[train_0.index]\n",
    "test = np.concatenate((X_test_baseline, X_test_total), axis = 1)\n",
    "#xgb_total = XGBRegressor(max_depth=5, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=1, colsample_bytree = 0.7)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "xgb_total = XGBRegressor(max_depth=7, n_estimators=300, learning_rate=0.03, subsample=0.55, min_child_weight=1)\n",
    "xgb_total.fit(np.array(train), tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.27 13.92 13.9\n",
      "Hurr until 2012:  10.27 13.92 13.9\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.25 12.56 10.73\n",
      "Hurr until 2012:  9.25 12.56 10.73\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#OFCL with AN EP ONLY\n",
    "train_0 = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "train = np.concatenate((train_0, X_test_total[train_0.index]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[train_0.index]\n",
    "test = np.concatenate((X_test_baseline, X_test_total), axis = 1)\n",
    "#xgb_total = XGBRegressor(max_depth=5, n_estimators=150, learning_rate=0.05, subsample=0.8, min_child_weight=1, colsample_bytree = 0.7)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "xgb_total = XGBRegressor(max_depth=6, n_estimators=200, learning_rate=0.03, subsample=0.8, min_child_weight=3, colsample_bytree = 1)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "#xgb_total = XGBRegressor(max_depth=7, n_estimators=200, learning_rate=0.03, subsample=0.8, min_child_weight=3, colsample_bytree = 1)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "#reached 9.1§\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.41 14.01 14.05\n",
      "Hurr until 2012:  10.41 14.01 14.05\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.64 13.04 11.88\n",
      "Hurr until 2012:  9.64 13.04 11.88\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#OFCL with AN EP ONLY\n",
    "train_0 = X_test_baseline[:17094].loc[X_test_baseline['cat_basin_AN_0'] + X_test_baseline['cat_basin_EP_0'] == 1]\n",
    "train = np.concatenate((train_0, X_test_embed[train_0.index]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[train_0.index]\n",
    "test = np.concatenate((X_test_baseline, X_test_embed), axis = 1)\n",
    "xgb_total = XGBRegressor(max_depth=6, n_estimators=300, learning_rate=0.03, subsample=0.55, min_child_weight=1)\n",
    "xgb_total.fit(np.array(train), tgt_train3)\n",
    "#xgb_total = XGBRegressor(max_depth=6, n_estimators=150, learning_rate=0.03, subsample=0.8, min_child_weight=2)\n",
    "#xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem with NaN\n",
    "#xgb2 = XGBRegressor(max_depth=8, n_estimators=140, learning_rate = 0.07, subsample = 0.7, min_child_weight = 5)\n",
    "#xgb2.fit(train, tgt_train3)\n",
    "#select = SelectFromModel(xgb2, prefit=True)\n",
    "#X_train_sparse = select.transform(train)\n",
    "#X_test_sparse = select.transform(test)\n",
    "#xgb_sparse2 = XGBRegressor(max_depth=3, n_estimators=150, learning_rate=0.07, subsample=0.8, min_child_weight=2, colsample_bytree = 0.7)\n",
    "#xgb_sparse2.fit(X_train_sparse, tgt_train3)\n",
    "#compare_perf_intensity_per_year_4cast(X_test_sparse, dict = {'year':[], 'num_samples':[], 'MAEs_full':[], 'std_full':[], 'MAES_2012':[], 'std_2012':[], 'MAES_SHIP':[], 'std_SHIP':[], 'MAES_HWRF':[], 'std_HWRF':[], 'MAES_OFCL':[], 'std_OFCL':[], 'MAES_FSSE':[], 'std_FSSE':[]}, xgb_total = xgb_sparse2, xgb_tot = xgb_sparse2, basin='AN', forecast='SHIP', mode='vmax', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  669\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.88 14.64 15.25\n",
      "Hurr until 2012:  10.88 14.64 15.25\n",
      "SHIP 11.29 15.51 17.34\n",
      "HWRF 9.59 12.59 11.21\n",
      "OFCL 8.55 11.85 7.32\n",
      "FSSE 8.44 11.29 7.32\n",
      "GFSO 14.0 15.64 22.42\n",
      "DSHP 10.28 13.59 14.8\n",
      "Total number of steps for comparison:  522\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.93 13.43 12.45\n",
      "Hurr until 2012:  9.93 13.43 12.45\n",
      "SHIP 11.97 15.22 16.86\n",
      "HWRF 9.95 14.02 14.18\n",
      "OFCL 9.55 12.99 7.85\n",
      "FSSE 9.22 12.38 9.96\n",
      "GFSO 16.95 19.67 31.99\n",
      "DSHP 11.85 15.13 16.86\n"
     ]
    }
   ],
   "source": [
    "#FULL TRAIN WITH CNN/GRU EMBEDS\n",
    "train = np.concatenate((X_test_baseline[:17094], X_test_embed[:17094]), axis = 1)\n",
    "tgt_train3 = tgt_intensity_test[:17094]\n",
    "test = np.concatenate((X_test_baseline, X_test_embed), axis = 1)\n",
    "xgb_total = XGBRegressor(max_depth=9, n_estimators=150, learning_rate=0.05, subsample=0.7, min_child_weight=7)\n",
    "xgb_total.fit(train, tgt_train3)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='AN', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)\n",
    "compare_perf_intensity_per_year_6cast(test, dict6, xgb_total = xgb_total, xgb_tot = xgb_total, basin='EP', forecast='SHIP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP', year = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  41\n",
      "Year  2012  MAE intensity basin AN Hurricast trained full:  9.13 with std  11.62\n",
      "Year  2012  MAE intensity basin AN Hurricast trained until 2012:  9.19 with std  11.32\n",
      "Year  2012  MAE intensity basin AN Official Forecast SHIP :  9.56 with std  10.79\n",
      "Year  2012  MAE intensity basin AN Official Forecast HWRF :  8.1 with std  11.14\n",
      "Year  2012  MAE intensity basin AN Official Forecast OFCL :  9.02 with std  11.36\n",
      "Year  2012  MAE intensity basin AN Official Forecast FSSE :  10.37 with std  11.62\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  8\n",
      "Year  2013  MAE intensity basin AN Hurricast trained full:  12.06 with std  11.75\n",
      "Year  2013  MAE intensity basin AN Hurricast trained until 2012:  11.28 with std  10.57\n",
      "Year  2013  MAE intensity basin AN Official Forecast SHIP :  19.31 with std  12.82\n",
      "Year  2013  MAE intensity basin AN Official Forecast HWRF :  9.31 with std  9.22\n",
      "Year  2013  MAE intensity basin AN Official Forecast OFCL :  14.06 with std  5.44\n",
      "Year  2013  MAE intensity basin AN Official Forecast FSSE :  8.56 with std  8.28\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  72\n",
      "Year  2014  MAE intensity basin AN Hurricast trained full:  6.73 with std  8.32\n",
      "Year  2014  MAE intensity basin AN Hurricast trained until 2012:  6.36 with std  8.0\n",
      "Year  2014  MAE intensity basin AN Official Forecast SHIP :  7.02 with std  8.36\n",
      "Year  2014  MAE intensity basin AN Official Forecast HWRF :  12.13 with std  13.58\n",
      "Year  2014  MAE intensity basin AN Official Forecast OFCL :  6.7 with std  8.39\n",
      "Year  2014  MAE intensity basin AN Official Forecast FSSE :  8.16 with std  8.09\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  122\n",
      "Year  2015  MAE intensity basin AN Hurricast trained full:  8.29 with std  11.25\n",
      "Year  2015  MAE intensity basin AN Hurricast trained until 2012:  8.48 with std  11.76\n",
      "Year  2015  MAE intensity basin AN Official Forecast SHIP :  9.52 with std  12.95\n",
      "Year  2015  MAE intensity basin AN Official Forecast HWRF :  9.44 with std  13.77\n",
      "Year  2015  MAE intensity basin AN Official Forecast OFCL :  7.93 with std  11.75\n",
      "Year  2015  MAE intensity basin AN Official Forecast FSSE :  8.0 with std  11.84\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  231\n",
      "Year  2016  MAE intensity basin AN Hurricast trained full:  11.42 with std  14.84\n",
      "Year  2016  MAE intensity basin AN Hurricast trained until 2012:  11.36 with std  14.99\n",
      "Year  2016  MAE intensity basin AN Official Forecast SHIP :  10.38 with std  14.57\n",
      "Year  2016  MAE intensity basin AN Official Forecast HWRF :  10.11 with std  14.34\n",
      "Year  2016  MAE intensity basin AN Official Forecast OFCL :  8.42 with std  11.4\n",
      "Year  2016  MAE intensity basin AN Official Forecast FSSE :  8.87 with std  12.22\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  228\n",
      "Year  2017  MAE intensity basin AN Hurricast trained full:  12.37 with std  15.73\n",
      "Year  2017  MAE intensity basin AN Hurricast trained until 2012:  12.42 with std  15.8\n",
      "Year  2017  MAE intensity basin AN Official Forecast SHIP :  12.32 with std  17.27\n",
      "Year  2017  MAE intensity basin AN Official Forecast HWRF :  10.05 with std  12.65\n",
      "Year  2017  MAE intensity basin AN Official Forecast OFCL :  8.59 with std  11.83\n",
      "Year  2017  MAE intensity basin AN Official Forecast FSSE :  7.72 with std  10.07\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  236\n",
      "Year  2018  MAE intensity basin AN Hurricast trained full:  9.78 with std  12.7\n",
      "Year  2018  MAE intensity basin AN Hurricast trained until 2012:  9.89 with std  12.82\n",
      "Year  2018  MAE intensity basin AN Official Forecast SHIP :  10.79 with std  14.97\n",
      "Year  2018  MAE intensity basin AN Official Forecast HWRF :  8.8 with std  12.37\n",
      "Year  2018  MAE intensity basin AN Official Forecast OFCL :  8.53 with std  12.1\n",
      "Year  2018  MAE intensity basin AN Official Forecast FSSE :  8.82 with std  12.16\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  208\n",
      "Year  2019  MAE intensity basin AN Hurricast trained full:  10.36 with std  13.38\n",
      "Year  2019  MAE intensity basin AN Hurricast trained until 2012:  10.52 with std  13.46\n",
      "Year  2019  MAE intensity basin AN Official Forecast SHIP :  10.89 with std  14.22\n",
      "Year  2019  MAE intensity basin AN Official Forecast HWRF :  9.89 with std  12.68\n",
      "Year  2019  MAE intensity basin AN Official Forecast OFCL :  8.55 with std  11.53\n",
      "Year  2019  MAE intensity basin AN Official Forecast FSSE :  8.73 with std  11.42\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [9.19, 11.28, 6.36, 8.48, 11.36, 12.42, 9.89, 10.52],\n",
       " 'MAES_FSSE': [10.37, 8.56, 8.16, 8.0, 8.87, 7.72, 8.82, 8.73],\n",
       " 'MAES_HWRF': [8.1, 9.31, 12.13, 9.44, 10.11, 10.05, 8.8, 9.89],\n",
       " 'MAES_OFCL': [9.02, 14.06, 6.7, 7.93, 8.42, 8.59, 8.53, 8.55],\n",
       " 'MAES_SHIP': [9.56, 19.31, 7.02, 9.52, 10.38, 12.32, 10.79, 10.89],\n",
       " 'MAEs_full': [9.13, 12.06, 6.73, 8.29, 11.42, 12.37, 9.78, 10.36],\n",
       " 'num_samples': [41, 8, 72, 122, 231, 228, 236, 208],\n",
       " 'std_2012': [11.32, 10.57, 8.0, 11.76, 14.99, 15.8, 12.82, 13.46],\n",
       " 'std_FSSE': [11.62, 8.28, 8.09, 11.84, 12.22, 10.07, 12.16, 11.42],\n",
       " 'std_HWRF': [11.14, 9.22, 13.58, 13.77, 14.34, 12.65, 12.37, 12.68],\n",
       " 'std_OFCL': [11.36, 5.44, 8.39, 11.75, 11.4, 11.83, 12.1, 11.53],\n",
       " 'std_SHIP': [10.79, 12.82, 8.36, 12.95, 14.57, 17.27, 14.97, 14.22],\n",
       " 'std_full': [11.62, 11.75, 8.32, 11.25, 14.84, 15.73, 12.7, 13.38],\n",
       " 'year': [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_4cast(forecast = 'SHIP', basin_only = False, sparse = False, max_depth = 8, n_estimators = 100, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  0\n",
      "Year 2012 Basin AN MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2012\n",
      "Total number of steps for comparison:  0\n",
      "Year 2013 Basin AN MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2013\n",
      "Total number of steps for comparison:  0\n",
      "Year 2014 Basin AN MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2014\n",
      "Total number of steps for comparison:  113\n",
      "Year 2015 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  8.25 11.46 11.5\n",
      "Hurr until 2012:  8.48 11.83 11.5\n",
      "SHIP 9.88 13.33 11.5\n",
      "HWRF 9.86 14.21 9.73\n",
      "OFCL 8.5 12.2 8.85\n",
      "FSSE 8.35 12.25 10.62\n",
      "GFSO 13.36 16.04 22.12\n",
      "DSHP 9.87 13.33 11.5\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  230\n",
      "Year 2016 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.49 15.0 16.09\n",
      "Hurr until 2012:  11.41 15.03 15.65\n",
      "SHIP 10.36 14.57 11.74\n",
      "HWRF 10.06 14.32 13.48\n",
      "OFCL 8.37 11.36 4.78\n",
      "FSSE 8.83 12.2 7.83\n",
      "GFSO 14.74 18.35 23.48\n",
      "DSHP 10.1 13.78 10.87\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  227\n",
      "Year 2017 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  12.17 15.41 20.26\n",
      "Hurr until 2012:  12.3 15.56 18.94\n",
      "SHIP 12.13 16.94 19.82\n",
      "HWRF 10.06 12.67 12.33\n",
      "OFCL 8.56 11.82 6.61\n",
      "FSSE 7.74 10.09 5.73\n",
      "GFSO 17.29 17.77 31.28\n",
      "DSHP 10.02 13.38 13.66\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  234\n",
      "Year 2018 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.8 12.75 12.82\n",
      "Hurr until 2012:  9.82 12.8 12.82\n",
      "SHIP 10.84 15.02 14.53\n",
      "HWRF 8.85 12.42 9.83\n",
      "OFCL 8.56 12.13 8.12\n",
      "FSSE 8.87 12.21 8.97\n",
      "GFSO 11.21 12.87 14.96\n",
      "DSHP 10.24 13.42 14.1\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  208\n",
      "Year 2019 Basin AN MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  10.35 13.28 10.58\n",
      "Hurr until 2012:  10.42 13.34 12.02\n",
      "SHIP 10.89 14.22 17.79\n",
      "HWRF 9.89 12.68 11.54\n",
      "OFCL 8.55 11.53 7.21\n",
      "FSSE 8.73 11.42 7.21\n",
      "GFSO 13.54 15.47 21.15\n",
      "DSHP 10.6 13.9 16.83\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [8.48, 11.41, 12.3, 9.82, 10.42],\n",
       " 'MAES_DSHP': [9.87, 10.1, 10.02, 10.24, 10.6],\n",
       " 'MAES_FSSE': [8.35, 8.83, 7.74, 8.87, 8.73],\n",
       " 'MAES_GFSO': [13.36, 14.74, 17.29, 11.21, 13.54],\n",
       " 'MAES_HWRF': [9.86, 10.06, 10.06, 8.85, 9.89],\n",
       " 'MAES_OFCL': [8.5, 8.37, 8.56, 8.56, 8.55],\n",
       " 'MAES_SHIP': [9.88, 10.36, 12.13, 10.84, 10.89],\n",
       " 'MAEs_full': [8.25, 11.49, 12.17, 9.8, 10.35],\n",
       " 'num_samples': [113, 230, 227, 234, 208],\n",
       " 'std_2012': [11.83, 15.03, 15.56, 12.8, 13.34],\n",
       " 'std_DSHP': [13.33, 13.78, 13.38, 13.42, 13.9],\n",
       " 'std_FSSE': [12.25, 12.2, 10.09, 12.21, 11.42],\n",
       " 'std_GFSO': [16.04, 18.35, 17.77, 12.87, 15.47],\n",
       " 'std_HWRF': [14.21, 14.32, 12.67, 12.42, 12.68],\n",
       " 'std_OFCL': [12.2, 11.36, 11.82, 12.13, 11.53],\n",
       " 'std_SHIP': [13.33, 14.57, 16.94, 15.02, 14.22],\n",
       " 'std_full': [11.46, 15.0, 15.41, 12.75, 13.28],\n",
       " 'year': [2015, 2016, 2017, 2018, 2019]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_6cast(forecast = 'SHIP', max_depth = 8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'AN', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps for comparison:  0\n",
      "Year 2012 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2012\n",
      "Total number of steps for comparison:  0\n",
      "Year 2013 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2013\n",
      "Total number of steps for comparison:  0\n",
      "Year 2014 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2014\n",
      "Total number of steps for comparison:  255\n",
      "Year 2015 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  11.65 16.07 17.65\n",
      "Hurr until 2012:  11.83 16.22 17.65\n",
      "SHIP 12.75 17.89 17.65\n",
      "HWRF 11.79 17.29 16.86\n",
      "OFCL 10.42 15.35 11.37\n",
      "FSSE 9.93 13.96 11.76\n",
      "GFSO 15.62 20.14 25.49\n",
      "DSHP 12.41 16.99 17.65\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  315\n",
      "Year 2016 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.64 13.24 13.97\n",
      "Hurr until 2012:  9.95 13.44 14.29\n",
      "SHIP 9.87 12.84 10.79\n",
      "HWRF 10.38 13.74 11.75\n",
      "OFCL 8.72 11.89 6.67\n",
      "FSSE 8.51 11.53 8.57\n",
      "GFSO 13.02 16.38 21.27\n",
      "DSHP 9.69 12.58 10.16\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  167\n",
      "Year 2017 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  9.02 12.96 8.98\n",
      "Hurr until 2012:  9.1 13.04 10.18\n",
      "SHIP 9.97 13.0 10.78\n",
      "HWRF 7.87 11.61 8.38\n",
      "OFCL 8.14 11.67 4.79\n",
      "FSSE 7.92 10.67 4.79\n",
      "GFSO 11.93 16.27 17.96\n",
      "DSHP 9.49 12.71 10.18\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  355\n",
      "Year 2018 Basin EP MAE intensity | std | busts > 20kn %\n",
      "Hurr full:  12.09 15.73 20.0\n",
      "Hurr until 2012:  12.4 16.1 21.13\n",
      "SHIP 12.91 15.83 19.72\n",
      "HWRF 10.94 14.86 16.9\n",
      "OFCL 10.22 13.48 9.3\n",
      "FSSE 9.83 12.64 12.39\n",
      "GFSO 19.32 20.45 38.59\n",
      "DSHP 12.96 15.85 20.0\n",
      "\n",
      "\n",
      "Total number of steps for comparison:  0\n",
      "Year 2019 Basin EP MAE intensity | std | busts > 20kn %\n",
      "\n",
      " No forecasts for year  2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAES_2012': [11.83, 9.95, 9.1, 12.4],\n",
       " 'MAES_DSHP': [12.41, 9.69, 9.49, 12.96],\n",
       " 'MAES_FSSE': [9.93, 8.51, 7.92, 9.83],\n",
       " 'MAES_GFSO': [15.62, 13.02, 11.93, 19.32],\n",
       " 'MAES_HWRF': [11.79, 10.38, 7.87, 10.94],\n",
       " 'MAES_OFCL': [10.42, 8.72, 8.14, 10.22],\n",
       " 'MAES_SHIP': [12.75, 9.87, 9.97, 12.91],\n",
       " 'MAEs_full': [11.65, 9.64, 9.02, 12.09],\n",
       " 'num_samples': [255, 315, 167, 355],\n",
       " 'std_2012': [16.22, 13.44, 13.04, 16.1],\n",
       " 'std_DSHP': [16.99, 12.58, 12.71, 15.85],\n",
       " 'std_FSSE': [13.96, 11.53, 10.67, 12.64],\n",
       " 'std_GFSO': [20.14, 16.38, 16.27, 20.45],\n",
       " 'std_HWRF': [17.29, 13.74, 11.61, 14.86],\n",
       " 'std_OFCL': [15.35, 11.89, 11.67, 13.48],\n",
       " 'std_SHIP': [17.89, 12.84, 13.0, 15.83],\n",
       " 'std_full': [16.07, 13.24, 12.96, 15.73],\n",
       " 'year': [2015, 2016, 2017, 2018]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xgb_intensity_all_years_full_train_6cast(forecast = 'SHIP', max_depth = 8, n_estimators = 150, learning_rate = 0.07, subsample = 0.7, min_child_weight=5, basin = 'EP', forecast2 = 'HWRF', forecast3 = 'OFCL', forecast4 = 'FSSE', forecast5 = 'GFSO', forecast6 = 'DSHP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
