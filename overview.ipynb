{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2016_2018\u001b[m\u001b[m\r\n",
      "\u001b[34mdata_era\u001b[m\u001b[m\r\n",
      "\u001b[34mtensor_completion\u001b[m\u001b[m\r\n",
      "vision_data.npy\r\n",
      "y.npy\r\n",
      "y_train_displacement_1980_50_20_90_w8.npy\r\n",
      "y_train_intensity_1980_50_20_90_w8.npy\r\n",
      "y_train_intensity_cat_1980_50_20_90_w8.npy\r\n",
      "y_train_intensity_cat_baseline_1980_50_20_90_w8.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Load the data using the torch.loaders. Depending on the mode chosen, the iterator will output different dictionaries.\n",
    "- Need to specify the correct mode (regression/classification)\n",
    "- Important TODO: Add an option to direclty load a tensor. However, it would probably be better to have directly the tensor(s) in the correct shape. **Double Check that point**. \n",
    "- Better to be able to load a dictionary of tensors directly to be able to delete the keys that we want. \n",
    "- TODO: Add an option to delete some of the keys as we go along. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset and corresponding sizes (null elements included):\n",
      "X_vision torch.Size([3735, 8, 9, 25, 25])\n",
      "X_stat torch.Size([3735, 8, 10])\n",
      "target_displacement torch.Size([3735, 8, 2])\n",
      "target_intensity torch.Size([3735])\n",
      "target_intensity_cat torch.Size([3735])\n",
      "target_intensity_cat_baseline torch.Size([3735])\n",
      "Keeping 3143 samples out of the initial 3735.\n",
      "Reshaping the displacement target...\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field, asdict\n",
    "import imp\n",
    "\n",
    "#For the Notebook\n",
    "@dataclass\n",
    "class Args:\n",
    "    data_dir: str\n",
    "    y_name: str\n",
    "    vision_name: str\n",
    "    predict_at: int\n",
    "    window_size: int\n",
    "    train_test_split: float\n",
    "    mode: str\n",
    "    batch_size: int\n",
    "        \n",
    "args = Args(\n",
    "    data_dir=\"data/\", \n",
    "    y_name=\"y.npy\",\n",
    "    vision_name=\"vision_data.npy\", \n",
    "    predict_at=8,\n",
    "    window_size=8, \n",
    "    train_test_split=0.8, \n",
    "    batch_size=10, \n",
    "    mode='intensity')\n",
    "\n",
    "from src.prepro import create_loaders\n",
    "##timeit\n",
    "train_loader, test_loader = create_loaders(**vars(args), debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does create_loaders work ?**\n",
    "```python\n",
    "\n",
    "vision_data = np.load(osp.join(data_dir, vision_name),\n",
    "                          allow_pickle=True)\n",
    "y = np.load(osp.join(data_dir, y_name),\n",
    "                allow_pickle=True)\n",
    "\n",
    "#Create named tensors\n",
    "train_tensors, test_tensors = Prepro.process(\n",
    "        y=y, \n",
    "        vision_data=vision_data,\n",
    "        train_split=train_test_split,\n",
    "        predict_at=predict_at,\n",
    "        window_size=window_size)\n",
    "\n",
    "#Filter the relevant keys\n",
    "train_tensors, test_tensors = filter_keys(\n",
    "     train_tensors, test_tensors, mode=mode)\n",
    "\n",
    "#Unroll in tensordataset\n",
    "train_ds = TensorDataset(*train_tensors.values())\n",
    "test_ds = TensorDataset(*test_tensors.values())\n",
    "    \n",
    "#Create collate_fn \n",
    "collate_fn = create_collate_fn()\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            drop_last=True,\n",
    "                            collate_fn=collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_ds, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False, \n",
    "                            collate_fn=collate_fn)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_model x_viz torch.Size([10, 8, 9, 25, 25])\n",
      "in_model x_stat torch.Size([10, 8, 10])\n",
      "in_loss trg_y torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#The output of the loaders are dictionary.\n",
    "in_model, in_loss = next(iter(train_loader))\n",
    "for k, v in in_model.items(): print('in_model', k, v.size())\n",
    "for k, v in in_loss.items(): print('in_loss', k, v.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(in_model['x_viz'][0,0,1].detach().numpy());plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Update when loading the tensors directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npath_train_stat = osp.join(\\n    \"data\", \"X_train_stat_1980_50_20_90_w8.npy\")\\nx_train = np.load(path_train_stat)\\nx_train = x_train.reshape(x_train.shape[0], args.window_size, -1)\\nprint(x_train.shape)\\n\\npath_test_stat = osp.join(\\n    \"data\", \"X_test_stat_1980_50_20_90_w8.npy\")\\nx_test = np.load(path_test_stat)\\nx_test = x_test.reshape(x_test.shape[0], args.window_size, -1)\\n\\nprint(x_test.shape)\\n# Select the first 7 values ?\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "path_train_stat = osp.join(\n",
    "    \"data\", \"X_train_stat_1980_50_20_90_w8.npy\")\n",
    "x_train = np.load(path_train_stat)\n",
    "x_train = x_train.reshape(x_train.shape[0], args.window_size, -1)\n",
    "print(x_train.shape)\n",
    "\n",
    "path_test_stat = osp.join(\n",
    "    \"data\", \"X_test_stat_1980_50_20_90_w8.npy\")\n",
    "x_test = np.load(path_test_stat)\n",
    "x_test = x_test.reshape(x_test.shape[0], args.window_size, -1)\n",
    "\n",
    "print(x_test.shape)\n",
    "# Select the first 7 values ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "path_train_stat = osp.join(\"data\", \"y.npy\")\n",
    "x_train = np.load(path_train_stat, allow_pickle=True)\n",
    "x_train.shape\n",
    "\n",
    "\n",
    "x_stat_train = torch.Tensor(np.load('data/X_train_stat_1980_50_20_90_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "                                        allow_pickle=True).reshape(-1, args.window_size, 30)[:,:,:10])[:,-args.sub_window_size:].to(device)\n",
    "x_stat_test = torch.Tensor(np.load('data/X_test_stat_1980_50_20_90_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "                                       allow_pickle=True).reshape(-1, args.window_size, 30)[:,:,:10])[:,-args.sub_window_size:].to(device)\n",
    "x_viz_train = torch.Tensor(np.load('data/X_train_vision_1980_34_20_120_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "                                       allow_pickle = True).reshape(-1, args.window_size, 9, 25, 25))[:,-args.sub_window_size:].to(device)\n",
    "x_viz_test = torch.Tensor(np.load('data/X_test_vision_1980_34_20_120_w' + str(args.window_size) + '_at_' + str(args.predict_at) + '.npy',\n",
    "                                      allow_pickle = True).reshape(-1, args.window_size, 9, 25, 25))[:,-args.sub_window_size:].to(device)\n",
    "\n",
    "x_stat_train = torch.Tensor(\n",
    "    np.load('data/X_train_stat_1980_50_20_90_w' + str(8) + '.npy',\n",
    "                                        allow_pickle=True).reshape(-1, 8, 30\n",
    "                                                                  )[:,:,:10])[:,-8:].to(device)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Models (OLD)\n",
    "Experimental version in experimental_models (TO COME, see below).\n",
    "___\n",
    "The different configurations are stored in scripts/config.py.\n",
    "We create a model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_loss.keys()\n",
    "from src.models import factory, hurricast_models\n",
    "from src.models import experimental_models as expm\n",
    "from scripts import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.test.models' from '/Users/theoguenais/Desktop/Harvard/Harvard-Classes/hurricast/src/test/models.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import test.models as tm\n",
    "from src.test import models as testmodels\n",
    "import imp \n",
    "imp.reload(testmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Split Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "2.56 s ± 182 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "testmodels.test_split_encoder(in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "Full Encoder, No Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "1.52 s ± 98.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "testmodels.test_full_encoder(in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "No Encoder, Stat\n",
      "Out Size torch.Size([10, 2])\n",
      "640 ms ± 105 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "testmodels.test_no_encoder(in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# 3 - Models (NEW)\n",
    "- Precise the encoder config: can be either one CNN that transforms the 9 channels or 3 separate CNNs (full_encoder_config vs split_encoder_config). In the later case, need to specify ```split_cnns=True``` when initiating the model.\n",
    "- Use ```train_stats = False``` to use the CNN only\n",
    "- Declare ```encoder_config=None``` not to use CNN (Or do not provdde any image to the model and it will automatically discard the image part of the data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(expm)\n",
    "from src.models import experimental_models as expm\n",
    "\n",
    "#%pdb\n",
    "full_encoder_config = dict(\n",
    "    n_in = 3 * 3,\n",
    "    n_out=128,\n",
    "    hidden_configuration=(\n",
    "        ('conv', 64),\n",
    "        ('conv', 64),\n",
    "        ('maxpool', None),\n",
    "        ('conv', 256),\n",
    "        ('maxpool', None),\n",
    "        ('flatten', 256 * 4 * 4),\n",
    "        ('linear', 256),\n",
    "        ('fc', 128)\n",
    "    ))\n",
    "\n",
    "split_encoder_config = dict(\n",
    "    n_in=3,\n",
    "    \n",
    "    n_out=128,\n",
    "    hidden_configuration=(\n",
    "        ('conv', 64),\n",
    "        ('conv', 64),\n",
    "        ('maxpool', None),\n",
    "        ('conv', 256),\n",
    "        ('maxpool', None),\n",
    "        ('flatten', 256 * 4 * 4),\n",
    "        ('linear', 256),\n",
    "        ('fc', 128)\n",
    "    ))\n",
    "\n",
    "transfo_config=dict(\n",
    "                n_in=128+10,\n",
    "                n_head=2, \n",
    "                dim_feedforward=2048,\n",
    "                num_layers=64,\n",
    "                dropout=0.1,\n",
    "                window_size=None, \n",
    "                n_out_unroll=None,\n",
    "                max_len_pe=10,\n",
    "                pool_method='default', \n",
    "                activation='tanh')\n",
    "\n",
    "\n",
    "gru_config = dict(n_in=128+10,\n",
    "                 hidden_dim=256,\n",
    "                 rnn_num_layers=2,\n",
    "                 N_OUT=256,\n",
    "                 rnn_type='gru',\n",
    "                 dropout=0.,\n",
    "                 activation_fn='tanh',\n",
    "                 bidir=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "#Examples with Splitted CNNS\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config=transfo_config,\n",
    "    encoder_config=split_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder',\n",
    "    split_cnns=True, \n",
    "    no_stat=False)\n",
    "\n",
    "#With Split CNNs and Stat\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())\n",
    "\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config={**transfo_config, **{'n_in':128}},\n",
    "    encoder_config=split_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder',\n",
    "    split_cnns=True, \n",
    "    no_stat=True)\n",
    "\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "#Examples with Full CNN\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config=transfo_config,\n",
    "    encoder_config=full_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder',\n",
    "    split_cnns=False, \n",
    "    no_stat=False)\n",
    "\n",
    "#With Split CNNs and Stat\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())\n",
    "\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config={**transfo_config, **{'n_in':128}},\n",
    "    encoder_config=full_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder',\n",
    "    split_cnns=False, \n",
    "    no_stat=True)\n",
    "\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "#Examples with No CNN\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config={**transfo_config, **{'n_in':10}},\n",
    "    encoder_config=None,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name=None,\n",
    "    split_cnns=False, \n",
    "    no_stat=False)\n",
    "\n",
    "\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())\n",
    "\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config={**transfo_config, **{'n_in':10}},\n",
    "    encoder_config=None,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name=None,\n",
    "    split_cnns=False, \n",
    "    no_stat=True)\n",
    "#With Split CNNs and Stat\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "#Example with GRU\n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config={**gru_config, **{'n_in':10}},\n",
    "    encoder_config=None,\n",
    "    decoder_name='ExpLSTM',\n",
    "    encoder_name=None,\n",
    "    split_cnns=False, \n",
    "    no_stat=True)\n",
    "#With Split CNNs and Stat\n",
    "out = Wrap(**in_model)\n",
    "print(out.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config=transfo_config,\n",
    "    encoder_config=split_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder',\n",
    "    split_cnns=True, \n",
    "    no_stat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfo_config=dict(\n",
    "                n_in=128+10,\n",
    "                n_head=2, \n",
    "                dim_feedforward=2048,\n",
    "                num_layers=64,\n",
    "                dropout=0.1,\n",
    "                window_size=None, \n",
    "                n_out_unroll=None,\n",
    "                max_len_pe=10,\n",
    "                pool_method='default', \n",
    "                activation='tanh')\n",
    "#With no CNN \n",
    "Wrap = expm.ExperimentalHurricast(\n",
    "    n_pred=2,\n",
    "    decoder_config=transfo_config,\n",
    "    encoder_config=full_encoder_config,\n",
    "    decoder_name='ExpTRANSFORMER',\n",
    "    encoder_name='CNNEncoder', \n",
    "    split_cnns=False, \n",
    "    no_stat=False)\n",
    "\n",
    "#ONE CNN AND STAT\n",
    "out = Wrap(**in_model)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS - OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rec_cells(rnn_type):\n",
    "#    _rec_cells = dict(\n",
    "#        lstm=nn.LSTM, \n",
    "#        gru=nn.GRU, \n",
    "#        rnn=nn.RNN)\n",
    "#    assert rnn_type in _rec_cells.keys(), \"\\\n",
    "#        Wrong type of rnn cell specified. Available cells:{}\".format(\n",
    "#        _rec_cells.keys())\n",
    "    #assert rnn_type != 'lstm', \"LSTM not supported yet\"\n",
    "#    return _rec_cells[rnn_type]\n",
    "\n",
    "\n",
    "#def _get_activation_module(name):\n",
    "#    #TODO: Write a func with check and so on.\n",
    "#    _activations_modules = dict(\n",
    "#        relu=nn.ReLU(),\n",
    "#        gelu=GELU(),\n",
    "#        identity=nn.Identity(),\n",
    "#    )\n",
    "#    return _activations_modules[name]\n",
    "\n",
    "#import torch.nn as nn\n",
    "\n",
    "#lstm_config = dict(n_in=128+10,\n",
    "#                 hidden_dim=256,\n",
    "#                 rnn_num_layers=2,\n",
    "#                 N_OUT=128,\n",
    "#                 rnn_type='gru',\n",
    "#                 dropout=0.1,\n",
    "#                 activation_fn='tanh',\n",
    "#                 bidir=True)\n",
    "\n",
    "\n",
    "    \n",
    "#lstm_config = dict(n_in=128+10,\n",
    "#                 hidden_dim=256,\n",
    "#                 rnn_num_layers=2,\n",
    "#                 N_OUT=128,\n",
    "#                 rnn_type='gru',\n",
    "#                 dropout=0.1,\n",
    "#                 activation_fn='tanh',\n",
    "#                 bidir=True)\n",
    "#Gru = VanillaRNN(**lstm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_x_viz = Wrap.encode(in_model['x_viz'])\n",
    "#print(encoded_x_viz.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 138])\n"
     ]
    }
   ],
   "source": [
    "fused_x = Wrap.fusion(in_model['x_stat'], encoded_x_viz)\n",
    "print(fused_x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 138])\n"
     ]
    }
   ],
   "source": [
    "out_transformer = Wrap.decode(fused_x)\n",
    "print(out_transformer.size()) #Pooled data: either mean pooling, or cls token..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 138])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_transformer.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, hidden = Gru.rnn(fused_x)\n",
    "hidden = hidden[0]\n",
    "print(hidden.size())\n",
    "torch.cat((hidden[-2, :, :], hidden[-1, :, :]), 1).size()\n",
    "#out_rnn[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 25, 25])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_viz.size()\n",
    "#unrolled = x_viz.unbind(1)\n",
    "#x = unrolled[0]\n",
    "#x.size()\n",
    "#x_split = torch.split(x, 3, dim=1)\n",
    "#x_split[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1089,  0.0503, -0.1470,  ...,  0.2681, -0.5071, -0.2926],\n",
       "        [-0.0448,  0.1818,  0.3278,  ...,  0.4195, -0.3653, -0.3424],\n",
       "        [-0.1918, -0.0556,  0.0775,  ...,  0.4764, -0.5221, -0.1965],\n",
       "        ...,\n",
       "        [-0.0077, -0.0079, -0.0717,  ...,  0.5837, -0.2861,  0.0182],\n",
       "        [-0.2135, -0.1460,  0.1935,  ...,  0.4441, -0.4734, -0.1142],\n",
       "        [ 0.0333,  0.0822, -0.1646,  ...,  0.4170, -0.2722,  0.0203]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gru(fused_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#import imp\n",
    "#import src\n",
    "#imp.reload(src.models)\n",
    "#imp.reload(src.models.factory)\n",
    "#imp.reload(src.models.hurricast_models)\n",
    "#import src.models\n",
    "#del args.device\n",
    "#del args.writer\n",
    "from dataclasses import dataclass, field, asdict\n",
    "import imp\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    data_dir: str\n",
    "    y_name: str\n",
    "    vision_name: str\n",
    "    predict_at: int\n",
    "    window_size: int\n",
    "    train_test_split: float\n",
    "    mode: str\n",
    "    batch_size: int\n",
    "        \n",
    "args = Args(data_dir=\"data/\", \n",
    "            y_name=\"y.npy\",\n",
    "           vision_name=\"vision_data.npy\", \n",
    "           predict_at=8,\n",
    "           window_size=8, \n",
    "           train_test_split=0.8, \n",
    "           batch_size=10, \n",
    "           mode='intensity')\n",
    "\"\"\"\n",
    "#assert hasaatr()\n",
    "Gru.N_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prepare the training using  cpu\n"
     ]
    }
   ],
   "source": [
    "#if args.encdec: decoder_config = config.encdec_config\n",
    "#elif args.transformer: decoder_config=config.transformer_config\n",
    "#else: decoder_config = config.lineartransform_config\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts import config\n",
    "from src.models import factory, hurricast_models\n",
    "from src import setup\n",
    "#Just a hack for the notebook\n",
    "args.encdec = True\n",
    "args.transformer = False\n",
    "args.output_dir = 'results/companion_notebook'\n",
    "writer = setup.create_board(args)\n",
    "device = setup.create_device(gpu_nb=-1)\n",
    "args.device = None\n",
    "args.writer = writer\n",
    "# End of the hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENCDEC(\n",
       "  (encoder): CNNEncoder(\n",
       "    (activation): ReLU()\n",
       "    (layers): Sequential(\n",
       "      (0): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU()\n",
       "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (11): Flatten()\n",
       "      (12): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): ReLU()\n",
       "      (15): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder_cells): Sequential(\n",
       "    (0): GRUCell(138, 128)\n",
       "    (1): GRUCell(128, 128)\n",
       "  )\n",
       "  (last_linear): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_config = config.encoder_config\n",
    "decoder_config = config.encdec_config\n",
    "\n",
    "model = factory.get_model(\n",
    "        mode=args.mode, \n",
    "        encoder_config=encoder_config,\n",
    "        decoder_config=decoder_config, \n",
    "        args=args)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the refistered models?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CNNEncoder': <class 'src.models.experimental_models.CNNEncoder'>, 'ENCDEC': <class 'src.models.experimental_models.ENCDEC'>, 'TRANSFORMER': <class 'src.models.hurricast_models.TRANSFORMER'>, 'LINEARTransform': <class 'src.models.hurricast_models.LINEARTransform'>, 'ExperimentalHurricast': <class 'src.models.experimental_models.ExperimentalHurricast'>, 'ExpTRANSFORMER': <class 'src.models.experimental_models.ExpTRANSFORMER'>, 'ExpLSTM': <class 'src.models.experimental_models.ExpLSTM'>, 'ExperimentalLINEARTransform': <class 'src.models.experimental_models.LINEARTransform'>}\n"
     ]
    }
   ],
   "source": [
    "print(factory.MODEL_REGISTRY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model creation is wrapped using the models/factory.py file and the function:**\n",
    "```py\n",
    "def get_model(mode, encoder_config, decoder_config, args):\n",
    "    #Needs to upload window size and _OUT_DECODER\n",
    "    #Get some\n",
    "    assert (int(args.encdec) + int(args.transformer) < 2), \"\\\n",
    "    Only one of encdec or transformer can be specified\"\n",
    "\n",
    "    _encoder = MODEL_REGISTRY['CNNEncoder']\n",
    "    if args.encdec:\n",
    "        _model = MODEL_REGISTRY['ENCDEC']\n",
    "    elif args.transformer:\n",
    "        _model = MODEL_REGISTRY['TRANSFORMER']\n",
    "    else:\n",
    "        model = MODEL_REGISTRY['LINEARTransform']\n",
    "\n",
    "    N_OUT_DECODER = 7 if mode == 'intensity_cat' else (\n",
    "        2 - (mode == 'intensity'))  # 7 classes of storms if categorical\n",
    "\n",
    "    #Encoder\n",
    "    encoder_config = encoder_config if isinstance(encoder_config, dict)\\\n",
    "        else vars(encoder_config)\n",
    "\n",
    "    encoder = _encoder(**encoder_config)\n",
    "\n",
    "    #Decoder: Update the config\n",
    "    decoder_config = decoder_config if isinstance(decoder_config, dict)\\\n",
    "        else vars(encoder_config)\n",
    "\n",
    "    if not args.encdec and not args.transformer:\n",
    "        decoder_config['target_intensity'] = args.target_intensity,\n",
    "        decoder_config['target_intensity_cat'] = args.target_intensity_cat\n",
    "\n",
    "    else:\n",
    "        decoder_config['encoder'] = encoder\n",
    "        decoder_config['window_size'] = args.window_size\n",
    "        decoder_config['n_out_decoder'] = N_OUT_DECODER\n",
    "\n",
    "    model = _model(**decoder_config)\n",
    "\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    if args.writer is not None:\n",
    "        configs = [encoder_config, decoder_config]\n",
    "        config_ = \"\"\n",
    "        for config__ in configs:\n",
    "            config_ += \"{}\\n\".format(config__)\n",
    "        args.writer.add_text('Configs', config_)\n",
    "    return model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3  - Prepare the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Inner Training loop:   0%|          | 0/251 [00:00<?, ?it/s]\u001b[A/Users/theoguenais/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\n",
      "Inner Training loop:   0%|          | 1/251 [00:00<03:24,  1.22it/s]\u001b[A\n",
      "Inner Training loop:   1%|          | 2/251 [00:01<03:25,  1.21it/s]\u001b[A\n",
      "Inner Training loop:   1%|          | 3/251 [00:02<03:34,  1.16it/s]\u001b[A\n",
      "Inner Training loop:   2%|▏         | 4/251 [00:03<03:36,  1.14it/s]\u001b[A\n",
      "Inner Training loop:   2%|▏         | 5/251 [00:04<03:43,  1.10it/s]\u001b[A\n",
      "Inner Training loop:   2%|▏         | 6/251 [00:05<03:44,  1.09it/s]\u001b[A\n",
      "Inner Training loop:   3%|▎         | 7/251 [00:06<03:47,  1.07it/s]\u001b[A\n",
      "Inner Training loop:   3%|▎         | 8/251 [00:07<03:50,  1.05it/s]\u001b[A\n",
      "Inner Training loop:   4%|▎         | 9/251 [00:08<04:01,  1.00it/s]\u001b[A\n",
      "Inner Training loop:   4%|▍         | 10/251 [00:09<03:54,  1.03it/s]\u001b[A\n",
      "Inner Training loop:   4%|▍         | 11/251 [00:10<03:51,  1.04it/s]\u001b[A\n",
      "Inner Training loop:   5%|▍         | 12/251 [00:11<03:46,  1.06it/s]\u001b[A\n",
      "Inner Training loop:   5%|▌         | 13/251 [00:12<03:37,  1.09it/s]\u001b[A\n",
      "Inner Training loop:   6%|▌         | 14/251 [00:12<03:23,  1.16it/s]\u001b[A\n",
      "Inner Training loop:   6%|▌         | 15/251 [00:13<03:16,  1.20it/s]\u001b[A\n",
      "Inner Training loop:   6%|▋         | 16/251 [00:14<03:06,  1.26it/s]\u001b[A\n",
      "Inner Training loop:   7%|▋         | 17/251 [00:15<02:58,  1.31it/s]\u001b[A\n",
      "Inner Training loop:   7%|▋         | 18/251 [00:15<02:53,  1.34it/s]\u001b[A\n",
      "Inner Training loop:   8%|▊         | 19/251 [00:16<02:49,  1.37it/s]\u001b[A\n",
      "Inner Training loop:   8%|▊         | 20/251 [00:17<03:10,  1.21it/s]\u001b[A\n",
      "Inner Training loop:   8%|▊         | 21/251 [00:18<03:19,  1.15it/s]\u001b[A\n",
      "Inner Training loop:   9%|▉         | 22/251 [00:19<03:16,  1.17it/s]\u001b[A\n",
      "Inner Training loop:   9%|▉         | 23/251 [00:20<03:22,  1.13it/s]\u001b[A\n",
      "Inner Training loop:  10%|▉         | 24/251 [00:21<03:20,  1.13it/s]\u001b[A\n",
      "Inner Training loop:  10%|▉         | 25/251 [00:21<03:10,  1.18it/s]\u001b[A\n",
      "Inner Training loop:  10%|█         | 26/251 [00:22<03:06,  1.21it/s]\u001b[A\n",
      "Inner Training loop:  11%|█         | 27/251 [00:23<03:02,  1.23it/s]\u001b[A\n",
      "Inner Training loop:  11%|█         | 28/251 [00:24<02:53,  1.29it/s]\u001b[A\n",
      "Inner Training loop:  12%|█▏        | 29/251 [00:24<02:47,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  12%|█▏        | 30/251 [00:25<02:41,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  12%|█▏        | 31/251 [00:26<02:38,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  13%|█▎        | 32/251 [00:26<02:36,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  13%|█▎        | 33/251 [00:27<02:38,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  14%|█▎        | 34/251 [00:28<02:39,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  14%|█▍        | 35/251 [00:29<02:37,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  14%|█▍        | 36/251 [00:29<02:34,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  15%|█▍        | 37/251 [00:30<02:32,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  15%|█▌        | 38/251 [00:31<02:30,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  16%|█▌        | 39/251 [00:31<02:29,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  16%|█▌        | 40/251 [00:32<02:30,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  16%|█▋        | 41/251 [00:33<02:33,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  17%|█▋        | 42/251 [00:34<02:30,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  17%|█▋        | 43/251 [00:34<02:29,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  18%|█▊        | 44/251 [00:35<02:27,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  18%|█▊        | 45/251 [00:36<02:26,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  18%|█▊        | 46/251 [00:36<02:26,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  19%|█▊        | 47/251 [00:37<02:26,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  19%|█▉        | 48/251 [00:38<02:31,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  20%|█▉        | 49/251 [00:39<02:27,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  20%|█▉        | 50/251 [00:39<02:26,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  20%|██        | 51/251 [00:40<02:23,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  21%|██        | 52/251 [00:41<02:21,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  21%|██        | 53/251 [00:42<02:25,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  22%|██▏       | 54/251 [00:43<02:40,  1.22it/s]\u001b[A\n",
      "Inner Training loop:  22%|██▏       | 55/251 [00:43<02:43,  1.20it/s]\u001b[A\n",
      "Inner Training loop:  22%|██▏       | 56/251 [00:44<02:36,  1.25it/s]\u001b[A\n",
      "Inner Training loop:  23%|██▎       | 57/251 [00:45<02:29,  1.30it/s]\u001b[A\n",
      "Inner Training loop:  23%|██▎       | 58/251 [00:46<02:24,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  24%|██▎       | 59/251 [00:46<02:21,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  24%|██▍       | 60/251 [00:47<02:21,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  24%|██▍       | 61/251 [00:48<02:20,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  25%|██▍       | 62/251 [00:48<02:18,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  25%|██▌       | 63/251 [00:49<02:16,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  25%|██▌       | 64/251 [00:50<02:14,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  26%|██▌       | 65/251 [00:51<02:13,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  26%|██▋       | 66/251 [00:51<02:12,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  27%|██▋       | 67/251 [00:52<02:14,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  27%|██▋       | 68/251 [00:53<02:16,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  27%|██▋       | 69/251 [00:54<02:13,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  28%|██▊       | 70/251 [00:54<02:11,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  28%|██▊       | 71/251 [00:55<02:09,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  29%|██▊       | 72/251 [00:56<02:08,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  29%|██▉       | 73/251 [00:56<02:06,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  29%|██▉       | 74/251 [00:57<02:08,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  30%|██▉       | 75/251 [00:58<02:09,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  30%|███       | 76/251 [00:59<02:07,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  31%|███       | 77/251 [00:59<02:05,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  31%|███       | 78/251 [01:00<02:02,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  31%|███▏      | 79/251 [01:01<02:01,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  32%|███▏      | 80/251 [01:01<02:01,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  32%|███▏      | 81/251 [01:02<02:02,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  33%|███▎      | 82/251 [01:03<02:04,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  33%|███▎      | 83/251 [01:04<02:02,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  33%|███▎      | 84/251 [01:04<02:00,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  34%|███▍      | 85/251 [01:05<01:59,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  34%|███▍      | 86/251 [01:06<01:58,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  35%|███▍      | 87/251 [01:07<01:59,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  35%|███▌      | 88/251 [01:07<01:57,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  35%|███▌      | 89/251 [01:08<01:59,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  36%|███▌      | 90/251 [01:09<01:57,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  36%|███▋      | 91/251 [01:09<01:55,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  37%|███▋      | 92/251 [01:10<01:53,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  37%|███▋      | 93/251 [01:11<01:52,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  37%|███▋      | 94/251 [01:12<01:54,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  38%|███▊      | 95/251 [01:12<01:51,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  38%|███▊      | 96/251 [01:13<01:52,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  39%|███▊      | 97/251 [01:14<01:50,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  39%|███▉      | 98/251 [01:14<01:50,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  39%|███▉      | 99/251 [01:15<01:49,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  40%|███▉      | 100/251 [01:16<01:48,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  40%|████      | 101/251 [01:17<01:49,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  41%|████      | 102/251 [01:17<01:47,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  41%|████      | 103/251 [01:18<01:48,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  41%|████▏     | 104/251 [01:19<01:46,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  42%|████▏     | 105/251 [01:20<01:44,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  42%|████▏     | 106/251 [01:20<01:43,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  43%|████▎     | 107/251 [01:21<01:43,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  43%|████▎     | 108/251 [01:22<01:44,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  43%|████▎     | 109/251 [01:22<01:42,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  44%|████▍     | 110/251 [01:23<01:42,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  44%|████▍     | 111/251 [01:24<01:40,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  45%|████▍     | 112/251 [01:25<01:38,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  45%|████▌     | 113/251 [01:25<01:37,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  45%|████▌     | 114/251 [01:26<01:36,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  46%|████▌     | 115/251 [01:27<01:37,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  46%|████▌     | 116/251 [01:27<01:36,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  47%|████▋     | 117/251 [01:28<01:36,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  47%|████▋     | 118/251 [01:29<01:34,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  47%|████▋     | 119/251 [01:30<01:33,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  48%|████▊     | 120/251 [01:30<01:32,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  48%|████▊     | 121/251 [01:31<01:30,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  49%|████▊     | 122/251 [01:32<01:32,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  49%|████▉     | 123/251 [01:32<01:31,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  49%|████▉     | 124/251 [01:33<01:31,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  50%|████▉     | 125/251 [01:34<01:29,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  50%|█████     | 126/251 [01:35<01:28,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  51%|█████     | 127/251 [01:35<01:27,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  51%|█████     | 128/251 [01:36<01:26,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  51%|█████▏    | 129/251 [01:37<01:28,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  52%|█████▏    | 130/251 [01:37<01:26,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  52%|█████▏    | 131/251 [01:38<01:27,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  53%|█████▎    | 132/251 [01:39<01:26,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  53%|█████▎    | 133/251 [01:40<01:25,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  53%|█████▎    | 134/251 [01:40<01:30,  1.29it/s]\u001b[A\n",
      "Inner Training loop:  54%|█████▍    | 135/251 [01:41<01:28,  1.31it/s]\u001b[A\n",
      "Inner Training loop:  54%|█████▍    | 136/251 [01:42<01:27,  1.31it/s]\u001b[A\n",
      "Inner Training loop:  55%|█████▍    | 137/251 [01:43<01:25,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  55%|█████▍    | 138/251 [01:43<01:24,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  55%|█████▌    | 139/251 [01:44<01:22,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  56%|█████▌    | 140/251 [01:45<01:21,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  56%|█████▌    | 141/251 [01:46<01:19,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  57%|█████▋    | 142/251 [01:46<01:20,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  57%|█████▋    | 143/251 [01:47<01:20,  1.34it/s]\u001b[A\n",
      "Inner Training loop:  57%|█████▋    | 144/251 [01:48<01:20,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  58%|█████▊    | 145/251 [01:49<01:18,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  58%|█████▊    | 146/251 [01:49<01:16,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  59%|█████▊    | 147/251 [01:50<01:14,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  59%|█████▉    | 148/251 [01:51<01:14,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  59%|█████▉    | 149/251 [01:51<01:12,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  60%|█████▉    | 150/251 [01:52<01:12,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  60%|██████    | 151/251 [01:53<01:13,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  61%|██████    | 152/251 [01:54<01:11,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  61%|██████    | 153/251 [01:54<01:10,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  61%|██████▏   | 154/251 [01:55<01:08,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  62%|██████▏   | 155/251 [01:56<01:11,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  62%|██████▏   | 156/251 [01:57<01:14,  1.28it/s]\u001b[A\n",
      "Inner Training loop:  63%|██████▎   | 157/251 [01:58<01:14,  1.26it/s]\u001b[A\n",
      "Inner Training loop:  63%|██████▎   | 158/251 [01:58<01:13,  1.26it/s]\u001b[A\n",
      "Inner Training loop:  63%|██████▎   | 159/251 [01:59<01:10,  1.31it/s]\u001b[A\n",
      "Inner Training loop:  64%|██████▎   | 160/251 [02:00<01:07,  1.35it/s]\u001b[A\n",
      "Inner Training loop:  64%|██████▍   | 161/251 [02:00<01:05,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  65%|██████▍   | 162/251 [02:01<01:03,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  65%|██████▍   | 163/251 [02:02<01:04,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  65%|██████▌   | 164/251 [02:03<01:02,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  66%|██████▌   | 165/251 [02:03<01:02,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  66%|██████▌   | 166/251 [02:04<01:01,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  67%|██████▋   | 167/251 [02:05<00:59,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  67%|██████▋   | 168/251 [02:05<00:58,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  67%|██████▋   | 169/251 [02:06<00:57,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  68%|██████▊   | 170/251 [02:07<00:58,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  68%|██████▊   | 171/251 [02:08<00:57,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  69%|██████▊   | 172/251 [02:08<00:57,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  69%|██████▉   | 173/251 [02:09<00:55,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  69%|██████▉   | 174/251 [02:10<00:54,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  70%|██████▉   | 175/251 [02:10<00:53,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  70%|███████   | 176/251 [02:11<00:52,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  71%|███████   | 177/251 [02:12<00:53,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  71%|███████   | 178/251 [02:13<00:51,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  71%|███████▏  | 179/251 [02:13<00:52,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  72%|███████▏  | 180/251 [02:14<00:50,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  72%|███████▏  | 181/251 [02:15<00:49,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  73%|███████▎  | 182/251 [02:15<00:48,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  73%|███████▎  | 183/251 [02:16<00:47,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  73%|███████▎  | 184/251 [02:17<00:50,  1.32it/s]\u001b[A\n",
      "Inner Training loop:  74%|███████▎  | 185/251 [02:18<00:55,  1.18it/s]\u001b[A\n",
      "Inner Training loop:  74%|███████▍  | 186/251 [02:19<00:56,  1.16it/s]\u001b[A\n",
      "Inner Training loop:  75%|███████▍  | 187/251 [02:20<00:56,  1.13it/s]\u001b[A\n",
      "Inner Training loop:  75%|███████▍  | 188/251 [02:21<00:56,  1.11it/s]\u001b[A\n",
      "Inner Training loop:  75%|███████▌  | 189/251 [02:22<00:54,  1.14it/s]\u001b[A\n",
      "Inner Training loop:  76%|███████▌  | 190/251 [02:22<00:51,  1.19it/s]\u001b[A\n",
      "Inner Training loop:  76%|███████▌  | 191/251 [02:23<00:49,  1.22it/s]\u001b[A\n",
      "Inner Training loop:  76%|███████▋  | 192/251 [02:24<00:46,  1.28it/s]\u001b[A\n",
      "Inner Training loop:  77%|███████▋  | 193/251 [02:24<00:43,  1.33it/s]\u001b[A\n",
      "Inner Training loop:  77%|███████▋  | 194/251 [02:25<00:41,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  78%|███████▊  | 195/251 [02:26<00:40,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  78%|███████▊  | 196/251 [02:27<00:40,  1.36it/s]\u001b[A\n",
      "Inner Training loop:  78%|███████▊  | 197/251 [02:27<00:38,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  79%|███████▉  | 198/251 [02:28<00:38,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  79%|███████▉  | 199/251 [02:29<00:37,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  80%|███████▉  | 200/251 [02:29<00:36,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  80%|████████  | 201/251 [02:30<00:35,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  80%|████████  | 202/251 [02:31<00:34,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  81%|████████  | 203/251 [02:32<00:34,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  81%|████████▏ | 204/251 [02:32<00:33,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  82%|████████▏ | 205/251 [02:33<00:33,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  82%|████████▏ | 206/251 [02:34<00:32,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  82%|████████▏ | 207/251 [02:34<00:31,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  83%|████████▎ | 208/251 [02:35<00:30,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  83%|████████▎ | 209/251 [02:36<00:29,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  84%|████████▎ | 210/251 [02:37<00:29,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  84%|████████▍ | 211/251 [02:37<00:28,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  84%|████████▍ | 212/251 [02:38<00:28,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  85%|████████▍ | 213/251 [02:39<00:27,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  85%|████████▌ | 214/251 [02:39<00:26,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  86%|████████▌ | 215/251 [02:40<00:25,  1.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inner Training loop:  86%|████████▌ | 216/251 [02:41<00:24,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  86%|████████▋ | 217/251 [02:42<00:24,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  87%|████████▋ | 218/251 [02:42<00:23,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  87%|████████▋ | 219/251 [02:43<00:23,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  88%|████████▊ | 220/251 [02:44<00:22,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  88%|████████▊ | 221/251 [02:44<00:21,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  88%|████████▊ | 222/251 [02:45<00:20,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  89%|████████▉ | 223/251 [02:46<00:19,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  89%|████████▉ | 224/251 [02:47<00:19,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  90%|████████▉ | 225/251 [02:47<00:18,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  90%|█████████ | 226/251 [02:48<00:18,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  90%|█████████ | 227/251 [02:49<00:17,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  91%|█████████ | 228/251 [02:50<00:16,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  91%|█████████ | 229/251 [02:50<00:15,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  92%|█████████▏| 230/251 [02:51<00:15,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  92%|█████████▏| 231/251 [02:52<00:14,  1.37it/s]\u001b[A\n",
      "Inner Training loop:  92%|█████████▏| 232/251 [02:52<00:13,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  93%|█████████▎| 233/251 [02:53<00:13,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  93%|█████████▎| 234/251 [02:54<00:12,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  94%|█████████▎| 235/251 [02:55<00:11,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  94%|█████████▍| 236/251 [02:55<00:10,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  94%|█████████▍| 237/251 [02:56<00:09,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  95%|█████████▍| 238/251 [02:57<00:09,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  95%|█████████▌| 239/251 [02:57<00:08,  1.41it/s]\u001b[A\n",
      "Inner Training loop:  96%|█████████▌| 240/251 [02:58<00:07,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  96%|█████████▌| 241/251 [02:59<00:07,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  96%|█████████▋| 242/251 [03:00<00:06,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  97%|█████████▋| 243/251 [03:00<00:05,  1.42it/s]\u001b[A\n",
      "Inner Training loop:  97%|█████████▋| 244/251 [03:01<00:04,  1.43it/s]\u001b[A\n",
      "Inner Training loop:  98%|█████████▊| 245/251 [03:02<00:04,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  98%|█████████▊| 246/251 [03:02<00:03,  1.40it/s]\u001b[A\n",
      "Inner Training loop:  98%|█████████▊| 247/251 [03:03<00:02,  1.38it/s]\u001b[A\n",
      "Inner Training loop:  99%|█████████▉| 248/251 [03:04<00:02,  1.39it/s]\u001b[A\n",
      "Inner Training loop:  99%|█████████▉| 249/251 [03:05<00:01,  1.41it/s]\u001b[A\n",
      "Inner Training loop: 100%|█████████▉| 250/251 [03:05<00:00,  1.41it/s]\u001b[A\n",
      "Inner Training loop: 100%|██████████| 251/251 [03:06<00:00,  1.35it/s]\u001b[A\n",
      "/Users/theoguenais/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([629])) that is different to the input size (torch.Size([629, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 0 | Loss 0.9798471331596375: 100%|██████████| 1/1 [03:14<00:00, 194.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not write confusion_matrix due to name 'workspace' is not defined\n",
      "Could not write accuracy due to name 'workspace' is not defined\n",
      "Could not write precision due to name 'workspace' is not defined\n",
      "Could not write recall due to name 'workspace' is not defined\n",
      "Could not write f1 due to name 'workspace' is not defined\n",
      "Could not write f1_micro due to name 'workspace' is not defined\n",
      "Could not write f1_macro due to name 'workspace' is not defined\n",
      "Could not write classification_report due to name 'workspace' is not defined\n",
      "Epoch: 01 | Time: 3m 14s\n",
      "\tTrain Loss: 1.0093 | Train PPL:   2.744\n",
      "\t Val. Loss: 0.980 |  Val. PPL:   2.664\n",
      "\t Final test ACC 0.980\n",
      "Problem 'Args' object has no attribute 'lr'\n",
      "Problem 'Args' object has no attribute 'l2_reg'\n",
      "Problem 'Args' object has no attribute 'lr'\n",
      "Problem 'Args' object has no attribute 'model'\n",
      "Problem 'Args' object has no attribute 'num_epochs'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theoguenais/anaconda/envs/graphcnn/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([629])) that is different to the input size (torch.Size([629, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#Hack for the notebook\n",
    "from src import metrics, run\n",
    "args.n_epochs = 1\n",
    "args.get_training_stats = True\n",
    "task = 'regression'\n",
    "train_loss_fn, \\\n",
    "eval_loss_fn, metrics_fn = metrics.create_metrics_fn(task)\n",
    "\n",
    "best_model, \\\n",
    "        optimizer, \\\n",
    "        training_stats = run.train(\n",
    "            model, optimizer,\n",
    "            num_epochs=args.n_epochs,\n",
    "            train_loss_fn=train_loss_fn,\n",
    "            test_loss_fn=eval_loss_fn,\n",
    "            metrics_fn=metrics_fn,\n",
    "            train_iterator=train_loader,\n",
    "            val_iterator=test_loader,\n",
    "            test_iterator=test_loader,\n",
    "            mode=args.mode,\n",
    "            task=task,\n",
    "            get_training_stats=args.get_training_stats,\n",
    "            clip=None,\n",
    "            scheduler=None,\n",
    "            l2_reg=0.,\n",
    "            save=False,\n",
    "            args=args,\n",
    "            output_dir=args.output_dir,\n",
    "            writer=args.writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the training work exactly?\n",
    "1. **We Backprop and train for one epoch**\n",
    "```py\n",
    "train_losses, \\\n",
    "preds, true_preds = train_epoch(\n",
    "                        model=model,\n",
    "                        train_iterator=train_iterator,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=train_loss_fn,\n",
    "                        global_step=epoch,\n",
    "                        task=get_training_stats,\n",
    "                        return_pt=True,\n",
    "                        l2_reg=l2_reg,\n",
    "                        clip=clip,\n",
    "                        scheduler=scheduler)\n",
    "```\n",
    "2. **Obtain the training metrics.**\n",
    "```py\n",
    "train_metrics = metrics_fn(preds, true_preds)\n",
    "```   \n",
    "3. **Eval (metrics obtained in the function directly).**\n",
    "```py\n",
    "preds, true_preds, \\\n",
    "valid_loss, eval_metrics = evaluate(\n",
    "                                    model=model, \n",
    "                                    iterator=val_iterator,\n",
    "                                    loss_fn=test_loss_fn,\n",
    "                                    metrics_func=metrics_fn,\n",
    "                                    task=task)\n",
    "```\n",
    "\n",
    "**We repeat the above for each epoch.**\n",
    "\n",
    "The final output of the training is: \n",
    "```py\n",
    "best_model, optimizer, training_stats : dict = {\n",
    "                                'train_metrics': ...,\n",
    "                                'eval_metrics': ...,\n",
    "                                'test_metrics': ...,\n",
    "                                'test_preds': ...,\n",
    "                                'test_labels': ...\n",
    "                                }\n",
    "```                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
